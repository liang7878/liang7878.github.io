{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/css/noscript.styl","path":"css/noscript.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/comments-buttons.js","path":"js/comments-buttons.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/comments.js","path":"js/comments.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/config.js","path":"js/config.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/pjax.js","path":"js/pjax.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/schedule.js","path":"js/schedule.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/logo-algolia-nebula-blue-full.svg","path":"images/logo-algolia-nebula-blue-full.svg","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/addtoany.js","path":"js/third-party/addtoany.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/fancybox.js","path":"js/third-party/fancybox.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/pace.js","path":"js/third-party/pace.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/quicklink.js","path":"js/third-party/quicklink.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/baidu-analytics.js","path":"js/third-party/analytics/baidu-analytics.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/google-analytics.js","path":"js/third-party/analytics/google-analytics.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/growingio.js","path":"js/third-party/analytics/growingio.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/matomo.js","path":"js/third-party/analytics/matomo.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/chatra.js","path":"js/third-party/chat/chatra.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/gitter.js","path":"js/third-party/chat/gitter.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/tidio.js","path":"js/third-party/chat/tidio.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/changyan.js","path":"js/third-party/comments/changyan.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqus.js","path":"js/third-party/comments/disqus.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqusjs.js","path":"js/third-party/comments/disqusjs.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/gitalk.js","path":"js/third-party/comments/gitalk.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/isso.js","path":"js/third-party/comments/isso.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/livere.js","path":"js/third-party/comments/livere.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/utterances.js","path":"js/third-party/comments/utterances.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/katex.js","path":"js/third-party/math/katex.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/mathjax.js","path":"js/third-party/math/mathjax.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/algolia-search.js","path":"js/third-party/search/algolia-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/firestore.js","path":"js/third-party/statistics/firestore.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/local-search.js","path":"js/third-party/search/local-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/mermaid.js","path":"js/third-party/tags/mermaid.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/lean-analytics.js","path":"js/third-party/statistics/lean-analytics.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/pdf.js","path":"js/third-party/tags/pdf.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/wavedrom.js","path":"js/third-party/tags/wavedrom.js","modified":0,"renderable":1},{"_id":"source/images/SQLite_Architecture.png","path":"images/SQLite_Architecture.png","modified":0,"renderable":0},{"_id":"source/images/avatar.png","path":"images/avatar.png","modified":0,"renderable":0},{"_id":"source/images/manu_arch.png","path":"images/manu_arch.png","modified":0,"renderable":0},{"_id":"source/images/logo.png","path":"images/logo.png","modified":0,"renderable":0},{"_id":"source/images/manu_e_commer_real_traffic.png","path":"images/manu_e_commer_real_traffic.png","modified":0,"renderable":0},{"_id":"source/images/manu_grace_time.png","path":"images/manu_grace_time.png","modified":0,"renderable":0},{"_id":"source/images/manu_index.png","path":"images/manu_index.png","modified":0,"renderable":0},{"_id":"source/images/manu_index_build.png","path":"images/manu_index_build.png","modified":0,"renderable":0},{"_id":"source/images/manu_log_system.png","path":"images/manu_log_system.png","modified":0,"renderable":0},{"_id":"source/images/manu_query_node.png","path":"images/manu_query_node.png","modified":0,"renderable":0},{"_id":"source/images/ob_arch.png","path":"images/ob_arch.png","modified":0,"renderable":0},{"_id":"source/images/manu_recommendation_recall.png","path":"images/manu_recommendation_recall.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"2763f27faef8123da34cb49177eb658d596ff702","modified":1690695790445},{"_id":"source/categories/index.md","hash":"4433347a472de4d12b330f153d540451de8efb21","modified":1690697497247},{"_id":"source/tags/index.md","hash":"731e95a3d6ba0dfdd822addcfd4cff6101e29c24","modified":1690697497259},{"_id":"source/images/SQLite_Architecture.png","hash":"04b4266d3b866f3578e89908fe4354f0b0369269","modified":1690697497247},{"_id":"source/images/manu_index.png","hash":"d2352a9e83be39ef736f9faf8b9cb7f7479bb371","modified":1690697497256},{"_id":"source/_posts/activedirectory/ESE源码分析.md","hash":"2d404c305b3b8010981d94ae3f2fa501f90bf2e9","modified":1690697497245},{"_id":"source/_posts/activedirectory/Kerberos.md","hash":"766b6056999e0450dc67eab6b3f2aa7c049ee664","modified":1690697497245},{"_id":"source/_posts/activedirectory/什么是 AD.md","hash":"e1ec3a19461cb8f23cb80d7437af5282a917d4be","modified":1690697497245},{"_id":"source/_posts/activedirectory/utd_vector.md","hash":"80eaf8e924f080da134634423514c72faa2c6d9c","modified":1690697497245},{"_id":"source/_posts/papers/Manu.md","hash":"18e993cef0bf8dff6e34a6d39676c1fbda80c552","modified":1690697497246},{"_id":"source/_posts/papers/Oceanbase.md","hash":"8c049bbda2ad0955a01e54b01ba044613a11a0f3","modified":1690716965281},{"_id":"source/_posts/aosabook/bdb.md","hash":"1b03748e604f420147248d4ca461c9d8665ace63","modified":1690697497245},{"_id":"source/_posts/papers/SQLite.md","hash":"971ead2a5653aeacab189ffcf61af9a7f1a31293","modified":1690697497246},{"_id":"source/_posts/interview/常见数据结构的时间复杂度和空间复杂度.md","hash":"0cc35683db46142d1b3eb9cfc859254aa08a10c4","modified":1690697497245},{"_id":"source/_posts/interview/数据库连接池设计.md","hash":"8058ce6b0c89412bc44a03901864e6b59ada67c9","modified":1690697497246},{"_id":"source/_posts/interview/etcd 源码分析-raft.md","hash":"c69627c5f323f1ff71bb2d25e299c5fa8cd118a9","modified":1690697497245},{"_id":"source/_posts/interview/生产环境中的限流方案.md","hash":"020df58e849fbc585767b2618ad4c0e65a029dfb","modified":1690697497246},{"_id":"source/_posts/tidb/store_interface.md","hash":"759917afc347043590580daeb5fe3cd7659b8308","modified":1690697497247},{"_id":"source/_posts/tidb/opt_rule.md","hash":"2fc416103ad73574070a9ea9fa0a614a5919bdfb","modified":1690697497247},{"_id":"source/_posts/tidb/optimize.md","hash":"66e60bac529afeb4cbff39d025c76e7e150dd45c","modified":1690697497247},{"_id":"source/images/manu_e_commer_real_traffic.png","hash":"ccfa57fae161ab248843c926341c4ac7269f895f","modified":1690697497255},{"_id":"source/images/manu_grace_time.png","hash":"a568b575c790ad2cc32cddf63f9cdff3df9b765d","modified":1690697497256},{"_id":"source/images/manu_index_build.png","hash":"68340c5963012b770a4e5341c5d300fac4c6f527","modified":1690697497256},{"_id":"source/images/manu_log_system.png","hash":"4c83bcdfa00dff3ed4c59d73356311ce1cc43291","modified":1690697497257},{"_id":"source/images/manu_recommendation_recall.png","hash":"35c970e543d6fb42cef79c3e1aff0399b35ca4c9","modified":1690697497258},{"_id":"source/images/manu_arch.png","hash":"e6d219b1779663f0dd1227082913567a85a7a0af","modified":1690697497255},{"_id":"source/images/manu_query_node.png","hash":"50ed770380d54d3b4a1edcad535bc59a94137adf","modified":1690697497258},{"_id":"source/images/ob_arch.png","hash":"b4a9dddf8a799b21c9359d0d8297f24dd8fbf18c","modified":1690697497259},{"_id":"node_modules/hexo-theme-next/LICENSE.md","hash":"68fc9a03d50fd4b5ea97092b05967d1819dea2c4","modified":1690698244345},{"_id":"node_modules/hexo-theme-next/README.md","hash":"36c4b25587ca494102323dab5a38de5490451a64","modified":1690698244349},{"_id":"node_modules/hexo-theme-next/_vendors.yml","hash":"c544f9a3710d8feb62c1904eef2f55bc8c019169","modified":1690698244434},{"_id":"node_modules/hexo-theme-next/_config.yml","hash":"05d38ed1a9a5353694a6c7bf2904d741eb047f33","modified":1690698244433},{"_id":"node_modules/hexo-theme-next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1690698244340},{"_id":"node_modules/hexo-theme-next/package.json","hash":"c7f27b775f080fc753d1c99a20dd1655af7bc041","modified":1690698244337},{"_id":"node_modules/hexo-theme-next/docs/AUTHORS.md","hash":"a648823121563c34a177ae91f5a774b5e29f01a0","modified":1690698244340},{"_id":"node_modules/hexo-theme-next/docs/LICENSE.txt","hash":"f5b14f791b7cfa1d16da981d929152e088a5d1b8","modified":1690698244431},{"_id":"node_modules/hexo-theme-next/languages/README.md","hash":"b2567e32805dda79601157351a07e5ca9fe01315","modified":1690698244348},{"_id":"node_modules/hexo-theme-next/languages/ar.yml","hash":"7d0f39e8684284a04bb9808521c87fecda8bd131","modified":1690698244434},{"_id":"node_modules/hexo-theme-next/languages/de.yml","hash":"79b37df731c29665dee6cd7c90d278e1edfb6e24","modified":1690698244435},{"_id":"node_modules/hexo-theme-next/languages/bn.yml","hash":"9f791494afa263c3e31f14b8a5fa2996dfc834c0","modified":1690698244435},{"_id":"node_modules/hexo-theme-next/languages/en.yml","hash":"ba0fd79a2b1d8db01a034180556061745965ff05","modified":1690698244435},{"_id":"node_modules/hexo-theme-next/languages/fr.yml","hash":"44cd26479f503751329f6da2ed80cce1bbf18117","modified":1690698244437},{"_id":"node_modules/hexo-theme-next/languages/id.yml","hash":"929df147f4f17d638b07de5fe52ca13e2549ab1c","modified":1690698244438},{"_id":"node_modules/hexo-theme-next/languages/it.yml","hash":"16d716ecfd748def2f6486ef5a82d0ab7ceb4890","modified":1690698244438},{"_id":"node_modules/hexo-theme-next/languages/ja.yml","hash":"543222bfc516aab6c33e8534f807972ecb8943a9","modified":1690698244438},{"_id":"node_modules/hexo-theme-next/languages/ko.yml","hash":"d345a303310c8a5f4836c3683f3580f861ebd1b4","modified":1690698244439},{"_id":"node_modules/hexo-theme-next/languages/fa.yml","hash":"f3ffc444599f4ac92d62e9ed00a1490ebc277d70","modified":1690698244437},{"_id":"node_modules/hexo-theme-next/languages/es.yml","hash":"dffc63ef42e1266b88e0acf08994fd17a9908d53","modified":1690698244436},{"_id":"node_modules/hexo-theme-next/languages/nl.yml","hash":"3cb3687696635ec71b4ca40c5fc43b56acc8843e","modified":1690698244439},{"_id":"node_modules/hexo-theme-next/languages/pt-BR.yml","hash":"76b8576ce228d540a16b1f0af5af2cce20923194","modified":1690698244440},{"_id":"node_modules/hexo-theme-next/languages/ru.yml","hash":"c6d8de0ff7d8148d09993257cfd3b7aca755696c","modified":1690698244440},{"_id":"node_modules/hexo-theme-next/languages/pt.yml","hash":"70de366e10ea584ba039d40d6b35ac97f93454ad","modified":1690698244440},{"_id":"node_modules/hexo-theme-next/languages/eo.yml","hash":"e34bb33ae827bf2f0727088599a73bc64bdad1b0","modified":1690698244436},{"_id":"node_modules/hexo-theme-next/languages/tk.yml","hash":"511726054873f6f8d7ce0d2e803f6731de0ddbe7","modified":1690698244442},{"_id":"node_modules/hexo-theme-next/languages/si.yml","hash":"2d712eedf3f60d04d36c3108cf5a12e2a52e875c","modified":1690698244441},{"_id":"node_modules/hexo-theme-next/languages/zh-CN.yml","hash":"741d7efe0262c9cdc2c648014b55599665d90f6b","modified":1690698244444},{"_id":"node_modules/hexo-theme-next/languages/vi.yml","hash":"7ebcba5e1128784195e4681dffc9d34c4e873fec","modified":1690698244444},{"_id":"node_modules/hexo-theme-next/languages/th.yml","hash":"6829e998b39f8f143e20b276bb1f62d95a29de58","modified":1690698244442},{"_id":"node_modules/hexo-theme-next/languages/zh-TW.yml","hash":"4695c87d6b81b3a23d16ad6513d9eaa925f8d8ad","modified":1690698244445},{"_id":"node_modules/hexo-theme-next/languages/tr.yml","hash":"a57e4ed089b893a95f5e1ecff17ce625165f4d46","modified":1690698244443},{"_id":"node_modules/hexo-theme-next/layout/_layout.njk","hash":"fc0a45112f2dcfc2642404e8934ea32a793c3bd7","modified":1690698244352},{"_id":"node_modules/hexo-theme-next/languages/uk.yml","hash":"ff537047b4b4c3ca9a7b64fa7f428a9942751eeb","modified":1690698244443},{"_id":"node_modules/hexo-theme-next/layout/index.njk","hash":"dd63e488ae8cc144335a5958acedf6a16edd7a92","modified":1690698244374},{"_id":"node_modules/hexo-theme-next/layout/archive.njk","hash":"d759f4d2cf5ddc6875ea250113a00662c1caf6d1","modified":1690698244355},{"_id":"node_modules/hexo-theme-next/layout/page.njk","hash":"b0660b2af0ac7d3fda14ca4d9f2c9e79ef06c6f9","modified":1690698244380},{"_id":"node_modules/hexo-theme-next/layout/category.njk","hash":"c68b7343d0f8145010f93351908cc36ef6212ec1","modified":1690698244361},{"_id":"node_modules/hexo-theme-next/layout/post.njk","hash":"0bfce9f133f501a9a4837257e3b862b3bbca15be","modified":1690698244385},{"_id":"node_modules/hexo-theme-next/docs/ru/README.md","hash":"ac3c4a7616ea80f0d32d68d6e53233952ba756dc","modified":1690698244347},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7a06d443f374bd1e84294067a0ac796afd9fbe60","modified":1690698244343},{"_id":"node_modules/hexo-theme-next/layout/tag.njk","hash":"9e16ba20c28a7f2c6bc75aa427f48122301a30aa","modified":1690698244387},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/CONTRIBUTING.md","hash":"a089f7a8368ab0b7d7b9b7ec0ac3767a453435df","modified":1690698244344},{"_id":"node_modules/hexo-theme-next/layout/_partials/comments.njk","hash":"d0c470b0f6690aa217e9ada848c5e2e73fb27c6f","modified":1690698244363},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/README.md","hash":"9bbdbb0656505acceef9b9895a576164175fe888","modified":1690698244347},{"_id":"node_modules/hexo-theme-next/layout/_partials/pagination.njk","hash":"bc719473ed5948ab6859449d60b8d36cfc1542b4","modified":1690698244380},{"_id":"node_modules/hexo-theme-next/layout/_partials/footer.njk","hash":"6fca18ed4234cf54146c2b3b97b0a6a3606ab33d","modified":1690698244366},{"_id":"node_modules/hexo-theme-next/layout/_partials/widgets.njk","hash":"e7f988ecddb2159313699a00827a45eca5622bd4","modified":1690698244388},{"_id":"node_modules/hexo-theme-next/layout/_macro/post-collapse.njk","hash":"1a30d751871dabfa80940042ddb1f77d07d830b9","modified":1690698244381},{"_id":"node_modules/hexo-theme-next/layout/_macro/sidebar.njk","hash":"547c62ab14d9e05d2d9116db9048a677fbe1fb6d","modified":1690698244386},{"_id":"node_modules/hexo-theme-next/layout/_partials/languages.njk","hash":"e43f22198cccb5f6e306b1ce0d28d12a4fb891f8","modified":1690698244375},{"_id":"node_modules/hexo-theme-next/layout/_scripts/index.njk","hash":"6668878a0f9a1166c6a879755f54a08d942da870","modified":1690698244371},{"_id":"node_modules/hexo-theme-next/layout/_macro/post.njk","hash":"95822069cce2c4702e035c770b3089bc12a3404c","modified":1690698244384},{"_id":"node_modules/hexo-theme-next/layout/_scripts/vendors.njk","hash":"be80b9fe415a9a09d74c28e230995fd292dfc123","modified":1690698244388},{"_id":"node_modules/hexo-theme-next/layout/_third-party/addtoany.njk","hash":"ef64c6bfb8540cd874701236b9be47db2496e98e","modified":1690698244352},{"_id":"node_modules/hexo-theme-next/layout/_third-party/index.njk","hash":"bda05391c72f7a25731e762077636c4a97fc4910","modified":1690698244372},{"_id":"node_modules/hexo-theme-next/layout/_third-party/fancybox.njk","hash":"844559f46e2ff1c8be234d5763703106e2072a7b","modified":1690698244365},{"_id":"node_modules/hexo-theme-next/layout/_third-party/pace.njk","hash":"d7ad5714079f7f65446f880baf14722435ca9061","modified":1690698244379},{"_id":"node_modules/hexo-theme-next/layout/_third-party/quicklink.njk","hash":"0efed71ed530447718c4ea5bbd5fc8695b0b0d5f","modified":1690698244385},{"_id":"node_modules/hexo-theme-next/source/css/_colors.styl","hash":"3c6798c10cc220d83481cb3f3782e78558cee789","modified":1690698244390},{"_id":"node_modules/hexo-theme-next/source/css/_mixins.styl","hash":"83647a6207333b9609ba90b0946b3fa9548e6381","modified":1690698244395},{"_id":"node_modules/hexo-theme-next/source/css/main.styl","hash":"921a58577f411cf4eb5cfd66db0a241f8f88578c","modified":1690698244419},{"_id":"node_modules/hexo-theme-next/languages/zh-HK.yml","hash":"88ea50eeb9097ab4a87a44981a102d8594feb064","modified":1690698244445},{"_id":"node_modules/hexo-theme-next/scripts/events/index.js","hash":"bd9ea82376cd87df611ea3ae077875c7c595a3df","modified":1690698244292},{"_id":"node_modules/hexo-theme-next/source/css/noscript.styl","hash":"dadc81256afb127b77eac6763d5ee0ec9c77f0a3","modified":1690698244421},{"_id":"node_modules/hexo-theme-next/source/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1690698244247},{"_id":"node_modules/hexo-theme-next/source/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1690698244214},{"_id":"node_modules/hexo-theme-next/source/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1690698244248},{"_id":"node_modules/hexo-theme-next/source/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1690698244257},{"_id":"node_modules/hexo-theme-next/source/js/motion.js","hash":"770d63c26f22705311028a36b52e999cc8a2da82","modified":1690698244314},{"_id":"node_modules/hexo-theme-next/source/js/pjax.js","hash":"b03ba78c6916ad2f390d55bc1bc18fafb64b0ebf","modified":1690698244325},{"_id":"node_modules/hexo-theme-next/source/js/next-boot.js","hash":"da0f07f9eaaa83de70128b0feaea3fdadb90457a","modified":1690698244319},{"_id":"node_modules/hexo-theme-next/source/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1690698244327},{"_id":"node_modules/hexo-theme-next/source/js/utils.js","hash":"5e1cf39de050964e97fb3ba0825aeec7f4bc36dd","modified":1690698244330},{"_id":"node_modules/hexo-theme-next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1690698244389},{"_id":"node_modules/hexo-theme-next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1690698244389},{"_id":"node_modules/hexo-theme-next/source/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1690698244105},{"_id":"node_modules/hexo-theme-next/source/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1690698244429},{"_id":"node_modules/hexo-theme-next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1690698244389},{"_id":"node_modules/hexo-theme-next/scripts/filters/minify.js","hash":"964a01bec35a95da974882295cababcb93219b40","modified":1690698244313},{"_id":"node_modules/hexo-theme-next/scripts/filters/locals.js","hash":"9eb5310664759931287dd28ea39165dfb67f12ed","modified":1690698244306},{"_id":"node_modules/hexo-theme-next/scripts/filters/default-injects.js","hash":"872f01cb10e422a648ea505436532e776e92926b","modified":1690698244265},{"_id":"node_modules/hexo-theme-next/source/images/logo.svg","hash":"099e11ab995a2c8981427a85476d082609848c77","modified":1690698244430},{"_id":"node_modules/hexo-theme-next/scripts/helpers/engine.js","hash":"d292b78485e8e8055712b0ed6de7cf559c5fbdcd","modified":1690698244275},{"_id":"node_modules/hexo-theme-next/scripts/filters/post.js","hash":"fdc8a0af90035e89c3fcb754a0eb189b8951a2bc","modified":1690698244325},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-config.js","hash":"226fccbe9c93265e65a300e3cb4bf6f9065cfdd7","modified":1690698244320},{"_id":"node_modules/hexo-theme-next/scripts/helpers/navigation.js","hash":"78107021101553c3d23e89290f7530b60cf4aa86","modified":1690698244318},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-paginator.js","hash":"e86c764b546e4fbb87970cabc4135a56f9ef9fe1","modified":1690698244321},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-url.js","hash":"fd24abfaba4d91923ddb6aecf0268b216678c8bd","modified":1690698244322},{"_id":"node_modules/hexo-theme-next/scripts/tags/button.js","hash":"c6ad2ed544fbb25ecb5d820c36e76302504271b7","modified":1690698244221},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-vendors.js","hash":"afdd6a188a74c188f0dd154fac70efd4080ca262","modified":1690698244322},{"_id":"node_modules/hexo-theme-next/scripts/helpers/font.js","hash":"3394185a7f0393c16ce52c8028f90da3e9239c55","modified":1690698244282},{"_id":"node_modules/hexo-theme-next/scripts/tags/center-quote.js","hash":"92c19d796bdb3320df9caea59bf52df7a95d9da9","modified":1690698244224},{"_id":"node_modules/hexo-theme-next/scripts/tags/caniuse.js","hash":"935a311142a409c1896b3ae3f01fe7a9e2db1134","modified":1690698244223},{"_id":"node_modules/hexo-theme-next/scripts/tags/index.js","hash":"1f6aba7820f1fb58b61969485148db21846e1aa9","modified":1690698244293},{"_id":"node_modules/hexo-theme-next/scripts/tags/group-pictures.js","hash":"9ed799c329abf830f623689d7e136991256a24ca","modified":1690698244287},{"_id":"node_modules/hexo-theme-next/scripts/tags/label.js","hash":"8a73348186113bae0a51ea2f891c1bb882fab05a","modified":1690698244300},{"_id":"node_modules/hexo-theme-next/scripts/tags/link-grid.js","hash":"18a483c2d5afd701f6080ffdddf2d1321370336c","modified":1690698244303},{"_id":"node_modules/hexo-theme-next/scripts/tags/mermaid.js","hash":"4fb01ca650fa8b256b8d48f50dc1b18350bd3d6d","modified":1690698244308},{"_id":"node_modules/hexo-theme-next/scripts/tags/pdf.js","hash":"344636b6fd7e27e8831c1e194039afc0d61931cd","modified":1690698244324},{"_id":"node_modules/hexo-theme-next/scripts/tags/tabs.js","hash":"0eabe51da40b4b13e16419c8fe02452d9a4fef73","modified":1690698244328},{"_id":"node_modules/hexo-theme-next/scripts/tags/note.js","hash":"7b94ddb46b7d4b0fe815f2fbe4bd375f07f55363","modified":1690698244323},{"_id":"node_modules/hexo-theme-next/scripts/tags/video.js","hash":"2ee926448583be8f95af1f2884ae2c9c4830151d","modified":1690698244334},{"_id":"node_modules/hexo-theme-next/scripts/tags/wavedrom.js","hash":"b44dfeeb58b41945d469141787f3dbce4b117d08","modified":1690698244336},{"_id":"node_modules/hexo-theme-next/layout/_partials/head/head-unique.njk","hash":"8da52a144060db1a0a088ccb2e6cc8376d1fce70","modified":1690698244369},{"_id":"node_modules/hexo-theme-next/layout/_partials/head/head.njk","hash":"5388b157bba4a40b9312f4a45c6678974ccf0837","modified":1690698244369},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/brand.njk","hash":"dd9c4c03e99dfde0dfb8edefcb2c933f2f560efc","modified":1690698244357},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/menu.njk","hash":"ee6fc2f111572d3eeab0a2fecbb2d6b3e37ab26b","modified":1690698244378},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/index.njk","hash":"650de421a8ce4cf685428ffbe0087ff84cbd1356","modified":1690698244370},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/menu-item.njk","hash":"41a8b0cc16f60fa085cb719d07216d86b6bc4bf8","modified":1690698244378},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/categories.njk","hash":"17156d99941f28a225951ffdcfa9a115e20dc2d2","modified":1690698244360},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/sub-menu.njk","hash":"06480d8ec5f0b87eafd47f082f07968d7282dd5c","modified":1690698244387},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/breadcrumb.njk","hash":"89825e75cc45e9709fa6ba89883669eedaff6f46","modified":1690698244358},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/page-header.njk","hash":"7ed4f102a1825195cff8d7995bf9219f323a9034","modified":1690698244379},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/tags.njk","hash":"a18d1598e36cc72f2b0b24c3cc3c5990dfaa3254","modified":1690698244387},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/schedule.njk","hash":"0f4bc8e257da60f77c0c1738607b2bde55810684","modified":1690698244386},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-meta.njk","hash":"9fa47e4fb342811da590ee4adc91cf81118c0a39","modified":1690698244382},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-followme.njk","hash":"c1e33b4889f75acc490af3c8bde0ec56c518ff41","modified":1690698244382},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-related.njk","hash":"e0986db00a0201dd3c60570f964829c84ba5bc68","modified":1690698244383},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-copyright.njk","hash":"79667fd0be85ee0e0c69e542e4f870b114c96c33","modified":1690698244381},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-reward.njk","hash":"e8b8a7c41e9ec612d0c0c73419529d55d1c16256","modified":1690698244383},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-share.njk","hash":"16696990e4ce65fc8db18c4635082a5d5d06ff07","modified":1690698244383},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/index.njk","hash":"8f6f256ab3b351ffc80f1f3f1d9834e9a7cfac31","modified":1690698244370},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/algolia-search.njk","hash":"efb2b6f19df02ba5ae623a1f274fff52aed21e6f","modified":1690698244354},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/localsearch.njk","hash":"661f7acae43f0be694266323320f977d84119abe","modified":1690698244376},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/gitter.njk","hash":"f8cc14b7aa949999a1faaeb7855e2f20b59a386d","modified":1690698244367},{"_id":"node_modules/hexo-theme-next/layout/_partials/sidebar/site-overview.njk","hash":"70342218473a6e6aa9148de06bfffe121afb8548","modified":1690698244386},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/chatra.njk","hash":"d7263fca16d0278ccf1f6aa1c6df6902a6344a09","modified":1690698244362},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/cloudflare.njk","hash":"a5b8297c2c383124dd6a56e256ecc0c0dcf489be","modified":1690698244363},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/baidu-analytics.njk","hash":"6215309aee028dcb734452beec448c5afb6c63fc","modified":1690698244356},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/google-analytics.njk","hash":"d89066ff53879693f023e540d59c86137172c529","modified":1690698244368},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/tidio.njk","hash":"02aab857c27fc103216029be991688b12a73a525","modified":1690698244387},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/growingio.njk","hash":"8afaa772c390bd9d53a5cff9645ac3168334eb98","modified":1690698244368},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/index.njk","hash":"f900306497b133e8b098bd9f4b96b93d1d96c185","modified":1690698244371},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/plausible.njk","hash":"ef9f2bb7110507f1c4336800af9157d5fa9765bd","modified":1690698244380},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/microsoft-clarity.njk","hash":"9dc00fcb0a05899f048eace9f9160b78956655d5","modified":1690698244379},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/umami.njk","hash":"3343750682fbd8535e50f8129be3003ad26015b4","modified":1690698244387},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/matomo.njk","hash":"4e89648a8ec8194c5823064cbca39c938a799006","modified":1690698244377},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/changyan.njk","hash":"d1c950f8fbdf85e7a3eae5463767a89e858e8220","modified":1690698244361},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/disqusjs.njk","hash":"0749cb6902baecdfd01f779a2a2513f6d2f6a823","modified":1690698244364},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/disqus.njk","hash":"9375b19a89b7fa9474e558d085af5448d4c5c50c","modified":1690698244364},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/gitalk.njk","hash":"b63b7e2ede0d3e66e732fa1a06bda9b19e1e85d4","modified":1690698244367},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/isso.njk","hash":"64cc3bdaf644fd32c0d0a247f29f5b6904da9af3","modified":1690698244374},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/livere.njk","hash":"3b13b09fba84ec6000886890a6710736a2b8fafe","modified":1690698244376},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/utterances.njk","hash":"5a94032bc3512a10ad4328fc19ec07b819a1d687","modified":1690698244388},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/katex.njk","hash":"1ebf658690468ea197bdd0416eb7cfa4bd0b083a","modified":1690698244375},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/index.njk","hash":"abf37fc55aa86702118e8fdf5bf2d389dd589aa0","modified":1690698244373},{"_id":"node_modules/hexo-theme-next/layout/_third-party/search/algolia-search.njk","hash":"24ed76e0c72a25ac152820c750a05826a706b6f4","modified":1690698244355},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/mathjax.njk","hash":"3677017fd4572b158311f5f5d870590ab25184e0","modified":1690698244377},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/busuanzi-counter.njk","hash":"a4bc501da0f22f7e420f0ca47e83988ce90b1368","modified":1690698244360},{"_id":"node_modules/hexo-theme-next/layout/_third-party/search/localsearch.njk","hash":"e45ea3542cdc9ed7ec8447b5e6f35df4c5e82758","modified":1690698244376},{"_id":"node_modules/hexo-theme-next/layout/_third-party/tags/mermaid.njk","hash":"099e031f52fb8e47b3af5b2684737efc9e643ee7","modified":1690698244379},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/index.njk","hash":"568ddf7955d11d93fb5e842b403a7ac8b1b7fdb1","modified":1690698244374},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/lean-analytics.njk","hash":"2446e748cdc102c78492216319ac02148db7daf6","modified":1690698244375},{"_id":"node_modules/hexo-theme-next/layout/_third-party/tags/wavedrom.njk","hash":"02202bf563fb5eedde2ccad4d6c5b9109d30a703","modified":1690698244388},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/firestore.njk","hash":"d32ebe94560fa95824478ebbff531bffc47b194d","modified":1690698244365},{"_id":"node_modules/hexo-theme-next/layout/_third-party/tags/pdf.njk","hash":"2c81984cc4f5123103460442f6e046f5b6c97127","modified":1690698244380},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Gemini.styl","hash":"96e0a7c2a65ce68215e17e369085b2ea2f1334f2","modified":1690698244411},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Mist.styl","hash":"a1418c9dc8c0f1a0ad4ded0f4627c45bf0db1a10","modified":1690698244420},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Muse.styl","hash":"e3be898f5ebcf435a26542653a9297ff2c71aeb0","modified":1690698244421},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/config.js","hash":"9ec51eb61f7fee612ffc5252f489003a0fa301fc","modified":1690698244256},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/highlight.js","hash":"6aec7b2c38c50989a23bfaa0d560e75c7f553e12","modified":1690698244288},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Pisces.styl","hash":"48f4f277946a168d0db1ea02804e85c22ca2c7db","modified":1690698244422},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/navigation.js","hash":"dd3562686d95a50375e6fd32e717ccb0d99c1e3d","modified":1690698244318},{"_id":"node_modules/hexo-theme-next/source/css/_variables/base.styl","hash":"c4fc4e862d09221265ab1466085f057be2ad2e4d","modified":1690698244401},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/injects.js","hash":"d987709267a1bc6e5014411e9983d7c49c102c16","modified":1690698244294},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/utils.js","hash":"6853e5433e3eaa19ea43fa20b08d956ba4cec4ac","modified":1690698244329},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/vendors.js","hash":"464db1e7182e5b9cdbd32e8b5368d5e683b1d9c7","modified":1690698244334},{"_id":"node_modules/hexo-theme-next/source/js/schemes/muse.js","hash":"ba7ba2c129d1f240c6a22cec3e53f3f22af64b6b","modified":1690698244317},{"_id":"node_modules/hexo-theme-next/source/js/third-party/addtoany.js","hash":"5276c8f78ee562a8965216dc67d762e59cb4a9f2","modified":1690698244149},{"_id":"node_modules/hexo-theme-next/source/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1690698244276},{"_id":"node_modules/hexo-theme-next/source/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1690698244323},{"_id":"node_modules/hexo-theme-next/source/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1690698244326},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/changyan.js","hash":"5798cfc8f63665031dd3e01debed051628cec319","modified":1690698244233},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/default-config.js","hash":"93ee5f9109dad885dc38c49bcee630c10f9dce6e","modified":1690698244259},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/common.js","hash":"19a402a225c31edffc50f202a14e0d582d3db23e","modified":1690698244249},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/disqus.js","hash":"7f71d6b271ba65ff333d5682e7575711d368c0d2","modified":1690698244267},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/isso.js","hash":"ff8b5b5145220a17d0ecd9508ba9bd2d3b2da47d","modified":1690698244296},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/gitalk.js","hash":"7bb7dafdd7f6bca8464b54e17e552ce7f1714195","modified":1690698244282},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/utterances.js","hash":"d3bded697bc32dace689d2a6dfb6eb7514169d15","modified":1690698244331},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/livere.js","hash":"5a07d8bb52bc1d51a624ca8db54be144566c306b","modified":1690698244303},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/index.styl","hash":"8e34df131830d4fa3725e4590a672ba1cf1903e5","modified":1690698244416},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/mobile.styl","hash":"580aa86ed2ec05a7382338a6eea02e9c740b02a5","modified":1690698244420},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/index.styl","hash":"2298e521253b3bf376a2412271bc2a7d305051f3","modified":1690698244412},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/back-to-top.styl","hash":"7664491542046df9a3887cf40a06e00c0b4086a9","modified":1690698244398},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/base.styl","hash":"d0a7c99095f490b0d2ed6b1be43d435960798cec","modified":1690698244400},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/reading-progress.styl","hash":"90a86045a33c1bae49fc2f6fa1e1b53170c7f77b","modified":1690698244423},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/buttons.styl","hash":"a042571d85ff7265f799004239a45f36b716b8a6","modified":1690698244406},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/comments.styl","hash":"e4fecc889ba3317a64e9abba5842c79dff9b7827","modified":1690698244407},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/disqusjs.js","hash":"a600a98e7436edeb31e291abca359885567df3c9","modified":1690698244271},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1690698244421},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/index.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1690698244417},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/pagination.styl","hash":"f4228c759db4a650c8d38745c2edd1dc83c45687","modified":1690698244422},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/toggles.styl","hash":"782ee1fc5e669d3ddbfeb82b73ad7fe561f1a4fb","modified":1690698244428},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Gemini/index.styl","hash":"9dfe853c901bdc52fc950bacdf15484dbb9bf140","modified":1690698244418},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_layout.styl","hash":"fa4fd8f76464e214fb7318f325b13c2b62f4b478","modified":1690698244393},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/index.styl","hash":"ab16a3dcdc0393b9b582ef59dcc13db9320e917c","modified":1690698244418},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tables.styl","hash":"e840b23d33023e6d45e018f6e84b683dd56efd8d","modified":1690698244427},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_header.styl","hash":"dafc6d23c80d6fe3e55a7711e94210d2479b629a","modified":1690698244391},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_header.styl","hash":"3fbfab591f280e2e7f3b0265901c93bc4bd137ed","modified":1690698244392},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_layout.styl","hash":"6569a6640f79d247a8235b3914772c0e2f99ead2","modified":1690698244393},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_menu.styl","hash":"fb550935d374e0bdf1097fce187337dc05cad3e1","modified":1690698244394},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_posts-expand.styl","hash":"485d23ccb42c0d0c8ead7ea8930dd3e06d79a285","modified":1690698244395},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_menu.styl","hash":"b7f48be3c43bfa393d62142544a5487a67871713","modified":1690698244394},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_sidebar.styl","hash":"547c0b5cd5e7ea10d21863d13a6b16579a49396c","modified":1690698244395},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1690698244396},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1690698244419},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_header.styl","hash":"ac2dc0ce9c775a83ef7132ae957b54539366ac9c","modified":1690698244393},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_sidebar.styl","hash":"91dbf3ca5c3a613d4e30618c120da535bf2d0336","modified":1690698244396},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_layout.styl","hash":"26a0cba1eee5de45a45a5e14e17707f905390512","modified":1690698244394},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_menu.styl","hash":"72dc825c50357402c342d62ab60fc0c478ab6bc1","modified":1690698244394},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"778ed2ad5643b93970c95626b325defeb586733f","modified":1690698244396},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1690698244197},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/index.styl","hash":"8000075b227749a7495eaf417cac6ccfbe441580","modified":1690698244419},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1690698244286},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1690698244287},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1690698244245},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1690698244284},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/matomo.js","hash":"c6a25b26a1443caa70b47fd3dfa282271574deb5","modified":1690698244308},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqusjs.js","hash":"1e826dea3f684c0515f362dc1352447a1f0eae71","modified":1690698244271},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqus.js","hash":"da361917d65e5dca8362f8cdeb6c8cc0e8316cec","modified":1690698244269},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1690698244240},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1690698244329},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1690698244283},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1690698244297},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1690698244304},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1690698244300},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1690698244332},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/algolia-search.js","hash":"fdb7b7cef1a147d897e7f7cd8903b58368ec2062","modified":1690698244178},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1690698244307},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/local-search.js","hash":"4536cb6d0a9bbaaa86fab3fa0101f6a3a3ec5a76","modified":1690698244305},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/firestore.js","hash":"6e0682bb42170d61b13b786295f45f9c785f8b73","modified":1690698244280},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/mermaid.js","hash":"6bf821310342c5b87a631873e7650a475a0765f1","modified":1690698244312},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/lean-analytics.js","hash":"835cbf54c49ef1327f47df70ff2636ad36b6f57d","modified":1690698244301},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1690698244324},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/bookmark.styl","hash":"e74f4bb47a101b014ee2a1783c87f3b87323f9a0","modified":1690698244405},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/github-banner.styl","hash":"38c64c2d04e46848382bfa246a0e9c508294767b","modified":1690698244411},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/wavedrom.js","hash":"40dcd10df6edf124088c329346e0cc0bdac74ef1","modified":1690698244337},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/footer/index.styl","hash":"4e967702cf4c637132346bc74ec8854426f1a68c","modified":1690698244415},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/site-nav.styl","hash":"bf3ad8b4268f763a1e26377681644887694bc009","modified":1690698244427},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/site-meta.styl","hash":"a851e9d5aefcd027c95eeb323860b6da70f202d1","modified":1690698244426},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/index.styl","hash":"6e0d0796ef7fbbb62ffdfb448753a850de82c74f","modified":1690698244415},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/index.styl","hash":"da5e88f8debd5ac8d7af5c6ba6240df66104955f","modified":1690698244416},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/related-posts.styl","hash":"b05908f04ef95f2d91e6eba89b12411c378d050f","modified":1690698244424},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/menu.styl","hash":"b750af2fb833c10c4313b5a4258237161a7833d7","modified":1690698244420},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"52fc98b1435129eb3edb9293ced9e507741f1350","modified":1690698244424},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"5b38ac4a0f1ade0e681aff0e3366c481d9cf3dcd","modified":1690698244424},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"c2e354a565c8c1b32bd0ceacc972b17982758b67","modified":1690698244425},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"24752d145c6fb8f5344dca9c7b9640839c02e009","modified":1690698244425},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"c6a27beb3f741211a14576026f3b4cfc44cc6407","modified":1690698244424},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"b926e368f702f8686aaa2eb98d3d2e533418958c","modified":1690698244424},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"9a7c71560fbdc936ad4e736fe15063ea3e8a644b","modified":1690698244426},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/site-state.styl","hash":"26dd0adfcb1db6df29c6090c8d7e9b5a43583fb0","modified":1690698244427},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/schedule.styl","hash":"6b816c2511242ee503fb5f34cd3e4dcdafc06b85","modified":1690698244424},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/categories.styl","hash":"b6e2eb1550a7845cb2adf86081a4ab6c7bde1e68","modified":1690698244406},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/breadcrumb.styl","hash":"8afdc311c6b8db121758371f95cf1c5e77354f42","modified":1690698244406},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/index.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1690698244412},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/tag-cloud.styl","hash":"1a81d1a71fcf0699629ce6e72dfd0a15f3a2dd0a","modified":1690698244428},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/index.styl","hash":"098d4bd034e986fcf7e443eac4fc2193935461b7","modified":1690698244413},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-footer.styl","hash":"11497388f124bfbb4001495a67d3629a9f618405","modified":1690698244422},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-body.styl","hash":"d757768a58743601d0d84158ba955eb15d4c3c01","modified":1690698244422},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-followme.styl","hash":"1ecfd64507954810b07a9d21fb5305b5378feda0","modified":1690698244422},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-collapse.styl","hash":"ec37a36e94ba791663607a5022f763915778578f","modified":1690698244422},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-gallery.styl","hash":"aa366d37389760c8595529b850f461569577a1c5","modified":1690698244423},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/disqusjs.styl","hash":"877a537d5b95beb048142e4fdee6f17e6ef9c7bb","modified":1690698244410},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-nav.styl","hash":"9ac6f477177264c26a46e8333b8456720a0444dc","modified":1690698244423},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-reward.styl","hash":"04cf4a69537fc14d3b8904f965d283356853847f","modified":1690698244423},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-header.styl","hash":"010c901e4ef49a606f8a350efbf09044e76d2ff3","modified":1690698244423},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/gitalk.styl","hash":"8f094c4ac17e2ab45569b12d157747f9c7333c12","modified":1690698244411},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-widgets.styl","hash":"ebfba158a0a4af3d1dabcacbc58986664de52140","modified":1690698244423},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/gitter.styl","hash":"35104dc6883a61c31e0e368dac8ac2f697be62fe","modified":1690698244411},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/index.styl","hash":"77550e0d3e029b7458e35d8c5ae1fbd612c9673b","modified":1690698244413},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/search.styl","hash":"e72799ce3f9b79753e365b2f8c8ef6c310668d4a","modified":1690698244424},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/utterances.styl","hash":"56d90ae0559caa55b75f3c300ff2711f9ed65fc4","modified":1690698244429},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/math.styl","hash":"9d995eb4871a6c273d9d51558676a1fdabf69e72","modified":1690698244419},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/highlight/index.styl","hash":"9056be572ec1cfa429abb22be4b45a662d5b0fb1","modified":1690698244417},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"393ff96234e4196b569d4b11496774eb78e147de","modified":1690698244411},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"d6418fd2bbfba7b73ddf11ec62db9637fdf5d8af","modified":1690698244402},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"670fc109b56a010b166b86b616823a1aae97a738","modified":1690698244409},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/index.styl","hash":"22cd37bd5df9972d5074710896aba4424ad5161c","modified":1690698244417},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/note.styl","hash":"98d4c20aff0f0fcfe1824017fb06ab21ef0d218e","modified":1690698244421},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/link-grid.styl","hash":"7f8a7345e6537a62cd9e9a94c8f7065b541d9b04","modified":1690698244419},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/mermaid.styl","hash":"48d35dba575a7c9e8845b16652e76b7d4a4646de","modified":1690698244420},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/label.styl","hash":"debee14539272fbe3835a7d3853af2230baa3501","modified":1690698244419},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/wavedrom.styl","hash":"af113411ad9cca7674177be36af8dd399680834d","modified":1690698244429},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b6654a1d7cf82577d8263faffee8af3ad4a5c0e8","modified":1690698244422},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/tabs.styl","hash":"7a39bcce7274284e87388743db62afc847fe6897","modified":1690698244428},{"_id":"source/images/logo.png","hash":"a7eef8fb65785db9e9368c8a2151cbe5eb82a22d","modified":1690697497254},{"_id":"source/images/avatar.png","hash":"ea7c8c561849dcceb2a8f9857c93fd308b9c4a16","modified":1690699973541},{"_id":"public/tags/index.html","hash":"ca8464b4959f9f6a92b1b3b74d1b7ddbe369e144","modified":1690700354121},{"_id":"public/categories/index.html","hash":"1f1ee093de8df407ce18e5e6b166ea52fe9a193c","modified":1690700354121},{"_id":"public/2023/07/30/activedirectory/Kerberos/index.html","hash":"303dfe3f3b9f5e874c532dfead62f306728b77e7","modified":1690700354121},{"_id":"public/2023/07/30/activedirectory/ESE源码分析/index.html","hash":"3bc083909820f75997385059190b78c1a0061004","modified":1690700354121},{"_id":"public/2023/07/30/activedirectory/utd_vector/index.html","hash":"a5833c46b0aab851bfed41d72f4b33c6dd22cb7b","modified":1690700354121},{"_id":"public/2023/07/30/interview/etcd 源码分析-raft/index.html","hash":"684a329c052f1735fd1ae3424b384da858b18894","modified":1690700354121},{"_id":"public/archives/index.html","hash":"76588dba63e095e1048ce59d1e49b4f4b1cf9c1e","modified":1690700354121},{"_id":"public/archives/page/2/index.html","hash":"1d49fe4ab45463407fd29ec95556dd2be7ea75fb","modified":1690700354121},{"_id":"public/archives/2023/index.html","hash":"102aa78434a4120604f6b39dcaf436cfc9056394","modified":1690700354121},{"_id":"public/archives/2023/page/2/index.html","hash":"9d4b6468e294650e425a91f36970c36fba38375e","modified":1690700354121},{"_id":"public/archives/2023/07/index.html","hash":"a08e71fed8f5fb38ebe537ea638c5a0a0b807247","modified":1690700354121},{"_id":"public/archives/2023/07/page/2/index.html","hash":"dfc95e9859e1592cefaea53d6a88d477f2a9401e","modified":1690700354121},{"_id":"public/tags/TBD/index.html","hash":"e110eeed8b7edf406e8ab8f24a078cd999a90e0d","modified":1690700354121},{"_id":"public/tags/数据库/index.html","hash":"536392c4a8ebc74a51fc41a037ced4075a0ded79","modified":1690700354121},{"_id":"public/tags/Paper-Reading/index.html","hash":"c842db3af353fcfb4c4a1ac36fd0219aa4c4a9d4","modified":1690700354121},{"_id":"public/tags/技术杂谈/index.html","hash":"7a343480519cc3bb2610a730852271ee0af29268","modified":1690700354121},{"_id":"public/tags/面试/index.html","hash":"91bfd5f66c738b53f6cebe358a07f1ff0783fb19","modified":1690700354121},{"_id":"public/tags/TiDB/index.html","hash":"20adc191d5b338477bf13ab5fa6827ff909080bb","modified":1690700354121},{"_id":"public/2023/07/30/tidb/store_interface/index.html","hash":"0925379814fe07c59ce2b721371629d41cd8a52a","modified":1690700354121},{"_id":"public/2023/07/30/tidb/optimize/index.html","hash":"19aab2479b2705ce21fdec64bddef209236e061b","modified":1690700354121},{"_id":"public/2023/07/30/papers/Oceanbase/index.html","hash":"8d9f5edc163f7e21cde84714761b15db7a15a531","modified":1690700354121},{"_id":"public/2023/07/30/interview/生产环境中的限流方案/index.html","hash":"45c5142f1bfb70bf533094565a9ca61705a2e743","modified":1690700354121},{"_id":"public/2023/07/30/tidb/opt_rule/index.html","hash":"8377133093d7578144c0fb150aec923286e814e1","modified":1690700354121},{"_id":"public/2023/07/30/activedirectory/什么是 AD/index.html","hash":"e697392ac8d9a6bdeeec50a67b0db2c593d9fb42","modified":1690700354121},{"_id":"public/2023/07/30/aosabook/bdb/index.html","hash":"80873c8b485656c1d4d8677e29b587c35393a59e","modified":1690700354121},{"_id":"public/2023/07/30/interview/常见数据结构的时间复杂度和空间复杂度/index.html","hash":"6681b72a3fd501449ee223f28f78b7cf06e95d8a","modified":1690700354121},{"_id":"public/2023/07/30/interview/数据库连接池设计/index.html","hash":"7ac0f7d33590fb81d8f2fd7c3a9e7c4fa41a3691","modified":1690700354121},{"_id":"public/2023/07/30/papers/Manu/index.html","hash":"8ad0725149873909924c66c0bd5cf592e6bc430e","modified":1690700354121},{"_id":"public/2023/07/30/papers/SQLite/index.html","hash":"dd49ddbff98aeabaacd142d81c472d76ac302435","modified":1690700354121},{"_id":"public/index.html","hash":"ffd3804b8099a3348188ec99afff5ba1244b292d","modified":1690700354121},{"_id":"public/page/2/index.html","hash":"11a7e2875dc4cb018d8849bdf39a47435c79688d","modified":1690700354121},{"_id":"public/tags/源码分析/index.html","hash":"9a0c12ed4ff0756523fa786c46b1c176de8de618","modified":1690700354121},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1690700354121},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1690700354121},{"_id":"public/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1690700354121},{"_id":"public/images/logo.svg","hash":"099e11ab995a2c8981427a85476d082609848c77","modified":1690700354121},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1690700354121},{"_id":"public/images/SQLite_Architecture.png","hash":"04b4266d3b866f3578e89908fe4354f0b0369269","modified":1690700354121},{"_id":"public/images/manu_index.png","hash":"d2352a9e83be39ef736f9faf8b9cb7f7479bb371","modified":1690700354121},{"_id":"public/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1690700354121},{"_id":"public/css/noscript.css","hash":"4cd5301e478e0e0d4b176740ec314087ec5cb707","modified":1690700354121},{"_id":"public/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1690700354121},{"_id":"public/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1690700354121},{"_id":"public/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1690700354121},{"_id":"public/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1690700354121},{"_id":"public/js/next-boot.js","hash":"da0f07f9eaaa83de70128b0feaea3fdadb90457a","modified":1690700354121},{"_id":"public/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1690700354121},{"_id":"public/js/motion.js","hash":"770d63c26f22705311028a36b52e999cc8a2da82","modified":1690700354121},{"_id":"public/js/schemes/muse.js","hash":"ba7ba2c129d1f240c6a22cec3e53f3f22af64b6b","modified":1690700354121},{"_id":"public/js/third-party/addtoany.js","hash":"5276c8f78ee562a8965216dc67d762e59cb4a9f2","modified":1690700354121},{"_id":"public/js/pjax.js","hash":"b03ba78c6916ad2f390d55bc1bc18fafb64b0ebf","modified":1690700354121},{"_id":"public/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1690700354121},{"_id":"public/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1690700354121},{"_id":"public/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1690700354121},{"_id":"public/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1690700354121},{"_id":"public/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1690700354121},{"_id":"public/js/third-party/analytics/matomo.js","hash":"c6a25b26a1443caa70b47fd3dfa282271574deb5","modified":1690700354121},{"_id":"public/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1690700354121},{"_id":"public/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1690700354121},{"_id":"public/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1690700354121},{"_id":"public/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1690700354121},{"_id":"public/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1690700354121},{"_id":"public/js/third-party/comments/disqusjs.js","hash":"1e826dea3f684c0515f362dc1352447a1f0eae71","modified":1690700354121},{"_id":"public/js/third-party/comments/disqus.js","hash":"da361917d65e5dca8362f8cdeb6c8cc0e8316cec","modified":1690700354121},{"_id":"public/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1690700354121},{"_id":"public/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1690700354121},{"_id":"public/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1690700354121},{"_id":"public/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1690700354121},{"_id":"public/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1690700354121},{"_id":"public/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1690700354121},{"_id":"public/js/third-party/search/algolia-search.js","hash":"fdb7b7cef1a147d897e7f7cd8903b58368ec2062","modified":1690700354121},{"_id":"public/js/third-party/search/local-search.js","hash":"4536cb6d0a9bbaaa86fab3fa0101f6a3a3ec5a76","modified":1690700354121},{"_id":"public/js/third-party/tags/mermaid.js","hash":"6bf821310342c5b87a631873e7650a475a0765f1","modified":1690700354121},{"_id":"public/js/third-party/statistics/firestore.js","hash":"6e0682bb42170d61b13b786295f45f9c785f8b73","modified":1690700354121},{"_id":"public/js/third-party/statistics/lean-analytics.js","hash":"835cbf54c49ef1327f47df70ff2636ad36b6f57d","modified":1690700354121},{"_id":"public/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1690700354121},{"_id":"public/js/third-party/tags/wavedrom.js","hash":"40dcd10df6edf124088c329346e0cc0bdac74ef1","modified":1690700354121},{"_id":"public/css/main.css","hash":"b16b649c54822d0fb7d4d5f4239759258fec5cec","modified":1690700354121},{"_id":"public/js/utils.js","hash":"5e1cf39de050964e97fb3ba0825aeec7f4bc36dd","modified":1690700354121},{"_id":"public/images/manu_grace_time.png","hash":"a568b575c790ad2cc32cddf63f9cdff3df9b765d","modified":1690700354121},{"_id":"public/images/manu_e_commer_real_traffic.png","hash":"ccfa57fae161ab248843c926341c4ac7269f895f","modified":1690700354121},{"_id":"public/images/manu_index_build.png","hash":"68340c5963012b770a4e5341c5d300fac4c6f527","modified":1690700354121},{"_id":"public/images/manu_log_system.png","hash":"4c83bcdfa00dff3ed4c59d73356311ce1cc43291","modified":1690700354121},{"_id":"public/images/manu_recommendation_recall.png","hash":"35c970e543d6fb42cef79c3e1aff0399b35ca4c9","modified":1690700354121},{"_id":"public/images/manu_arch.png","hash":"e6d219b1779663f0dd1227082913567a85a7a0af","modified":1690700354121},{"_id":"public/images/manu_query_node.png","hash":"50ed770380d54d3b4a1edcad535bc59a94137adf","modified":1690700354121},{"_id":"public/images/ob_arch.png","hash":"b4a9dddf8a799b21c9359d0d8297f24dd8fbf18c","modified":1690700354121},{"_id":"public/images/logo.png","hash":"a7eef8fb65785db9e9368c8a2151cbe5eb82a22d","modified":1690700354121},{"_id":"public/images/avatar.png","hash":"ea7c8c561849dcceb2a8f9857c93fd308b9c4a16","modified":1690700354121}],"Category":[],"Data":[],"Page":[{"title":"tags","date":"2023-07-30T05:46:28.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2023-07-30 13:46:28\ntype: tags\n---\n","updated":"2023-07-30T06:11:37.259Z","path":"tags/index.html","comments":1,"layout":"page","_id":"clkp3c6is00001ts1546w3g6n","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2023-07-30T05:49:33.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2023-07-30 13:49:33\ntype: categories\n---\n","updated":"2023-07-30T06:11:37.247Z","path":"categories/index.html","comments":1,"layout":"page","_id":"clkp3c6iu00021ts166amazbx","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Kerberos 详解","_content":"","source":"_posts/activedirectory/Kerberos.md","raw":"---\ntitle: Kerberos 详解\ntags:\n    - TBD\n---","slug":"activedirectory/Kerberos","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6is00011ts1fhspfo2b","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"ESE 源码分析","_content":"","source":"_posts/activedirectory/ESE源码分析.md","raw":"---\ntitle: ESE 源码分析\ntags:\n    - TBD\n---","slug":"activedirectory/ESE源码分析","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iu00031ts13l9d2cup","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"AD的 replication","_content":"","source":"_posts/activedirectory/utd_vector.md","raw":"---\ntitle: AD的 replication\ntags:\n    - TBD\n---","slug":"activedirectory/utd_vector","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iv00051ts19qdl93x6","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Active Directory 介绍","_content":"\n其实我们真的是个数据库。\n\n<!-- more -->\n\n每次和朋友聊到我们使用的数据库，他们都会一脸问号。什么是 [Active Directory(AD)](https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/get-started/virtual-dc/active-directory-domain-services-overview)？AD 不是用来做权限管理的吗？每次我都要解释，我们是一个非关系型数据库，是构建在 ESE 引擎上，支持 LDAP 协议的一个数据库，数据的逻辑视图是树形层次结构的。其实我自己对 AD 的了解也仅限与此，更多一点，可能知道AD 可以提供 DNS 服务，可以提供 Kerberos 验证。今天这篇文章，我就大概先讲一下什么是 AD，内容会有一些中英夹杂，因为很多单词翻译出来和我在工作中的表达方式有所不同，翻译之后会略显生硬，所以使用英文以保留其原意。\n\n维基百科对 AD 的解释是[“Active Directory (AD) is a directory service developed by Microsoft for Windows domain networks. ”](https://en.wikipedia.org/wiki/Active_Directory)。Directory 是一种存储网络对象的层次结构。Directory Service提供了一套存储访问 directory数据的方法，让这些数据能够被网络用户和管理员访问到。\n\nAD 里面存储这各种各样的数据，比如服务器、打印机、网络用户、计算机账户等各种数据。AD 提供了安全的方式（登录验证、访问控制）让用户来访问这些数据。\n\n接下来我们从几个方面讲一下 AD：\n\n- AD 的整体结构\n- AD 里有哪些角色\n- AD 的 schema是什么\n- AD 如何存储和访问数据\n\n## AD 的整体结构\n\n从存储结构来讲，AD 里面主要包含四个部分：\n\n- AD 的 domain 和 forest。forest 是 AD 里面的安全边界，domain、forest 和 organizational unit 是 AD 逻辑结构的核心元素\n- DNS。AD 还提供了DNS 域名解析服务\n- Schema。数据的 schema\n- Data store. 负责 AD 里面的数据存储和检索。\n\n![Active Directory Data Structure and Storage Architecture](https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/images/cc759186.ccf65c10-edb1-4a3a-ad87-38775ee43b8a(ws.10).gif)\n\n在 forest 下面还有 domain，domain 可以把 forest 中的数据几家看进一步的分割，这样可以更灵活地控制数据的复制同步，这部分我们在下次可以详细讲一下。而 OU 则可以将 domain 下的资源进一步分割，便于更加灵活的管理。下面这张图是forest、domain、OU 的逻辑结构\n\n![Logical Structure Architecture](https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/image2s/cc759186.a55b8656-0958-4681-88bd-86a6f27a4451(ws.10).gif)\n\n## AD的角色\n通常来讲，一个安装有 AD 服务的windows 服务器就被称为一个 domain controller，简称 DC。正常来说，DC 上面存有其所在 domain下面一个 domain partition的所有数据。事实上一台 DC 可以保存一个或者多个 domain partition。其实有一些DC会扮演特殊的角色，提供一些特殊的功能，主要分两大类，一是 Global Catalog Server，另外就是各种 Operation Master。\n\n首先我们来看看 Global Catalog Server，简称 GC。如上文所说，一个 DC 里面存有其所在 domain 里面的所有数据，而 GC 则活跃在 forest 层面。G 上一般保存着它自己所在 domain 的所有的可写的 replica 数据，和部分forest 内其他 domain 的可读数据。GC 里面的数据由 AD 的 replication 机制来自动复制。这些可读数据可以用来搜索到对应的对象。可读数据一般是一个 object 的某些 attribute，这个可以通过修改 schema 来进行配置。一般来讲，一个 forest 里面的第一台 DC 会被自动配置成 GC，在加入更多DC 之后，我们也可以指定其他 DC 来作为 GC。\n\n另一类就是各种 master 了，这些 master 负责执行一些任务来保证特定数据的一致性。AD 的 master 主要有五个：schema master、domain naming master、relative identifier（RID）master、primary domain controller（PDC）emulateor 和 infrastructure master。我们把它们叫做 FSMO(Flexible Single Master Operation) roles。\n\nAD 是一个多主数据库，非常灵活，我们可以在 forest 里任何一台 dc 上做数据的更新，但是，这同样也导致了一些数据冲突的产生。AD 可以通过比较版本号和时间戳的方式来解决一些冲突，但是有时候也会出现无法解决冲突的情况。所以在执行一些特殊的操作，比如说 domain 的添加和删除、或者密码修改的时候，AD 会以一种单主的方式来运行。在单主模式下，只有一台 DC 被允许执行更新的过程。上面提到的各种 master 就是在这个时候用到，用来负责处理不同类型的更新。\n\n下面讲一下不同的 master 的职责:\n\n- Schema master。顾名思义，这个角色主要是为了处理一些 schema 上的更新。schema 的更新只能发生在拥有这个角色的机器上，更新完成后被复制到其他的 DC 上。\n- Domain naming master。这个角色负责处理 forest 范围内的 domain 更新。\n- RID master。负责处理来自domain 下所有 DC 的 RID Pool 请求。当 DC 创建一个安全主体对象（用户或者组）时，它会给这个对象一个唯一的 Security ID(SID)，SID 由两部分组成，一部分是 domain SID，用于区分 domain，另一部分则是一个 relative ID(RID)，用于区分 domain 下的对象。domain 下的每个 DC 都有一个 RID pool，用于给自己创建的对象赋予一个 RID，当 一个 DC 的RID pool 剩余的RID 不够时，会向 domain 的 RID master 申请额外的 RID。每一个 domain 下面有且只有一个 RID master。\n- PDC emulator。这个角色主要负责同步时间。Kerberos 协议需要基于时间戳实现，整个组织内部的时间按照层次结构来逐层同步，这个 role 就是整个时间同步结构的根，它会从外部数据源同步时间。在 windows domain 下，这个角色同样还承担着一些其他和 auth相关的功能。\n- Infrastructure master。这个角色主要负责更新 object 在跨 domain 对象引用中的 SID 和 DN。\n\n## AD 的 schema 是什么\nAD 里面的数据是以对象为单位来进行存储的。Schema 就是这些对象的格式，我们在存储一个对象之前，需要将这个对象的格式定义在 AD 的 schema 中，每个对象由许多不同的属性组成，比如 name、guid、whenCreated、whenChanged等等。这个有点类似于关系数据库里面对表结构的定义，但是又略有不同。也可以理解为一个 mongoDB，但是里面所有 object 的结构都是预先定义好的。\n\n## AD 如何存储和访问数据\nAD 使用 LDAP 协议来访问数据，在执行搜索时，通过指定 search base，可以将查询范围限定在层次结构的某个对象之下，通过 LDAP filter可以指定对应的查询条件。\n\nAD 的数据存储在 ESE database中，ESE 全称 Extensible Storage Engine(ESE)，也叫 JET Blue。某种程度上，AD 就是一个访问 ESE 数据库的客户端，以存储计算的方式来分层的话，AD 相当于一个计算层，ESE 作为存储层。AD 还会提供 replication 的能力，将数据在一个 forest 内互相复制、同步。从数据库的架构角度来说，AD 属于 Shared Everything 的结构，不同节点之间并不共享任何计算和存储的资源。与 MySQL等其他数据库类似，ESE 底层使用 B+树组织所有的数据。\n\n之后我会写几篇文章详细介绍AD 的复制同步和存储是如何实现的。","source":"_posts/activedirectory/什么是 AD.md","raw":"---\ntitle: Active Directory 介绍\ntags:\n    - 数据库\n---\n\n其实我们真的是个数据库。\n\n<!-- more -->\n\n每次和朋友聊到我们使用的数据库，他们都会一脸问号。什么是 [Active Directory(AD)](https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/get-started/virtual-dc/active-directory-domain-services-overview)？AD 不是用来做权限管理的吗？每次我都要解释，我们是一个非关系型数据库，是构建在 ESE 引擎上，支持 LDAP 协议的一个数据库，数据的逻辑视图是树形层次结构的。其实我自己对 AD 的了解也仅限与此，更多一点，可能知道AD 可以提供 DNS 服务，可以提供 Kerberos 验证。今天这篇文章，我就大概先讲一下什么是 AD，内容会有一些中英夹杂，因为很多单词翻译出来和我在工作中的表达方式有所不同，翻译之后会略显生硬，所以使用英文以保留其原意。\n\n维基百科对 AD 的解释是[“Active Directory (AD) is a directory service developed by Microsoft for Windows domain networks. ”](https://en.wikipedia.org/wiki/Active_Directory)。Directory 是一种存储网络对象的层次结构。Directory Service提供了一套存储访问 directory数据的方法，让这些数据能够被网络用户和管理员访问到。\n\nAD 里面存储这各种各样的数据，比如服务器、打印机、网络用户、计算机账户等各种数据。AD 提供了安全的方式（登录验证、访问控制）让用户来访问这些数据。\n\n接下来我们从几个方面讲一下 AD：\n\n- AD 的整体结构\n- AD 里有哪些角色\n- AD 的 schema是什么\n- AD 如何存储和访问数据\n\n## AD 的整体结构\n\n从存储结构来讲，AD 里面主要包含四个部分：\n\n- AD 的 domain 和 forest。forest 是 AD 里面的安全边界，domain、forest 和 organizational unit 是 AD 逻辑结构的核心元素\n- DNS。AD 还提供了DNS 域名解析服务\n- Schema。数据的 schema\n- Data store. 负责 AD 里面的数据存储和检索。\n\n![Active Directory Data Structure and Storage Architecture](https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/images/cc759186.ccf65c10-edb1-4a3a-ad87-38775ee43b8a(ws.10).gif)\n\n在 forest 下面还有 domain，domain 可以把 forest 中的数据几家看进一步的分割，这样可以更灵活地控制数据的复制同步，这部分我们在下次可以详细讲一下。而 OU 则可以将 domain 下的资源进一步分割，便于更加灵活的管理。下面这张图是forest、domain、OU 的逻辑结构\n\n![Logical Structure Architecture](https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/image2s/cc759186.a55b8656-0958-4681-88bd-86a6f27a4451(ws.10).gif)\n\n## AD的角色\n通常来讲，一个安装有 AD 服务的windows 服务器就被称为一个 domain controller，简称 DC。正常来说，DC 上面存有其所在 domain下面一个 domain partition的所有数据。事实上一台 DC 可以保存一个或者多个 domain partition。其实有一些DC会扮演特殊的角色，提供一些特殊的功能，主要分两大类，一是 Global Catalog Server，另外就是各种 Operation Master。\n\n首先我们来看看 Global Catalog Server，简称 GC。如上文所说，一个 DC 里面存有其所在 domain 里面的所有数据，而 GC 则活跃在 forest 层面。G 上一般保存着它自己所在 domain 的所有的可写的 replica 数据，和部分forest 内其他 domain 的可读数据。GC 里面的数据由 AD 的 replication 机制来自动复制。这些可读数据可以用来搜索到对应的对象。可读数据一般是一个 object 的某些 attribute，这个可以通过修改 schema 来进行配置。一般来讲，一个 forest 里面的第一台 DC 会被自动配置成 GC，在加入更多DC 之后，我们也可以指定其他 DC 来作为 GC。\n\n另一类就是各种 master 了，这些 master 负责执行一些任务来保证特定数据的一致性。AD 的 master 主要有五个：schema master、domain naming master、relative identifier（RID）master、primary domain controller（PDC）emulateor 和 infrastructure master。我们把它们叫做 FSMO(Flexible Single Master Operation) roles。\n\nAD 是一个多主数据库，非常灵活，我们可以在 forest 里任何一台 dc 上做数据的更新，但是，这同样也导致了一些数据冲突的产生。AD 可以通过比较版本号和时间戳的方式来解决一些冲突，但是有时候也会出现无法解决冲突的情况。所以在执行一些特殊的操作，比如说 domain 的添加和删除、或者密码修改的时候，AD 会以一种单主的方式来运行。在单主模式下，只有一台 DC 被允许执行更新的过程。上面提到的各种 master 就是在这个时候用到，用来负责处理不同类型的更新。\n\n下面讲一下不同的 master 的职责:\n\n- Schema master。顾名思义，这个角色主要是为了处理一些 schema 上的更新。schema 的更新只能发生在拥有这个角色的机器上，更新完成后被复制到其他的 DC 上。\n- Domain naming master。这个角色负责处理 forest 范围内的 domain 更新。\n- RID master。负责处理来自domain 下所有 DC 的 RID Pool 请求。当 DC 创建一个安全主体对象（用户或者组）时，它会给这个对象一个唯一的 Security ID(SID)，SID 由两部分组成，一部分是 domain SID，用于区分 domain，另一部分则是一个 relative ID(RID)，用于区分 domain 下的对象。domain 下的每个 DC 都有一个 RID pool，用于给自己创建的对象赋予一个 RID，当 一个 DC 的RID pool 剩余的RID 不够时，会向 domain 的 RID master 申请额外的 RID。每一个 domain 下面有且只有一个 RID master。\n- PDC emulator。这个角色主要负责同步时间。Kerberos 协议需要基于时间戳实现，整个组织内部的时间按照层次结构来逐层同步，这个 role 就是整个时间同步结构的根，它会从外部数据源同步时间。在 windows domain 下，这个角色同样还承担着一些其他和 auth相关的功能。\n- Infrastructure master。这个角色主要负责更新 object 在跨 domain 对象引用中的 SID 和 DN。\n\n## AD 的 schema 是什么\nAD 里面的数据是以对象为单位来进行存储的。Schema 就是这些对象的格式，我们在存储一个对象之前，需要将这个对象的格式定义在 AD 的 schema 中，每个对象由许多不同的属性组成，比如 name、guid、whenCreated、whenChanged等等。这个有点类似于关系数据库里面对表结构的定义，但是又略有不同。也可以理解为一个 mongoDB，但是里面所有 object 的结构都是预先定义好的。\n\n## AD 如何存储和访问数据\nAD 使用 LDAP 协议来访问数据，在执行搜索时，通过指定 search base，可以将查询范围限定在层次结构的某个对象之下，通过 LDAP filter可以指定对应的查询条件。\n\nAD 的数据存储在 ESE database中，ESE 全称 Extensible Storage Engine(ESE)，也叫 JET Blue。某种程度上，AD 就是一个访问 ESE 数据库的客户端，以存储计算的方式来分层的话，AD 相当于一个计算层，ESE 作为存储层。AD 还会提供 replication 的能力，将数据在一个 forest 内互相复制、同步。从数据库的架构角度来说，AD 属于 Shared Everything 的结构，不同节点之间并不共享任何计算和存储的资源。与 MySQL等其他数据库类似，ESE 底层使用 B+树组织所有的数据。\n\n之后我会写几篇文章详细介绍AD 的复制同步和存储是如何实现的。","slug":"activedirectory/什么是 AD","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iv00061ts117rtfzcu","content":"<p>其实我们真的是个数据库。</p>\n<span id=\"more\"></span>\n\n<p>每次和朋友聊到我们使用的数据库，他们都会一脸问号。什么是 <a href=\"https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/get-started/virtual-dc/active-directory-domain-services-overview\">Active Directory(AD)</a>？AD 不是用来做权限管理的吗？每次我都要解释，我们是一个非关系型数据库，是构建在 ESE 引擎上，支持 LDAP 协议的一个数据库，数据的逻辑视图是树形层次结构的。其实我自己对 AD 的了解也仅限与此，更多一点，可能知道AD 可以提供 DNS 服务，可以提供 Kerberos 验证。今天这篇文章，我就大概先讲一下什么是 AD，内容会有一些中英夹杂，因为很多单词翻译出来和我在工作中的表达方式有所不同，翻译之后会略显生硬，所以使用英文以保留其原意。</p>\n<p>维基百科对 AD 的解释是<a href=\"https://en.wikipedia.org/wiki/Active_Directory\">“Active Directory (AD) is a directory service developed by Microsoft for Windows domain networks. ”</a>。Directory 是一种存储网络对象的层次结构。Directory Service提供了一套存储访问 directory数据的方法，让这些数据能够被网络用户和管理员访问到。</p>\n<p>AD 里面存储这各种各样的数据，比如服务器、打印机、网络用户、计算机账户等各种数据。AD 提供了安全的方式（登录验证、访问控制）让用户来访问这些数据。</p>\n<p>接下来我们从几个方面讲一下 AD：</p>\n<ul>\n<li>AD 的整体结构</li>\n<li>AD 里有哪些角色</li>\n<li>AD 的 schema是什么</li>\n<li>AD 如何存储和访问数据</li>\n</ul>\n<h2 id=\"AD-的整体结构\"><a href=\"#AD-的整体结构\" class=\"headerlink\" title=\"AD 的整体结构\"></a>AD 的整体结构</h2><p>从存储结构来讲，AD 里面主要包含四个部分：</p>\n<ul>\n<li>AD 的 domain 和 forest。forest 是 AD 里面的安全边界，domain、forest 和 organizational unit 是 AD 逻辑结构的核心元素</li>\n<li>DNS。AD 还提供了DNS 域名解析服务</li>\n<li>Schema。数据的 schema</li>\n<li>Data store. 负责 AD 里面的数据存储和检索。</li>\n</ul>\n<p><img src=\"https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/images/cc759186.ccf65c10-edb1-4a3a-ad87-38775ee43b8a(ws.10).gif\" alt=\"Active Directory Data Structure and Storage Architecture\"></p>\n<p>在 forest 下面还有 domain，domain 可以把 forest 中的数据几家看进一步的分割，这样可以更灵活地控制数据的复制同步，这部分我们在下次可以详细讲一下。而 OU 则可以将 domain 下的资源进一步分割，便于更加灵活的管理。下面这张图是forest、domain、OU 的逻辑结构</p>\n<p><img src=\"https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/image2s/cc759186.a55b8656-0958-4681-88bd-86a6f27a4451(ws.10).gif\" alt=\"Logical Structure Architecture\"></p>\n<h2 id=\"AD的角色\"><a href=\"#AD的角色\" class=\"headerlink\" title=\"AD的角色\"></a>AD的角色</h2><p>通常来讲，一个安装有 AD 服务的windows 服务器就被称为一个 domain controller，简称 DC。正常来说，DC 上面存有其所在 domain下面一个 domain partition的所有数据。事实上一台 DC 可以保存一个或者多个 domain partition。其实有一些DC会扮演特殊的角色，提供一些特殊的功能，主要分两大类，一是 Global Catalog Server，另外就是各种 Operation Master。</p>\n<p>首先我们来看看 Global Catalog Server，简称 GC。如上文所说，一个 DC 里面存有其所在 domain 里面的所有数据，而 GC 则活跃在 forest 层面。G 上一般保存着它自己所在 domain 的所有的可写的 replica 数据，和部分forest 内其他 domain 的可读数据。GC 里面的数据由 AD 的 replication 机制来自动复制。这些可读数据可以用来搜索到对应的对象。可读数据一般是一个 object 的某些 attribute，这个可以通过修改 schema 来进行配置。一般来讲，一个 forest 里面的第一台 DC 会被自动配置成 GC，在加入更多DC 之后，我们也可以指定其他 DC 来作为 GC。</p>\n<p>另一类就是各种 master 了，这些 master 负责执行一些任务来保证特定数据的一致性。AD 的 master 主要有五个：schema master、domain naming master、relative identifier（RID）master、primary domain controller（PDC）emulateor 和 infrastructure master。我们把它们叫做 FSMO(Flexible Single Master Operation) roles。</p>\n<p>AD 是一个多主数据库，非常灵活，我们可以在 forest 里任何一台 dc 上做数据的更新，但是，这同样也导致了一些数据冲突的产生。AD 可以通过比较版本号和时间戳的方式来解决一些冲突，但是有时候也会出现无法解决冲突的情况。所以在执行一些特殊的操作，比如说 domain 的添加和删除、或者密码修改的时候，AD 会以一种单主的方式来运行。在单主模式下，只有一台 DC 被允许执行更新的过程。上面提到的各种 master 就是在这个时候用到，用来负责处理不同类型的更新。</p>\n<p>下面讲一下不同的 master 的职责:</p>\n<ul>\n<li>Schema master。顾名思义，这个角色主要是为了处理一些 schema 上的更新。schema 的更新只能发生在拥有这个角色的机器上，更新完成后被复制到其他的 DC 上。</li>\n<li>Domain naming master。这个角色负责处理 forest 范围内的 domain 更新。</li>\n<li>RID master。负责处理来自domain 下所有 DC 的 RID Pool 请求。当 DC 创建一个安全主体对象（用户或者组）时，它会给这个对象一个唯一的 Security ID(SID)，SID 由两部分组成，一部分是 domain SID，用于区分 domain，另一部分则是一个 relative ID(RID)，用于区分 domain 下的对象。domain 下的每个 DC 都有一个 RID pool，用于给自己创建的对象赋予一个 RID，当 一个 DC 的RID pool 剩余的RID 不够时，会向 domain 的 RID master 申请额外的 RID。每一个 domain 下面有且只有一个 RID master。</li>\n<li>PDC emulator。这个角色主要负责同步时间。Kerberos 协议需要基于时间戳实现，整个组织内部的时间按照层次结构来逐层同步，这个 role 就是整个时间同步结构的根，它会从外部数据源同步时间。在 windows domain 下，这个角色同样还承担着一些其他和 auth相关的功能。</li>\n<li>Infrastructure master。这个角色主要负责更新 object 在跨 domain 对象引用中的 SID 和 DN。</li>\n</ul>\n<h2 id=\"AD-的-schema-是什么\"><a href=\"#AD-的-schema-是什么\" class=\"headerlink\" title=\"AD 的 schema 是什么\"></a>AD 的 schema 是什么</h2><p>AD 里面的数据是以对象为单位来进行存储的。Schema 就是这些对象的格式，我们在存储一个对象之前，需要将这个对象的格式定义在 AD 的 schema 中，每个对象由许多不同的属性组成，比如 name、guid、whenCreated、whenChanged等等。这个有点类似于关系数据库里面对表结构的定义，但是又略有不同。也可以理解为一个 mongoDB，但是里面所有 object 的结构都是预先定义好的。</p>\n<h2 id=\"AD-如何存储和访问数据\"><a href=\"#AD-如何存储和访问数据\" class=\"headerlink\" title=\"AD 如何存储和访问数据\"></a>AD 如何存储和访问数据</h2><p>AD 使用 LDAP 协议来访问数据，在执行搜索时，通过指定 search base，可以将查询范围限定在层次结构的某个对象之下，通过 LDAP filter可以指定对应的查询条件。</p>\n<p>AD 的数据存储在 ESE database中，ESE 全称 Extensible Storage Engine(ESE)，也叫 JET Blue。某种程度上，AD 就是一个访问 ESE 数据库的客户端，以存储计算的方式来分层的话，AD 相当于一个计算层，ESE 作为存储层。AD 还会提供 replication 的能力，将数据在一个 forest 内互相复制、同步。从数据库的架构角度来说，AD 属于 Shared Everything 的结构，不同节点之间并不共享任何计算和存储的资源。与 MySQL等其他数据库类似，ESE 底层使用 B+树组织所有的数据。</p>\n<p>之后我会写几篇文章详细介绍AD 的复制同步和存储是如何实现的。</p>\n","site":{"data":{}},"excerpt":"<p>其实我们真的是个数据库。</p>","more":"<p>每次和朋友聊到我们使用的数据库，他们都会一脸问号。什么是 <a href=\"https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/get-started/virtual-dc/active-directory-domain-services-overview\">Active Directory(AD)</a>？AD 不是用来做权限管理的吗？每次我都要解释，我们是一个非关系型数据库，是构建在 ESE 引擎上，支持 LDAP 协议的一个数据库，数据的逻辑视图是树形层次结构的。其实我自己对 AD 的了解也仅限与此，更多一点，可能知道AD 可以提供 DNS 服务，可以提供 Kerberos 验证。今天这篇文章，我就大概先讲一下什么是 AD，内容会有一些中英夹杂，因为很多单词翻译出来和我在工作中的表达方式有所不同，翻译之后会略显生硬，所以使用英文以保留其原意。</p>\n<p>维基百科对 AD 的解释是<a href=\"https://en.wikipedia.org/wiki/Active_Directory\">“Active Directory (AD) is a directory service developed by Microsoft for Windows domain networks. ”</a>。Directory 是一种存储网络对象的层次结构。Directory Service提供了一套存储访问 directory数据的方法，让这些数据能够被网络用户和管理员访问到。</p>\n<p>AD 里面存储这各种各样的数据，比如服务器、打印机、网络用户、计算机账户等各种数据。AD 提供了安全的方式（登录验证、访问控制）让用户来访问这些数据。</p>\n<p>接下来我们从几个方面讲一下 AD：</p>\n<ul>\n<li>AD 的整体结构</li>\n<li>AD 里有哪些角色</li>\n<li>AD 的 schema是什么</li>\n<li>AD 如何存储和访问数据</li>\n</ul>\n<h2 id=\"AD-的整体结构\"><a href=\"#AD-的整体结构\" class=\"headerlink\" title=\"AD 的整体结构\"></a>AD 的整体结构</h2><p>从存储结构来讲，AD 里面主要包含四个部分：</p>\n<ul>\n<li>AD 的 domain 和 forest。forest 是 AD 里面的安全边界，domain、forest 和 organizational unit 是 AD 逻辑结构的核心元素</li>\n<li>DNS。AD 还提供了DNS 域名解析服务</li>\n<li>Schema。数据的 schema</li>\n<li>Data store. 负责 AD 里面的数据存储和检索。</li>\n</ul>\n<p><img src=\"https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/images/cc759186.ccf65c10-edb1-4a3a-ad87-38775ee43b8a(ws.10).gif\" alt=\"Active Directory Data Structure and Storage Architecture\"></p>\n<p>在 forest 下面还有 domain，domain 可以把 forest 中的数据几家看进一步的分割，这样可以更灵活地控制数据的复制同步，这部分我们在下次可以详细讲一下。而 OU 则可以将 domain 下的资源进一步分割，便于更加灵活的管理。下面这张图是forest、domain、OU 的逻辑结构</p>\n<p><img src=\"https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/image2s/cc759186.a55b8656-0958-4681-88bd-86a6f27a4451(ws.10).gif\" alt=\"Logical Structure Architecture\"></p>\n<h2 id=\"AD的角色\"><a href=\"#AD的角色\" class=\"headerlink\" title=\"AD的角色\"></a>AD的角色</h2><p>通常来讲，一个安装有 AD 服务的windows 服务器就被称为一个 domain controller，简称 DC。正常来说，DC 上面存有其所在 domain下面一个 domain partition的所有数据。事实上一台 DC 可以保存一个或者多个 domain partition。其实有一些DC会扮演特殊的角色，提供一些特殊的功能，主要分两大类，一是 Global Catalog Server，另外就是各种 Operation Master。</p>\n<p>首先我们来看看 Global Catalog Server，简称 GC。如上文所说，一个 DC 里面存有其所在 domain 里面的所有数据，而 GC 则活跃在 forest 层面。G 上一般保存着它自己所在 domain 的所有的可写的 replica 数据，和部分forest 内其他 domain 的可读数据。GC 里面的数据由 AD 的 replication 机制来自动复制。这些可读数据可以用来搜索到对应的对象。可读数据一般是一个 object 的某些 attribute，这个可以通过修改 schema 来进行配置。一般来讲，一个 forest 里面的第一台 DC 会被自动配置成 GC，在加入更多DC 之后，我们也可以指定其他 DC 来作为 GC。</p>\n<p>另一类就是各种 master 了，这些 master 负责执行一些任务来保证特定数据的一致性。AD 的 master 主要有五个：schema master、domain naming master、relative identifier（RID）master、primary domain controller（PDC）emulateor 和 infrastructure master。我们把它们叫做 FSMO(Flexible Single Master Operation) roles。</p>\n<p>AD 是一个多主数据库，非常灵活，我们可以在 forest 里任何一台 dc 上做数据的更新，但是，这同样也导致了一些数据冲突的产生。AD 可以通过比较版本号和时间戳的方式来解决一些冲突，但是有时候也会出现无法解决冲突的情况。所以在执行一些特殊的操作，比如说 domain 的添加和删除、或者密码修改的时候，AD 会以一种单主的方式来运行。在单主模式下，只有一台 DC 被允许执行更新的过程。上面提到的各种 master 就是在这个时候用到，用来负责处理不同类型的更新。</p>\n<p>下面讲一下不同的 master 的职责:</p>\n<ul>\n<li>Schema master。顾名思义，这个角色主要是为了处理一些 schema 上的更新。schema 的更新只能发生在拥有这个角色的机器上，更新完成后被复制到其他的 DC 上。</li>\n<li>Domain naming master。这个角色负责处理 forest 范围内的 domain 更新。</li>\n<li>RID master。负责处理来自domain 下所有 DC 的 RID Pool 请求。当 DC 创建一个安全主体对象（用户或者组）时，它会给这个对象一个唯一的 Security ID(SID)，SID 由两部分组成，一部分是 domain SID，用于区分 domain，另一部分则是一个 relative ID(RID)，用于区分 domain 下的对象。domain 下的每个 DC 都有一个 RID pool，用于给自己创建的对象赋予一个 RID，当 一个 DC 的RID pool 剩余的RID 不够时，会向 domain 的 RID master 申请额外的 RID。每一个 domain 下面有且只有一个 RID master。</li>\n<li>PDC emulator。这个角色主要负责同步时间。Kerberos 协议需要基于时间戳实现，整个组织内部的时间按照层次结构来逐层同步，这个 role 就是整个时间同步结构的根，它会从外部数据源同步时间。在 windows domain 下，这个角色同样还承担着一些其他和 auth相关的功能。</li>\n<li>Infrastructure master。这个角色主要负责更新 object 在跨 domain 对象引用中的 SID 和 DN。</li>\n</ul>\n<h2 id=\"AD-的-schema-是什么\"><a href=\"#AD-的-schema-是什么\" class=\"headerlink\" title=\"AD 的 schema 是什么\"></a>AD 的 schema 是什么</h2><p>AD 里面的数据是以对象为单位来进行存储的。Schema 就是这些对象的格式，我们在存储一个对象之前，需要将这个对象的格式定义在 AD 的 schema 中，每个对象由许多不同的属性组成，比如 name、guid、whenCreated、whenChanged等等。这个有点类似于关系数据库里面对表结构的定义，但是又略有不同。也可以理解为一个 mongoDB，但是里面所有 object 的结构都是预先定义好的。</p>\n<h2 id=\"AD-如何存储和访问数据\"><a href=\"#AD-如何存储和访问数据\" class=\"headerlink\" title=\"AD 如何存储和访问数据\"></a>AD 如何存储和访问数据</h2><p>AD 使用 LDAP 协议来访问数据，在执行搜索时，通过指定 search base，可以将查询范围限定在层次结构的某个对象之下，通过 LDAP filter可以指定对应的查询条件。</p>\n<p>AD 的数据存储在 ESE database中，ESE 全称 Extensible Storage Engine(ESE)，也叫 JET Blue。某种程度上，AD 就是一个访问 ESE 数据库的客户端，以存储计算的方式来分层的话，AD 相当于一个计算层，ESE 作为存储层。AD 还会提供 replication 的能力，将数据在一个 forest 内互相复制、同步。从数据库的架构角度来说，AD 属于 Shared Everything 的结构，不同节点之间并不共享任何计算和存储的资源。与 MySQL等其他数据库类似，ESE 底层使用 B+树组织所有的数据。</p>\n<p>之后我会写几篇文章详细介绍AD 的复制同步和存储是如何实现的。</p>"},{"title":"(Paper Reading) Manu: A Cloud Native Vector Database Management System","_content":"\n时隔几周，又来更新了。这几周时间比较碎片，没有找到比较好的机会写文。话不多说，开整。\n\n<!-- more -->\n\n今天这篇文章是还是 VLDB 上的一篇文章，主要讲了 OceanBase 的整体架构和设计经验。主要包括 OceanBase 的设计目标、设计标准、整体架构、关键组件以及相关的设计经验。主要分成下面五个部分，这篇文章也主要从这五个部分来展开：\n- OB 的设计目标和标准、系统架构、SQL 引擎以及多租户实现\n- OB 使用的基于 LSM tree 的存储引擎、非对称读写设计、增量压缩和副本类型等\n- OB 的事务处理引擎、隔离级别和复制表\n- TPC-C benchmark test。这个噱头十足，等下可以仔细看看。\n- 构建 OB 过程中的设计经验\n\n从技术选型来看，OB 使用了分布式数据库系统中常用的一些技术：LSM tree、Paxos等等，当然这部分各种分布式数据库的实现都是大同小异，没有最完美的设计，只有尽可能贴近当前业务场景的Best Practice。\n\n老规矩看下 chatGPT 怎么说。\n\n```\nOceanBase是由中国阿里巴巴集团开发的分布式关系型数据库系统。它是阿里巴巴公司的自主研发项目之一，旨在满足其海量数据存储和高并发访问的需求。OceanBase在设计上借鉴了Google的Spanner和F1等分布式数据库系统的一些思想。\n\n主要特点和优势：\n\n1. 分布式架构：OceanBase是一个分布式数据库系统，它将数据划分成多个分片并在多台服务器上存储，以实现数据的高可用性和可扩展性。\n\n2. ACID事务支持：OceanBase支持ACID（原子性、一致性、隔离性和持久性）事务，这意味着它可以保证数据在并发环境下的一致性和完整性。\n\n3. 高并发读写：作为用于大规模在线服务的数据库系统，OceanBase被设计为能够处理高并发读写请求，满足对海量数据的实时访问需求。\n\n4. 水平扩展：OceanBase可以通过添加更多的节点来实现水平扩展，以应对数据量和访问量的增长。\n\n5. 多租户支持：OceanBase支持多租户架构，允许将不同的应用和用户隔离在不同的数据库实例中，提供更好的安全性和资源隔离。\n\n6. 多数据模型支持：除了关系型数据模型，OceanBase还支持存储非结构化数据和半结构化数据，使其能够适应不同类型的应用场景。\n```\n\n## 整体设计\nOB 的设计目标是为了在商用级硬件上构建可快速伸缩的高性能、低成本数据库，需要满足可跨区域部署、错误容忍等需求，OB 需要兼容常见的主流数据库，这也和设计 OB 时的时代背景有关，如果没记错应该是在 10 年前后，当时国内也没有像现在一样百花齐放，淘宝当时使用的主要还是 Oracle、MySQL 之类的数据库产品。（这个时间点我刚上大学，完全没有意识到波澜壮阔的中国互联网时代正在拉开帷幕）\n\n首先是 OB 的设计目标，主要有以下几点：\n- 支持在商品级硬件上快速伸缩，满足高性能和低成本的要求（这主要是因为 Oracle 真的太贵，卡脖子了）\n- 跨区域部署和错误容忍，说白了就是要高可用。\n- 兼容主流数据库（因为不兼容的话业务方就不想迁移过来了）\n整体来说，这几个设计目标很符合当时的时代背景。\n\n接着是设计标准，对于一个新的数据库而言，总要面临以下挑战：\n\n1. 业务的迁移成本和风险\n2. 业务方的学习成本\n3. 第三方服务提供者的学习成本\n\n为了应对这些挑战，OB 定下了以下的设计标准：原生兼容主流数据库，考虑各种大中小组织的需求。对各种主流数据库的兼容能够降低业务方的迁移成本和学习成本，适用不同规模组织能够最大成都满足各类业务场景的成本和性能要求。\n\n\n下面我们来看下基础架构，OB 支持 shared-nothing 架构，如下图所示，这其实是一个很标准的存算分离的架构。应用层发送请求到 proxy 层，由 proxy 层转发到对应的 db 节点，db 节点主要负责计算逻辑，由存储引擎访问底层的存储集群。\n\n![Alt text](../images/ob_arch.png)\n\n每个 OB 集群由多个不同的 zone 组成，不同的 zone 可以部署到单个 region 或者多个 region。在单个 zone 内，OB 是以 shared-nothing 的方式来部署的。Database 被切割成多个分片，这些分片是数据分布和负载均衡的基本单元。每个 partition 在每个 zone 都有一个副本，zone 与 zone 之间通过 Paxos 来同步。\n\n单个 OB 节点和传统的关系型数据库差不多，接收到 SQL语句后，会把语句编译成执行计划，本地计划直接执行，跨节点计划采用两阶段提交来实现，事务提交在 redo log 被持久化到多数的 Paxos 节点后。\n\nOB 中有多个 Paxos 组，其中一个组负责整个集群的调度、负载均衡、节点管理、失败检测等工作。\n\n```\n\"Shared-nothing\"是一种计算机系统架构和设计模式，主要用于构建分布式系统。在shared-nothing架构中，不同的节点（计算机或服务器）之间不共享任何主要资源，如内存、存储或处理器。每个节点都是独立的、自治的单元，其操作不会影响其他节点。\n\n主要特点和优势：\n\n1. 高可伸缩性：由于每个节点都是独立的，shared-nothing架构可以轻松地通过添加更多的节点来扩展整个系统的性能和处理能力。这使得系统能够适应不断增长的数据和用户需求。\n\n2. 高可用性：由于节点之间不共享资源，一个节点的故障通常不会对其他节点产生影响。这种独立性使得shared-nothing系统具有高度的容错性和可用性。\n\n3. 简化系统管理：每个节点都是独立的，不需要复杂的资源管理和协调。这样可以降低系统管理的复杂性，简化系统维护和故障排除。\n\n4. 避免资源竞争：由于节点之间不共享资源，不会出现资源竞争的情况。这可以避免锁和同步等问题，提高系统的并发性能。\n\n5. 数据分区：在shared-nothing系统中，数据通常被分散存储在不同节点上，每个节点负责管理自己的数据。这种数据分区可以提高系统的负载均衡和查询性能。\n\nshared-nothing架构通常在大规模的分布式数据库系统、分布式文件系统和云计算平台等领域得到广泛应用。著名的shared-nothing数据库系统包括Google的Bigtable和Amazon的DynamoDB。这种设计模式对于构建高性能、高可扩展性和高可用性的分布式系统非常有益。\n```","source":"_posts/papers/Oceanbase.md","raw":"---\ntitle: \"(Paper Reading) Manu: A Cloud Native Vector Database Management System\"\ntags:\n    - 数据库\n    - Paper Reading\n---\n\n时隔几周，又来更新了。这几周时间比较碎片，没有找到比较好的机会写文。话不多说，开整。\n\n<!-- more -->\n\n今天这篇文章是还是 VLDB 上的一篇文章，主要讲了 OceanBase 的整体架构和设计经验。主要包括 OceanBase 的设计目标、设计标准、整体架构、关键组件以及相关的设计经验。主要分成下面五个部分，这篇文章也主要从这五个部分来展开：\n- OB 的设计目标和标准、系统架构、SQL 引擎以及多租户实现\n- OB 使用的基于 LSM tree 的存储引擎、非对称读写设计、增量压缩和副本类型等\n- OB 的事务处理引擎、隔离级别和复制表\n- TPC-C benchmark test。这个噱头十足，等下可以仔细看看。\n- 构建 OB 过程中的设计经验\n\n从技术选型来看，OB 使用了分布式数据库系统中常用的一些技术：LSM tree、Paxos等等，当然这部分各种分布式数据库的实现都是大同小异，没有最完美的设计，只有尽可能贴近当前业务场景的Best Practice。\n\n老规矩看下 chatGPT 怎么说。\n\n```\nOceanBase是由中国阿里巴巴集团开发的分布式关系型数据库系统。它是阿里巴巴公司的自主研发项目之一，旨在满足其海量数据存储和高并发访问的需求。OceanBase在设计上借鉴了Google的Spanner和F1等分布式数据库系统的一些思想。\n\n主要特点和优势：\n\n1. 分布式架构：OceanBase是一个分布式数据库系统，它将数据划分成多个分片并在多台服务器上存储，以实现数据的高可用性和可扩展性。\n\n2. ACID事务支持：OceanBase支持ACID（原子性、一致性、隔离性和持久性）事务，这意味着它可以保证数据在并发环境下的一致性和完整性。\n\n3. 高并发读写：作为用于大规模在线服务的数据库系统，OceanBase被设计为能够处理高并发读写请求，满足对海量数据的实时访问需求。\n\n4. 水平扩展：OceanBase可以通过添加更多的节点来实现水平扩展，以应对数据量和访问量的增长。\n\n5. 多租户支持：OceanBase支持多租户架构，允许将不同的应用和用户隔离在不同的数据库实例中，提供更好的安全性和资源隔离。\n\n6. 多数据模型支持：除了关系型数据模型，OceanBase还支持存储非结构化数据和半结构化数据，使其能够适应不同类型的应用场景。\n```\n\n## 整体设计\nOB 的设计目标是为了在商用级硬件上构建可快速伸缩的高性能、低成本数据库，需要满足可跨区域部署、错误容忍等需求，OB 需要兼容常见的主流数据库，这也和设计 OB 时的时代背景有关，如果没记错应该是在 10 年前后，当时国内也没有像现在一样百花齐放，淘宝当时使用的主要还是 Oracle、MySQL 之类的数据库产品。（这个时间点我刚上大学，完全没有意识到波澜壮阔的中国互联网时代正在拉开帷幕）\n\n首先是 OB 的设计目标，主要有以下几点：\n- 支持在商品级硬件上快速伸缩，满足高性能和低成本的要求（这主要是因为 Oracle 真的太贵，卡脖子了）\n- 跨区域部署和错误容忍，说白了就是要高可用。\n- 兼容主流数据库（因为不兼容的话业务方就不想迁移过来了）\n整体来说，这几个设计目标很符合当时的时代背景。\n\n接着是设计标准，对于一个新的数据库而言，总要面临以下挑战：\n\n1. 业务的迁移成本和风险\n2. 业务方的学习成本\n3. 第三方服务提供者的学习成本\n\n为了应对这些挑战，OB 定下了以下的设计标准：原生兼容主流数据库，考虑各种大中小组织的需求。对各种主流数据库的兼容能够降低业务方的迁移成本和学习成本，适用不同规模组织能够最大成都满足各类业务场景的成本和性能要求。\n\n\n下面我们来看下基础架构，OB 支持 shared-nothing 架构，如下图所示，这其实是一个很标准的存算分离的架构。应用层发送请求到 proxy 层，由 proxy 层转发到对应的 db 节点，db 节点主要负责计算逻辑，由存储引擎访问底层的存储集群。\n\n![Alt text](../images/ob_arch.png)\n\n每个 OB 集群由多个不同的 zone 组成，不同的 zone 可以部署到单个 region 或者多个 region。在单个 zone 内，OB 是以 shared-nothing 的方式来部署的。Database 被切割成多个分片，这些分片是数据分布和负载均衡的基本单元。每个 partition 在每个 zone 都有一个副本，zone 与 zone 之间通过 Paxos 来同步。\n\n单个 OB 节点和传统的关系型数据库差不多，接收到 SQL语句后，会把语句编译成执行计划，本地计划直接执行，跨节点计划采用两阶段提交来实现，事务提交在 redo log 被持久化到多数的 Paxos 节点后。\n\nOB 中有多个 Paxos 组，其中一个组负责整个集群的调度、负载均衡、节点管理、失败检测等工作。\n\n```\n\"Shared-nothing\"是一种计算机系统架构和设计模式，主要用于构建分布式系统。在shared-nothing架构中，不同的节点（计算机或服务器）之间不共享任何主要资源，如内存、存储或处理器。每个节点都是独立的、自治的单元，其操作不会影响其他节点。\n\n主要特点和优势：\n\n1. 高可伸缩性：由于每个节点都是独立的，shared-nothing架构可以轻松地通过添加更多的节点来扩展整个系统的性能和处理能力。这使得系统能够适应不断增长的数据和用户需求。\n\n2. 高可用性：由于节点之间不共享资源，一个节点的故障通常不会对其他节点产生影响。这种独立性使得shared-nothing系统具有高度的容错性和可用性。\n\n3. 简化系统管理：每个节点都是独立的，不需要复杂的资源管理和协调。这样可以降低系统管理的复杂性，简化系统维护和故障排除。\n\n4. 避免资源竞争：由于节点之间不共享资源，不会出现资源竞争的情况。这可以避免锁和同步等问题，提高系统的并发性能。\n\n5. 数据分区：在shared-nothing系统中，数据通常被分散存储在不同节点上，每个节点负责管理自己的数据。这种数据分区可以提高系统的负载均衡和查询性能。\n\nshared-nothing架构通常在大规模的分布式数据库系统、分布式文件系统和云计算平台等领域得到广泛应用。著名的shared-nothing数据库系统包括Google的Bigtable和Amazon的DynamoDB。这种设计模式对于构建高性能、高可扩展性和高可用性的分布式系统非常有益。\n```","slug":"papers/Oceanbase","published":1,"date":"2023-07-30T06:11:37.246Z","updated":"2023-07-30T11:36:05.281Z","_id":"clkp3c6iv00071ts16lz5hiue","comments":1,"layout":"post","photos":[],"link":"","content":"<p>时隔几周，又来更新了。这几周时间比较碎片，没有找到比较好的机会写文。话不多说，开整。</p>\n<span id=\"more\"></span>\n\n<p>今天这篇文章是还是 VLDB 上的一篇文章，主要讲了 OceanBase 的整体架构和设计经验。主要包括 OceanBase 的设计目标、设计标准、整体架构、关键组件以及相关的设计经验。主要分成下面五个部分，这篇文章也主要从这五个部分来展开：</p>\n<ul>\n<li>OB 的设计目标和标准、系统架构、SQL 引擎以及多租户实现</li>\n<li>OB 使用的基于 LSM tree 的存储引擎、非对称读写设计、增量压缩和副本类型等</li>\n<li>OB 的事务处理引擎、隔离级别和复制表</li>\n<li>TPC-C benchmark test。这个噱头十足，等下可以仔细看看。</li>\n<li>构建 OB 过程中的设计经验</li>\n</ul>\n<p>从技术选型来看，OB 使用了分布式数据库系统中常用的一些技术：LSM tree、Paxos等等，当然这部分各种分布式数据库的实现都是大同小异，没有最完美的设计，只有尽可能贴近当前业务场景的Best Practice。</p>\n<p>老规矩看下 chatGPT 怎么说。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">OceanBase是由中国阿里巴巴集团开发的分布式关系型数据库系统。它是阿里巴巴公司的自主研发项目之一，旨在满足其海量数据存储和高并发访问的需求。OceanBase在设计上借鉴了Google的Spanner和F1等分布式数据库系统的一些思想。</span><br><span class=\"line\"></span><br><span class=\"line\">主要特点和优势：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 分布式架构：OceanBase是一个分布式数据库系统，它将数据划分成多个分片并在多台服务器上存储，以实现数据的高可用性和可扩展性。</span><br><span class=\"line\"></span><br><span class=\"line\">2. ACID事务支持：OceanBase支持ACID（原子性、一致性、隔离性和持久性）事务，这意味着它可以保证数据在并发环境下的一致性和完整性。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 高并发读写：作为用于大规模在线服务的数据库系统，OceanBase被设计为能够处理高并发读写请求，满足对海量数据的实时访问需求。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 水平扩展：OceanBase可以通过添加更多的节点来实现水平扩展，以应对数据量和访问量的增长。</span><br><span class=\"line\"></span><br><span class=\"line\">5. 多租户支持：OceanBase支持多租户架构，允许将不同的应用和用户隔离在不同的数据库实例中，提供更好的安全性和资源隔离。</span><br><span class=\"line\"></span><br><span class=\"line\">6. 多数据模型支持：除了关系型数据模型，OceanBase还支持存储非结构化数据和半结构化数据，使其能够适应不同类型的应用场景。</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"整体设计\"><a href=\"#整体设计\" class=\"headerlink\" title=\"整体设计\"></a>整体设计</h2><p>OB 的设计目标是为了在商用级硬件上构建可快速伸缩的高性能、低成本数据库，需要满足可跨区域部署、错误容忍等需求，OB 需要兼容常见的主流数据库，这也和设计 OB 时的时代背景有关，如果没记错应该是在 10 年前后，当时国内也没有像现在一样百花齐放，淘宝当时使用的主要还是 Oracle、MySQL 之类的数据库产品。（这个时间点我刚上大学，完全没有意识到波澜壮阔的中国互联网时代正在拉开帷幕）</p>\n<p>首先是 OB 的设计目标，主要有以下几点：</p>\n<ul>\n<li>支持在商品级硬件上快速伸缩，满足高性能和低成本的要求（这主要是因为 Oracle 真的太贵，卡脖子了）</li>\n<li>跨区域部署和错误容忍，说白了就是要高可用。</li>\n<li>兼容主流数据库（因为不兼容的话业务方就不想迁移过来了）<br>整体来说，这几个设计目标很符合当时的时代背景。</li>\n</ul>\n<p>接着是设计标准，对于一个新的数据库而言，总要面临以下挑战：</p>\n<ol>\n<li>业务的迁移成本和风险</li>\n<li>业务方的学习成本</li>\n<li>第三方服务提供者的学习成本</li>\n</ol>\n<p>为了应对这些挑战，OB 定下了以下的设计标准：原生兼容主流数据库，考虑各种大中小组织的需求。对各种主流数据库的兼容能够降低业务方的迁移成本和学习成本，适用不同规模组织能够最大成都满足各类业务场景的成本和性能要求。</p>\n<p>下面我们来看下基础架构，OB 支持 shared-nothing 架构，如下图所示，这其实是一个很标准的存算分离的架构。应用层发送请求到 proxy 层，由 proxy 层转发到对应的 db 节点，db 节点主要负责计算逻辑，由存储引擎访问底层的存储集群。</p>\n<p><img src=\"/../images/ob_arch.png\" alt=\"Alt text\"></p>\n<p>每个 OB 集群由多个不同的 zone 组成，不同的 zone 可以部署到单个 region 或者多个 region。在单个 zone 内，OB 是以 shared-nothing 的方式来部署的。Database 被切割成多个分片，这些分片是数据分布和负载均衡的基本单元。每个 partition 在每个 zone 都有一个副本，zone 与 zone 之间通过 Paxos 来同步。</p>\n<p>单个 OB 节点和传统的关系型数据库差不多，接收到 SQL语句后，会把语句编译成执行计划，本地计划直接执行，跨节点计划采用两阶段提交来实现，事务提交在 redo log 被持久化到多数的 Paxos 节点后。</p>\n<p>OB 中有多个 Paxos 组，其中一个组负责整个集群的调度、负载均衡、节点管理、失败检测等工作。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;Shared-nothing&quot;是一种计算机系统架构和设计模式，主要用于构建分布式系统。在shared-nothing架构中，不同的节点（计算机或服务器）之间不共享任何主要资源，如内存、存储或处理器。每个节点都是独立的、自治的单元，其操作不会影响其他节点。</span><br><span class=\"line\"></span><br><span class=\"line\">主要特点和优势：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 高可伸缩性：由于每个节点都是独立的，shared-nothing架构可以轻松地通过添加更多的节点来扩展整个系统的性能和处理能力。这使得系统能够适应不断增长的数据和用户需求。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 高可用性：由于节点之间不共享资源，一个节点的故障通常不会对其他节点产生影响。这种独立性使得shared-nothing系统具有高度的容错性和可用性。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 简化系统管理：每个节点都是独立的，不需要复杂的资源管理和协调。这样可以降低系统管理的复杂性，简化系统维护和故障排除。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 避免资源竞争：由于节点之间不共享资源，不会出现资源竞争的情况。这可以避免锁和同步等问题，提高系统的并发性能。</span><br><span class=\"line\"></span><br><span class=\"line\">5. 数据分区：在shared-nothing系统中，数据通常被分散存储在不同节点上，每个节点负责管理自己的数据。这种数据分区可以提高系统的负载均衡和查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">shared-nothing架构通常在大规模的分布式数据库系统、分布式文件系统和云计算平台等领域得到广泛应用。著名的shared-nothing数据库系统包括Google的Bigtable和Amazon的DynamoDB。这种设计模式对于构建高性能、高可扩展性和高可用性的分布式系统非常有益。</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>时隔几周，又来更新了。这几周时间比较碎片，没有找到比较好的机会写文。话不多说，开整。</p>","more":"<p>今天这篇文章是还是 VLDB 上的一篇文章，主要讲了 OceanBase 的整体架构和设计经验。主要包括 OceanBase 的设计目标、设计标准、整体架构、关键组件以及相关的设计经验。主要分成下面五个部分，这篇文章也主要从这五个部分来展开：</p>\n<ul>\n<li>OB 的设计目标和标准、系统架构、SQL 引擎以及多租户实现</li>\n<li>OB 使用的基于 LSM tree 的存储引擎、非对称读写设计、增量压缩和副本类型等</li>\n<li>OB 的事务处理引擎、隔离级别和复制表</li>\n<li>TPC-C benchmark test。这个噱头十足，等下可以仔细看看。</li>\n<li>构建 OB 过程中的设计经验</li>\n</ul>\n<p>从技术选型来看，OB 使用了分布式数据库系统中常用的一些技术：LSM tree、Paxos等等，当然这部分各种分布式数据库的实现都是大同小异，没有最完美的设计，只有尽可能贴近当前业务场景的Best Practice。</p>\n<p>老规矩看下 chatGPT 怎么说。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">OceanBase是由中国阿里巴巴集团开发的分布式关系型数据库系统。它是阿里巴巴公司的自主研发项目之一，旨在满足其海量数据存储和高并发访问的需求。OceanBase在设计上借鉴了Google的Spanner和F1等分布式数据库系统的一些思想。</span><br><span class=\"line\"></span><br><span class=\"line\">主要特点和优势：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 分布式架构：OceanBase是一个分布式数据库系统，它将数据划分成多个分片并在多台服务器上存储，以实现数据的高可用性和可扩展性。</span><br><span class=\"line\"></span><br><span class=\"line\">2. ACID事务支持：OceanBase支持ACID（原子性、一致性、隔离性和持久性）事务，这意味着它可以保证数据在并发环境下的一致性和完整性。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 高并发读写：作为用于大规模在线服务的数据库系统，OceanBase被设计为能够处理高并发读写请求，满足对海量数据的实时访问需求。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 水平扩展：OceanBase可以通过添加更多的节点来实现水平扩展，以应对数据量和访问量的增长。</span><br><span class=\"line\"></span><br><span class=\"line\">5. 多租户支持：OceanBase支持多租户架构，允许将不同的应用和用户隔离在不同的数据库实例中，提供更好的安全性和资源隔离。</span><br><span class=\"line\"></span><br><span class=\"line\">6. 多数据模型支持：除了关系型数据模型，OceanBase还支持存储非结构化数据和半结构化数据，使其能够适应不同类型的应用场景。</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"整体设计\"><a href=\"#整体设计\" class=\"headerlink\" title=\"整体设计\"></a>整体设计</h2><p>OB 的设计目标是为了在商用级硬件上构建可快速伸缩的高性能、低成本数据库，需要满足可跨区域部署、错误容忍等需求，OB 需要兼容常见的主流数据库，这也和设计 OB 时的时代背景有关，如果没记错应该是在 10 年前后，当时国内也没有像现在一样百花齐放，淘宝当时使用的主要还是 Oracle、MySQL 之类的数据库产品。（这个时间点我刚上大学，完全没有意识到波澜壮阔的中国互联网时代正在拉开帷幕）</p>\n<p>首先是 OB 的设计目标，主要有以下几点：</p>\n<ul>\n<li>支持在商品级硬件上快速伸缩，满足高性能和低成本的要求（这主要是因为 Oracle 真的太贵，卡脖子了）</li>\n<li>跨区域部署和错误容忍，说白了就是要高可用。</li>\n<li>兼容主流数据库（因为不兼容的话业务方就不想迁移过来了）<br>整体来说，这几个设计目标很符合当时的时代背景。</li>\n</ul>\n<p>接着是设计标准，对于一个新的数据库而言，总要面临以下挑战：</p>\n<ol>\n<li>业务的迁移成本和风险</li>\n<li>业务方的学习成本</li>\n<li>第三方服务提供者的学习成本</li>\n</ol>\n<p>为了应对这些挑战，OB 定下了以下的设计标准：原生兼容主流数据库，考虑各种大中小组织的需求。对各种主流数据库的兼容能够降低业务方的迁移成本和学习成本，适用不同规模组织能够最大成都满足各类业务场景的成本和性能要求。</p>\n<p>下面我们来看下基础架构，OB 支持 shared-nothing 架构，如下图所示，这其实是一个很标准的存算分离的架构。应用层发送请求到 proxy 层，由 proxy 层转发到对应的 db 节点，db 节点主要负责计算逻辑，由存储引擎访问底层的存储集群。</p>\n<p><img src=\"/../images/ob_arch.png\" alt=\"Alt text\"></p>\n<p>每个 OB 集群由多个不同的 zone 组成，不同的 zone 可以部署到单个 region 或者多个 region。在单个 zone 内，OB 是以 shared-nothing 的方式来部署的。Database 被切割成多个分片，这些分片是数据分布和负载均衡的基本单元。每个 partition 在每个 zone 都有一个副本，zone 与 zone 之间通过 Paxos 来同步。</p>\n<p>单个 OB 节点和传统的关系型数据库差不多，接收到 SQL语句后，会把语句编译成执行计划，本地计划直接执行，跨节点计划采用两阶段提交来实现，事务提交在 redo log 被持久化到多数的 Paxos 节点后。</p>\n<p>OB 中有多个 Paxos 组，其中一个组负责整个集群的调度、负载均衡、节点管理、失败检测等工作。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;Shared-nothing&quot;是一种计算机系统架构和设计模式，主要用于构建分布式系统。在shared-nothing架构中，不同的节点（计算机或服务器）之间不共享任何主要资源，如内存、存储或处理器。每个节点都是独立的、自治的单元，其操作不会影响其他节点。</span><br><span class=\"line\"></span><br><span class=\"line\">主要特点和优势：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 高可伸缩性：由于每个节点都是独立的，shared-nothing架构可以轻松地通过添加更多的节点来扩展整个系统的性能和处理能力。这使得系统能够适应不断增长的数据和用户需求。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 高可用性：由于节点之间不共享资源，一个节点的故障通常不会对其他节点产生影响。这种独立性使得shared-nothing系统具有高度的容错性和可用性。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 简化系统管理：每个节点都是独立的，不需要复杂的资源管理和协调。这样可以降低系统管理的复杂性，简化系统维护和故障排除。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 避免资源竞争：由于节点之间不共享资源，不会出现资源竞争的情况。这可以避免锁和同步等问题，提高系统的并发性能。</span><br><span class=\"line\"></span><br><span class=\"line\">5. 数据分区：在shared-nothing系统中，数据通常被分散存储在不同节点上，每个节点负责管理自己的数据。这种数据分区可以提高系统的负载均衡和查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">shared-nothing架构通常在大规模的分布式数据库系统、分布式文件系统和云计算平台等领域得到广泛应用。著名的shared-nothing数据库系统包括Google的Bigtable和Amazon的DynamoDB。这种设计模式对于构建高性能、高可扩展性和高可用性的分布式系统非常有益。</span><br></pre></td></tr></table></figure>"},{"title":"(Paper Reading) Manu: A Cloud Native Vector Database Management System","date":"2023-07-30T02:10:33.000Z","_content":"\n这篇文章同样是 VLDB 的一篇文章，讲的是云原生向量数据库。\n\n<!-- more -->\n\n首先按照惯例问一下 chatGPT，什么是向量数据库：\n\n```\n向量数据库（Vector Database）是一种专门用于存储、管理和查询向量数据的数据库系统。向量数据是由向量（Vector）组成的数据集合，其中每个向量代表了一个数据点或实体的特征表示。\n\n传统的关系型数据库或文档型数据库主要以标量数据为基础，而向量数据库专注于处理和分析向量数据。它提供了针对向量数据的高效存储和检索机制，以及针对向量的特定操作和查询功能。\n\n向量数据库通常具备以下特点和功能：\n\n1. 高维向量存储：向量数据库能够有效地存储和管理高维向量数据。它使用高效的数据结构和索引机制，以支持在大规模向量集合中进行高效的查询和分析。\n\n2. 向量相似性搜索：向量数据库提供了针对向量相似性搜索的功能。它能够根据向量之间的相似性度量，如欧氏距离、余弦相似度等，快速检索最相似的向量。\n\n3. 向量索引：为了加速查询速度，向量数据库使用特定的索引结构，如KD-Tree、LSH（局部敏感哈希）等，以支持高效的向量搜索和匹配。\n\n4. 向量操作和计算：向量数据库提供了针对向量的操作和计算功能，如向量加法、向量乘法、向量投影等。这些功能使得在向量数据上进行复杂的分析和计算成为可能。\n\n5. 分布式架构：为了应对大规模向量数据的处理需求，一些向量数据库采用分布式架构，允许在多个节点上存储和处理向量数据，以提高吞吐量和可扩展性。\n\n向量数据库在许多领域都具有广泛的应用，包括机器学习、图像识别、自然语言处理、推荐系统等。它们为处理和分析大规模向量数据提供了高效的存储和查询解决方案，推动了向量数据应用领域的发展和创新。\n```\n\n论文开篇就介绍了向量数据库与传统数据库在相应应用场景下的区别：\n\n- 向量数据库不太需要支持复杂的事务\n- 向量数据库需要能调整性能和一致性之间平衡\n- 向量数据库的硬件开销较大，所以需要足够细粒度的可伸缩性\n\n文章主要有以下贡献：\n\n- 文章总结了过去三年内跟 1200 个工业用户沟通所得到的经验，阐明了向量数据库和传统数据库的区别，并列出了向量数据库需要满足的设计目标\n- 文章介绍了 Manu 这个云原生向量数据库的关键架构设计，介绍了如何在减少事务实现复杂度之后如何获得可调节的一致性和细粒度可伸缩性\n- 文章同时还介绍了一些在可使用性（Usability）和性能上的优化设计\n\n接下来我们系统过一下整篇文章，首先是背景和动机。如上文所述，向量数据库主要应用在一些向量数据相关的场景，比如视频推荐场景下，视频和用户的各类关键信息会被编码成一个高维的向量数据，通过计算向量之间的相似度，我们可以为用户实现视频推荐等功能。然而，在这类场景下，不管是视频或者其他被推荐的内容还是用户数据本身，数据规模都极大。传统的关系型数据库并不能很好地应对这类场景，向量数据库有着不同的需求：\n\n首先，向量数据库的应用场景在不断地变革当中，因此向量数据库本身也需要能够满足各类场景下的不同需求；其次，向量数据库并不需要复杂事务，因为向量数据往往被编码到一个单独的向量中，并不需要多行或者多列的复杂事务操作，因此只要行级的 ACID 即可满足要求。再者，向量数据库需要灵活的性能与一致性之间的平衡，因为不同场景下用户的需求不同，有的侧重系统吞吐，有的关注一致性，向量数据库需要能够灵活配置这些需求。最后，由于向量数据库的特定场景需求，向量数据库需要能够利用到各类硬件加速能力，同时，由于数据局部性较差，其还需要较大的 RAM，在不同场景下，硬件的需求也不同，有的需要高并发的向量搜索，有的只需要满足离线数据导入和索引需求即可，所以为了应对不同场景，向量数据库需要足够灵活的可伸缩性。\n\n```\nNote: ACID基本是面试任何数据库团队甚至一些业务团队必考到的内容了，在回答 ACID 是什么的基础上，我们经常还会聊到 ACID 是如何实现的，这类问题网上的解释很多，我随便贴个 chatGPT的回答如下：\n\nACID 是数据库事务的四个关键特性的缩写，它们分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。这些特性确保了数据库事务的可靠性、可预测性和完整性。\n\n1. 原子性（Atomicity）：原子性确保事务中的所有操作要么全部成功完成，要么全部失败回滚。事务被视为一个不可分割的原子单元，要么完全执行，要么完全回滚。\n\n2. 一致性（Consistency）：一致性确保在事务执行前后数据库的状态保持一致。在事务执行过程中，数据必须满足预定义的完整性约束和业务规则。\n\n3. 隔离性（Isolation）：隔离性确保事务的并发执行不会相互干扰，每个事务都应该像是在独立运行的环境中执行一样。事务之间的读写操作应该相互隔离，以避免数据不一致或冲突的情况。\n\n4. 持久性（Durability）：持久性确保一旦事务提交成功，对数据库的改变将永久保存，即使在系统发生故障或重启的情况下也能保持数据的完整性。\n\n为了实现 ACID 特性，数据库系统采用了一系列技术和机制：\n\n1. 事务管理：数据库系统提供了事务管理器来管理事务的提交、回滚和并发控制。事务管理器确保事务的原子性和一致性，并协调并发执行的事务之间的隔离性。\n\n2. 日志记录：数据库使用日志来记录事务的操作和改变。日志记录包括事务的开始和结束、数据的修改和回滚操作等。通过日志记录，可以在系统故障后恢复数据，并确保事务的持久性。\n\n3. 并发控制：数据库系统使用并发控制机制来处理多个事务同时访问和修改数据时可能出现的冲突。常见的并发控制技术包括锁机制、多版本并发控制（MVCC）、时间戳等。\n\n4. 数据写入策略：数据库系统通常采用缓冲区和写入策略来提高性能和持久性。数据被缓存在内存中，然后根据策略将数据写入磁盘或其他持久存储介质，以确保数据的持久性。\n\n综上所述，ACID 是数据库事务的重要特性，通过事务管理、日志记录、并发控制和持久性机制来实现。这些机制确保了事务的原子性、一致性、隔离性和持久性，从而保证了数据库系统的可靠性和数据完整性。\n```\n\nManu 数据库的设计目标主要有五个：\n\n- 长期可进化性：这个系统架构必须保证有足够的可进化性，不仅是系统整体、各个独立模块之间都要能够进化。这里想起马丁大叔书里的关于monolith/microservice 的一句论述 \"A good architecture will allow a system to be born as a monolith, deployed in a single file, but then to grow into a set of independently deployable units, and then all the way to independent services and/or micro-services.\"其实好的架构设计就是这样，各个模块要足够独立，具有独立的可迭代性。\n- 可调的一致性：Manu 引入了一种叫做 Delta consistency 的一致性，介于强一致性和总重一致性之间，用户可以调节 delta 值来决定选择一致性偏好。\n- 良好的可伸缩性：这个就不多说了，向量数据库需要应用的场景多，需要能够满足比较好的系统伸缩性，以满足不同规模不同场景的需求。\n- 高可用性：这个更不用说了，现在是个系统都得高可用。\n- 高性能：这个可以看一下最后的实验对比数据。\n- 强适配性：要求数据库能够被用于不同的环境，下到 laptop 上到 cloud，各种环境都要能用。\n\n好了，下面开始看一下整个系统的设计。\n\n首先是系统内的几个基本概念：\n- Schema：Manu 的基本数据类型有向量、字符串、布尔值、整数和浮点数。\n- Collection：类似于关系型数据库中的表，但是不同 collection 之间不存在任何关联，所以不存在类似于关系型数据库中的 join 等操作\n- Shard：Shard 其实就是数据分片，可以基于主键将一些数据哈希到不同的 shard 中\n- Segment：Segment 组成 Shard，其实也很好理解，类似于 LSM tree 中的SSTable，生成块的策略是基于块的大小或者一定时间，为了避免有些块过小，Manu 还会将一些小的块合并成大块。\n\n接着是整体系统的设计，如下图所示：\n![Alt text](../images/manu_arch.png)\n\nManu总共分四层：访问层、协调层、工作层和存储层。\n\n- 访问层：由无状态代理组成，用于提供给用户访问数据库的服务节点。这一层会执行请求分发、结果合并等操作，同时也缓存了一部分元数据，用于验证一些查询请求的合法性（比如表是否存在之类的），保证有问题的请求可以快速失败，从而减少达到下层的请求数量，优化整体的性能\n- 协调层：管理系统状态、维护 collection 的元数据，协调不同系统组件之间的任务。这一层包含四个 coordinator：Root coordinator 用于处理数据定义的请求，可以维护所有 collection 的元数据信息，新增或删除 collection；Data coordinator 用于记录 collection 的详细信息，比如 segment 在存储层的路由信息，它还会负责协调数据节点将数据更新请求转换成 binlog；Query coordinator 用于管理查询节点，负责整个查询节点的负载均衡；最后是 Index coordinator，顾名思义，负责维护元信息的索引和索引构建工作，由于向量数据库中没什么跨表的操作，所以不同 collection 的请求可以由独立的 coordinator 实例来处理\n- 工作层：负责执行具体的计算任务，这一层的工作节点都是无状态的，节点之间不需要任何的协作。工作层有多种不同类型的节点，负责不同的任务，比如：查询节点负责查询执行，索引节点负责索引构建，数据节点负责日志存档。由于节点之间任务是相互独立的，所以各类节点可以独立伸缩\n- 存储层：用于持久化系统状态、元数据、collection 和索引。Manu 使用 etcd 作为元数据存储中心，元数据先写入 etcd，再同步到协调节点。由于数据库内的其他数据（binlog、数据、索引等）非常大，所以 Manu 直接使用 AWS S3来存储，其他很多存储系统的 API 与 S3 的 API 相互兼容，所以 Manu 很容易切换到其他的存储平台。\n\nManu 遵循“log as data”的设计理念，所以日志系统是 Manu 的核心，作为 Manu 系统的骨干服务。Manu 将 WAL 和 binlog 暴露出来，作为整个系统的骨干服务。WAL 是负责增量数据，binlog 负责存量数据。Logger 负责将数据写入到 WAL 日志中，数据节点订阅 WAL 日志，将基于行的 WAL 日志转为基于列的 binlog。所有的只读组件（如索引节点和查询节点）缩回分别订阅日志服务来保证数据更新。这种架构完全解耦了读写模块，从而保证各模块可以独立伸缩。\n\nManu 会在日志中记录所有更改系统的操作，比如数据定义请求、数据操作请求、系统协调请求等。Manu 使用的是逻辑日志，而非物理日志，逻辑日志记录的是数据操作的事件，而非物理数据页面的操作。日志系统的结构如下：\n\n![Alt text](../images/manu_log_system.png)\n\n可以看出，这里用到了一致性哈希，插入请求中的 entity 会被哈希到哈希环上的一个节点。当 logger 接收到一个请求时，它会先验证请求的合法性，TSO（time service oracle）会给这个 entity 提供一个 ID，用于决定这个 entity 应该放在哪个 segment 上，并将这个 entity 写入 WAL 日志。logger 同时也会将这个 entity ID 到 segment ID 的映射写入本地的 LSM tree 中，并周期性将 LSM tree 的增量部分刷入对象存储中。每个 logger 都缓存了它所管理的 shard 的 mapping 关系。\n\nManu 的 WAL 日志试试用消息队列（Kafka or Pulsar）来实现的，这里有多个不同的 logical channel 来处理不同类型的请求，实现资源隔离，同时提高整体的数据吞吐。数据节点则会订阅 WAL，将基于行的 WAL 日志转为基于列的 binlog。列存的 binlog 能够保证单个 field 的批量读写效率，同时提高存储和 IO 的性能。索引节点则只需要读必要的 field 来构建索引，避免读放大。\n\n系统内的协调通过日志来实现，在关键操作完成时，日志系统会广播这些系统事件，日志的时序性也保证了协调消息的有序性。\n\n```markdown\nNote: 读放大（Read Amplification）和写放大（Write Amplification）是与数据库存储引擎相关的性能指标。\n\n1. 读放大：读放大指的是实际从磁盘或存储介质中读取的数据量与应用程序所请求的数据量之间的比例关系。当读放大较高时，意味着需要读取更多的数据才能满足应用程序的读取需求，从而增加了磁盘或存储介质的访问负载和读取延迟。\n\n   读放大通常出现在数据库查询中，特别是在使用索引时。例如，如果查询需要访问多个磁盘块或索引节点才能获取所需的数据，读放大就会增加。\n\n2. 写放大：写放大指的是实际写入到磁盘或存储介质的数据量与应用程序所请求的数据量之间的比例关系。当写放大较高时，意味着需要写入更多的数据才能满足应用程序的写入需求，从而增加了磁盘或存储介质的写入负载和写入延迟。\n\n   写放大通常出现在数据库的更新操作中，特别是在使用事务或写入频繁的场景中。例如，如果更新操作需要在磁盘上进行多次写入或写入大量冗余数据，写放大就会增加。\n\n高读放大和写放大会导致存储引擎性能下降、延迟增加和资源利用率降低。数据库存储引擎通过采用各种技术和优化策略来降低读放大和写放大的程度，以提高数据库系统的性能和效率。例如，使用适当的索引、缓存机制、写入合并和压缩等技术可以减少读放大和写放大的影响，提升数据库的整体性能。\n```\n\n接下来我们来看一下这篇论文提到的另一个关键点，可调的一致性。用户可以通过指定查询和数据的时间偏移量来定义“staleness tolerance”。为了满足用户使用物理时间来定义偏移量的需求，Manu 使用TSO 中的混合逻辑时钟来生成时间戳，每个时间戳包含两个部分，物理部分用于表示物理时间，逻辑部分用于表示时间的顺序。逻辑时间戳用于物理时间相同时判断不同时间的顺序。这里物理时间的时间戳是 Manu 收到这个请求的物理时间。对于一个日志订阅者而言，要实现可调的一致性，需要知道三个值：用户设置容忍的时间偏移值、最后一个数据更新的时间和查询请求签发的时间。基于这三个时间，Manu 可以决定是否需要等待最后一个数据更新的到达用户可容忍的时间区间。在强一致性下，用户可容忍的时间偏移值为 0，在最终一致性下，用户可容忍的时间偏移值为无限长。\n\n接着我们来谈谈索引构建，Manu 支持的索引类型如下：\n![Alt text](../images/manu_index.png)\n\nVector Quantization 能够压缩向量以降低内存占用，同时能够降低向量距离和相似度的计算。Inverted index 能够将向量分组到不同聚簇，这样在查询时就只需要查询最符合期望的聚簇。Proximity Graph能够将相似的向量构建成一个图，在高内存消耗的情况下实现高准确性和低延迟。\n\nManu 的索引构建有两类场景，批量索引和流式索引。批量索引是说用户在给整个 collection 构建索引，这个时候index coordinator 需要从data coordinator 那里拿到所有的 这个 collection 的segment 的路径，然后给每个 segment 构建索引。流式索引则是指用户在数据更新时异步构建索引。整个索引过程 index coordinator、data coordinator 会互相协调完成索引构建，构建完成后通知 query coordinator 使用构建好的索引来执行查询。\n\nManu支持传统向量搜索、属性过滤和多向量搜索。传统向量搜索里的相似度计算主要使用欧氏距离、内积或者角距离。属性过滤主要用于向量搜索过程中基于某些属性进行过滤，这种其实和传统关系型数据库的实现类似。多向量搜索主要是用于一个实体被编码成多个向量的场景。在执行向量搜索时，由于数据天然使用 segment 进行切片，所以不过查询节点可以处理不同 segment，以达到并发执行的目的，这样基本就不需要查询节点之间进行协调。对于一些需要聚合的操作，比如 top-k 查询，Manu 会对不同 segment 执行 top-k查询，最后将结果进行汇总。查询节点主要从三个数据源获取数据：WAL、索引文件和 binlog。为了提高查询的整体效率，Manu 将每个 segment 划分成多个切片，每个切片包含 10000 个向量，在每个切片满了的时候就为这个切片生成一个临时索引。这个索引能够带来 10 倍的性能提升。当一个 segment 满了之后，索引节点就会真正生成这个 segment 的索引，替换掉每个切片的临时索引。\n\n下面是 Manu 的几个关键 feature：\n- 云原生：Manu 的这种低耦合设计能够方便地将其部署在云环境。\n- 可使用性（Usability）：Manu 抽象了支持不同语言的查询 API，能够支持向量场景下的各类查询\n- 时间旅行（Time Travel）：Manu 允许用户基于物理时间戳来对数据库进行恢复。\n- 硬件优化：Manu 针对不同硬件进行了对应的优化，论文介绍了如何在 内存优先的查询节点利用SSD进行大数据规模的向量查询。\n\n接下来是 Manu 的几个使用案例，比如推荐、多媒体、语言、安全、药品。论文介绍了几个具体的场景，如电商推荐、病毒扫描、视频去重等，具体性能数据可以直接参考论文，这部分就不一一赘述了。\n\n下面是论文中几个实验的性能数据，贴上来给大家参考。\n\n下图是电商推荐场景不同吞吐量下的查询召回率。\n![Alt text](../images/manu_recommendation_recall.png)\n\n下图是 24 小时内真实电商流量下的 QPS 和 latency，不同颜色表示使用不同数量的查询节点。\n![Alt text](../images/manu_e_commer_real_traffic.png)\n\n下面两个图则分别展示了查询节点数量和数据规模对QPS 的影响\n\n![Alt text](../images/manu_query_node.png)\n\n下图展示的是所谓可调节的一致性对查询延迟的影响，可以看出查询延迟容忍越低，查询延迟越大。\n\n![Alt text](../images/manu_grace_time.png)\n\n最后是不同数据规模下索引构建时间\n\n![Alt text](../images/manu_index_build.png)","source":"_posts/papers/Manu.md","raw":"---\ntitle: '(Paper Reading) Manu: A Cloud Native Vector Database Management System'\ndate: 2023-07-30 10:10:33\ntags: \"Paper Reading\"\n---\n\n这篇文章同样是 VLDB 的一篇文章，讲的是云原生向量数据库。\n\n<!-- more -->\n\n首先按照惯例问一下 chatGPT，什么是向量数据库：\n\n```\n向量数据库（Vector Database）是一种专门用于存储、管理和查询向量数据的数据库系统。向量数据是由向量（Vector）组成的数据集合，其中每个向量代表了一个数据点或实体的特征表示。\n\n传统的关系型数据库或文档型数据库主要以标量数据为基础，而向量数据库专注于处理和分析向量数据。它提供了针对向量数据的高效存储和检索机制，以及针对向量的特定操作和查询功能。\n\n向量数据库通常具备以下特点和功能：\n\n1. 高维向量存储：向量数据库能够有效地存储和管理高维向量数据。它使用高效的数据结构和索引机制，以支持在大规模向量集合中进行高效的查询和分析。\n\n2. 向量相似性搜索：向量数据库提供了针对向量相似性搜索的功能。它能够根据向量之间的相似性度量，如欧氏距离、余弦相似度等，快速检索最相似的向量。\n\n3. 向量索引：为了加速查询速度，向量数据库使用特定的索引结构，如KD-Tree、LSH（局部敏感哈希）等，以支持高效的向量搜索和匹配。\n\n4. 向量操作和计算：向量数据库提供了针对向量的操作和计算功能，如向量加法、向量乘法、向量投影等。这些功能使得在向量数据上进行复杂的分析和计算成为可能。\n\n5. 分布式架构：为了应对大规模向量数据的处理需求，一些向量数据库采用分布式架构，允许在多个节点上存储和处理向量数据，以提高吞吐量和可扩展性。\n\n向量数据库在许多领域都具有广泛的应用，包括机器学习、图像识别、自然语言处理、推荐系统等。它们为处理和分析大规模向量数据提供了高效的存储和查询解决方案，推动了向量数据应用领域的发展和创新。\n```\n\n论文开篇就介绍了向量数据库与传统数据库在相应应用场景下的区别：\n\n- 向量数据库不太需要支持复杂的事务\n- 向量数据库需要能调整性能和一致性之间平衡\n- 向量数据库的硬件开销较大，所以需要足够细粒度的可伸缩性\n\n文章主要有以下贡献：\n\n- 文章总结了过去三年内跟 1200 个工业用户沟通所得到的经验，阐明了向量数据库和传统数据库的区别，并列出了向量数据库需要满足的设计目标\n- 文章介绍了 Manu 这个云原生向量数据库的关键架构设计，介绍了如何在减少事务实现复杂度之后如何获得可调节的一致性和细粒度可伸缩性\n- 文章同时还介绍了一些在可使用性（Usability）和性能上的优化设计\n\n接下来我们系统过一下整篇文章，首先是背景和动机。如上文所述，向量数据库主要应用在一些向量数据相关的场景，比如视频推荐场景下，视频和用户的各类关键信息会被编码成一个高维的向量数据，通过计算向量之间的相似度，我们可以为用户实现视频推荐等功能。然而，在这类场景下，不管是视频或者其他被推荐的内容还是用户数据本身，数据规模都极大。传统的关系型数据库并不能很好地应对这类场景，向量数据库有着不同的需求：\n\n首先，向量数据库的应用场景在不断地变革当中，因此向量数据库本身也需要能够满足各类场景下的不同需求；其次，向量数据库并不需要复杂事务，因为向量数据往往被编码到一个单独的向量中，并不需要多行或者多列的复杂事务操作，因此只要行级的 ACID 即可满足要求。再者，向量数据库需要灵活的性能与一致性之间的平衡，因为不同场景下用户的需求不同，有的侧重系统吞吐，有的关注一致性，向量数据库需要能够灵活配置这些需求。最后，由于向量数据库的特定场景需求，向量数据库需要能够利用到各类硬件加速能力，同时，由于数据局部性较差，其还需要较大的 RAM，在不同场景下，硬件的需求也不同，有的需要高并发的向量搜索，有的只需要满足离线数据导入和索引需求即可，所以为了应对不同场景，向量数据库需要足够灵活的可伸缩性。\n\n```\nNote: ACID基本是面试任何数据库团队甚至一些业务团队必考到的内容了，在回答 ACID 是什么的基础上，我们经常还会聊到 ACID 是如何实现的，这类问题网上的解释很多，我随便贴个 chatGPT的回答如下：\n\nACID 是数据库事务的四个关键特性的缩写，它们分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。这些特性确保了数据库事务的可靠性、可预测性和完整性。\n\n1. 原子性（Atomicity）：原子性确保事务中的所有操作要么全部成功完成，要么全部失败回滚。事务被视为一个不可分割的原子单元，要么完全执行，要么完全回滚。\n\n2. 一致性（Consistency）：一致性确保在事务执行前后数据库的状态保持一致。在事务执行过程中，数据必须满足预定义的完整性约束和业务规则。\n\n3. 隔离性（Isolation）：隔离性确保事务的并发执行不会相互干扰，每个事务都应该像是在独立运行的环境中执行一样。事务之间的读写操作应该相互隔离，以避免数据不一致或冲突的情况。\n\n4. 持久性（Durability）：持久性确保一旦事务提交成功，对数据库的改变将永久保存，即使在系统发生故障或重启的情况下也能保持数据的完整性。\n\n为了实现 ACID 特性，数据库系统采用了一系列技术和机制：\n\n1. 事务管理：数据库系统提供了事务管理器来管理事务的提交、回滚和并发控制。事务管理器确保事务的原子性和一致性，并协调并发执行的事务之间的隔离性。\n\n2. 日志记录：数据库使用日志来记录事务的操作和改变。日志记录包括事务的开始和结束、数据的修改和回滚操作等。通过日志记录，可以在系统故障后恢复数据，并确保事务的持久性。\n\n3. 并发控制：数据库系统使用并发控制机制来处理多个事务同时访问和修改数据时可能出现的冲突。常见的并发控制技术包括锁机制、多版本并发控制（MVCC）、时间戳等。\n\n4. 数据写入策略：数据库系统通常采用缓冲区和写入策略来提高性能和持久性。数据被缓存在内存中，然后根据策略将数据写入磁盘或其他持久存储介质，以确保数据的持久性。\n\n综上所述，ACID 是数据库事务的重要特性，通过事务管理、日志记录、并发控制和持久性机制来实现。这些机制确保了事务的原子性、一致性、隔离性和持久性，从而保证了数据库系统的可靠性和数据完整性。\n```\n\nManu 数据库的设计目标主要有五个：\n\n- 长期可进化性：这个系统架构必须保证有足够的可进化性，不仅是系统整体、各个独立模块之间都要能够进化。这里想起马丁大叔书里的关于monolith/microservice 的一句论述 \"A good architecture will allow a system to be born as a monolith, deployed in a single file, but then to grow into a set of independently deployable units, and then all the way to independent services and/or micro-services.\"其实好的架构设计就是这样，各个模块要足够独立，具有独立的可迭代性。\n- 可调的一致性：Manu 引入了一种叫做 Delta consistency 的一致性，介于强一致性和总重一致性之间，用户可以调节 delta 值来决定选择一致性偏好。\n- 良好的可伸缩性：这个就不多说了，向量数据库需要应用的场景多，需要能够满足比较好的系统伸缩性，以满足不同规模不同场景的需求。\n- 高可用性：这个更不用说了，现在是个系统都得高可用。\n- 高性能：这个可以看一下最后的实验对比数据。\n- 强适配性：要求数据库能够被用于不同的环境，下到 laptop 上到 cloud，各种环境都要能用。\n\n好了，下面开始看一下整个系统的设计。\n\n首先是系统内的几个基本概念：\n- Schema：Manu 的基本数据类型有向量、字符串、布尔值、整数和浮点数。\n- Collection：类似于关系型数据库中的表，但是不同 collection 之间不存在任何关联，所以不存在类似于关系型数据库中的 join 等操作\n- Shard：Shard 其实就是数据分片，可以基于主键将一些数据哈希到不同的 shard 中\n- Segment：Segment 组成 Shard，其实也很好理解，类似于 LSM tree 中的SSTable，生成块的策略是基于块的大小或者一定时间，为了避免有些块过小，Manu 还会将一些小的块合并成大块。\n\n接着是整体系统的设计，如下图所示：\n![Alt text](../images/manu_arch.png)\n\nManu总共分四层：访问层、协调层、工作层和存储层。\n\n- 访问层：由无状态代理组成，用于提供给用户访问数据库的服务节点。这一层会执行请求分发、结果合并等操作，同时也缓存了一部分元数据，用于验证一些查询请求的合法性（比如表是否存在之类的），保证有问题的请求可以快速失败，从而减少达到下层的请求数量，优化整体的性能\n- 协调层：管理系统状态、维护 collection 的元数据，协调不同系统组件之间的任务。这一层包含四个 coordinator：Root coordinator 用于处理数据定义的请求，可以维护所有 collection 的元数据信息，新增或删除 collection；Data coordinator 用于记录 collection 的详细信息，比如 segment 在存储层的路由信息，它还会负责协调数据节点将数据更新请求转换成 binlog；Query coordinator 用于管理查询节点，负责整个查询节点的负载均衡；最后是 Index coordinator，顾名思义，负责维护元信息的索引和索引构建工作，由于向量数据库中没什么跨表的操作，所以不同 collection 的请求可以由独立的 coordinator 实例来处理\n- 工作层：负责执行具体的计算任务，这一层的工作节点都是无状态的，节点之间不需要任何的协作。工作层有多种不同类型的节点，负责不同的任务，比如：查询节点负责查询执行，索引节点负责索引构建，数据节点负责日志存档。由于节点之间任务是相互独立的，所以各类节点可以独立伸缩\n- 存储层：用于持久化系统状态、元数据、collection 和索引。Manu 使用 etcd 作为元数据存储中心，元数据先写入 etcd，再同步到协调节点。由于数据库内的其他数据（binlog、数据、索引等）非常大，所以 Manu 直接使用 AWS S3来存储，其他很多存储系统的 API 与 S3 的 API 相互兼容，所以 Manu 很容易切换到其他的存储平台。\n\nManu 遵循“log as data”的设计理念，所以日志系统是 Manu 的核心，作为 Manu 系统的骨干服务。Manu 将 WAL 和 binlog 暴露出来，作为整个系统的骨干服务。WAL 是负责增量数据，binlog 负责存量数据。Logger 负责将数据写入到 WAL 日志中，数据节点订阅 WAL 日志，将基于行的 WAL 日志转为基于列的 binlog。所有的只读组件（如索引节点和查询节点）缩回分别订阅日志服务来保证数据更新。这种架构完全解耦了读写模块，从而保证各模块可以独立伸缩。\n\nManu 会在日志中记录所有更改系统的操作，比如数据定义请求、数据操作请求、系统协调请求等。Manu 使用的是逻辑日志，而非物理日志，逻辑日志记录的是数据操作的事件，而非物理数据页面的操作。日志系统的结构如下：\n\n![Alt text](../images/manu_log_system.png)\n\n可以看出，这里用到了一致性哈希，插入请求中的 entity 会被哈希到哈希环上的一个节点。当 logger 接收到一个请求时，它会先验证请求的合法性，TSO（time service oracle）会给这个 entity 提供一个 ID，用于决定这个 entity 应该放在哪个 segment 上，并将这个 entity 写入 WAL 日志。logger 同时也会将这个 entity ID 到 segment ID 的映射写入本地的 LSM tree 中，并周期性将 LSM tree 的增量部分刷入对象存储中。每个 logger 都缓存了它所管理的 shard 的 mapping 关系。\n\nManu 的 WAL 日志试试用消息队列（Kafka or Pulsar）来实现的，这里有多个不同的 logical channel 来处理不同类型的请求，实现资源隔离，同时提高整体的数据吞吐。数据节点则会订阅 WAL，将基于行的 WAL 日志转为基于列的 binlog。列存的 binlog 能够保证单个 field 的批量读写效率，同时提高存储和 IO 的性能。索引节点则只需要读必要的 field 来构建索引，避免读放大。\n\n系统内的协调通过日志来实现，在关键操作完成时，日志系统会广播这些系统事件，日志的时序性也保证了协调消息的有序性。\n\n```markdown\nNote: 读放大（Read Amplification）和写放大（Write Amplification）是与数据库存储引擎相关的性能指标。\n\n1. 读放大：读放大指的是实际从磁盘或存储介质中读取的数据量与应用程序所请求的数据量之间的比例关系。当读放大较高时，意味着需要读取更多的数据才能满足应用程序的读取需求，从而增加了磁盘或存储介质的访问负载和读取延迟。\n\n   读放大通常出现在数据库查询中，特别是在使用索引时。例如，如果查询需要访问多个磁盘块或索引节点才能获取所需的数据，读放大就会增加。\n\n2. 写放大：写放大指的是实际写入到磁盘或存储介质的数据量与应用程序所请求的数据量之间的比例关系。当写放大较高时，意味着需要写入更多的数据才能满足应用程序的写入需求，从而增加了磁盘或存储介质的写入负载和写入延迟。\n\n   写放大通常出现在数据库的更新操作中，特别是在使用事务或写入频繁的场景中。例如，如果更新操作需要在磁盘上进行多次写入或写入大量冗余数据，写放大就会增加。\n\n高读放大和写放大会导致存储引擎性能下降、延迟增加和资源利用率降低。数据库存储引擎通过采用各种技术和优化策略来降低读放大和写放大的程度，以提高数据库系统的性能和效率。例如，使用适当的索引、缓存机制、写入合并和压缩等技术可以减少读放大和写放大的影响，提升数据库的整体性能。\n```\n\n接下来我们来看一下这篇论文提到的另一个关键点，可调的一致性。用户可以通过指定查询和数据的时间偏移量来定义“staleness tolerance”。为了满足用户使用物理时间来定义偏移量的需求，Manu 使用TSO 中的混合逻辑时钟来生成时间戳，每个时间戳包含两个部分，物理部分用于表示物理时间，逻辑部分用于表示时间的顺序。逻辑时间戳用于物理时间相同时判断不同时间的顺序。这里物理时间的时间戳是 Manu 收到这个请求的物理时间。对于一个日志订阅者而言，要实现可调的一致性，需要知道三个值：用户设置容忍的时间偏移值、最后一个数据更新的时间和查询请求签发的时间。基于这三个时间，Manu 可以决定是否需要等待最后一个数据更新的到达用户可容忍的时间区间。在强一致性下，用户可容忍的时间偏移值为 0，在最终一致性下，用户可容忍的时间偏移值为无限长。\n\n接着我们来谈谈索引构建，Manu 支持的索引类型如下：\n![Alt text](../images/manu_index.png)\n\nVector Quantization 能够压缩向量以降低内存占用，同时能够降低向量距离和相似度的计算。Inverted index 能够将向量分组到不同聚簇，这样在查询时就只需要查询最符合期望的聚簇。Proximity Graph能够将相似的向量构建成一个图，在高内存消耗的情况下实现高准确性和低延迟。\n\nManu 的索引构建有两类场景，批量索引和流式索引。批量索引是说用户在给整个 collection 构建索引，这个时候index coordinator 需要从data coordinator 那里拿到所有的 这个 collection 的segment 的路径，然后给每个 segment 构建索引。流式索引则是指用户在数据更新时异步构建索引。整个索引过程 index coordinator、data coordinator 会互相协调完成索引构建，构建完成后通知 query coordinator 使用构建好的索引来执行查询。\n\nManu支持传统向量搜索、属性过滤和多向量搜索。传统向量搜索里的相似度计算主要使用欧氏距离、内积或者角距离。属性过滤主要用于向量搜索过程中基于某些属性进行过滤，这种其实和传统关系型数据库的实现类似。多向量搜索主要是用于一个实体被编码成多个向量的场景。在执行向量搜索时，由于数据天然使用 segment 进行切片，所以不过查询节点可以处理不同 segment，以达到并发执行的目的，这样基本就不需要查询节点之间进行协调。对于一些需要聚合的操作，比如 top-k 查询，Manu 会对不同 segment 执行 top-k查询，最后将结果进行汇总。查询节点主要从三个数据源获取数据：WAL、索引文件和 binlog。为了提高查询的整体效率，Manu 将每个 segment 划分成多个切片，每个切片包含 10000 个向量，在每个切片满了的时候就为这个切片生成一个临时索引。这个索引能够带来 10 倍的性能提升。当一个 segment 满了之后，索引节点就会真正生成这个 segment 的索引，替换掉每个切片的临时索引。\n\n下面是 Manu 的几个关键 feature：\n- 云原生：Manu 的这种低耦合设计能够方便地将其部署在云环境。\n- 可使用性（Usability）：Manu 抽象了支持不同语言的查询 API，能够支持向量场景下的各类查询\n- 时间旅行（Time Travel）：Manu 允许用户基于物理时间戳来对数据库进行恢复。\n- 硬件优化：Manu 针对不同硬件进行了对应的优化，论文介绍了如何在 内存优先的查询节点利用SSD进行大数据规模的向量查询。\n\n接下来是 Manu 的几个使用案例，比如推荐、多媒体、语言、安全、药品。论文介绍了几个具体的场景，如电商推荐、病毒扫描、视频去重等，具体性能数据可以直接参考论文，这部分就不一一赘述了。\n\n下面是论文中几个实验的性能数据，贴上来给大家参考。\n\n下图是电商推荐场景不同吞吐量下的查询召回率。\n![Alt text](../images/manu_recommendation_recall.png)\n\n下图是 24 小时内真实电商流量下的 QPS 和 latency，不同颜色表示使用不同数量的查询节点。\n![Alt text](../images/manu_e_commer_real_traffic.png)\n\n下面两个图则分别展示了查询节点数量和数据规模对QPS 的影响\n\n![Alt text](../images/manu_query_node.png)\n\n下图展示的是所谓可调节的一致性对查询延迟的影响，可以看出查询延迟容忍越低，查询延迟越大。\n\n![Alt text](../images/manu_grace_time.png)\n\n最后是不同数据规模下索引构建时间\n\n![Alt text](../images/manu_index_build.png)","slug":"papers/Manu","published":1,"updated":"2023-07-30T06:11:37.246Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6ix000a1ts12k768hix","content":"<p>这篇文章同样是 VLDB 的一篇文章，讲的是云原生向量数据库。</p>\n<span id=\"more\"></span>\n\n<p>首先按照惯例问一下 chatGPT，什么是向量数据库：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">向量数据库（Vector Database）是一种专门用于存储、管理和查询向量数据的数据库系统。向量数据是由向量（Vector）组成的数据集合，其中每个向量代表了一个数据点或实体的特征表示。</span><br><span class=\"line\"></span><br><span class=\"line\">传统的关系型数据库或文档型数据库主要以标量数据为基础，而向量数据库专注于处理和分析向量数据。它提供了针对向量数据的高效存储和检索机制，以及针对向量的特定操作和查询功能。</span><br><span class=\"line\"></span><br><span class=\"line\">向量数据库通常具备以下特点和功能：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 高维向量存储：向量数据库能够有效地存储和管理高维向量数据。它使用高效的数据结构和索引机制，以支持在大规模向量集合中进行高效的查询和分析。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 向量相似性搜索：向量数据库提供了针对向量相似性搜索的功能。它能够根据向量之间的相似性度量，如欧氏距离、余弦相似度等，快速检索最相似的向量。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 向量索引：为了加速查询速度，向量数据库使用特定的索引结构，如KD-Tree、LSH（局部敏感哈希）等，以支持高效的向量搜索和匹配。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 向量操作和计算：向量数据库提供了针对向量的操作和计算功能，如向量加法、向量乘法、向量投影等。这些功能使得在向量数据上进行复杂的分析和计算成为可能。</span><br><span class=\"line\"></span><br><span class=\"line\">5. 分布式架构：为了应对大规模向量数据的处理需求，一些向量数据库采用分布式架构，允许在多个节点上存储和处理向量数据，以提高吞吐量和可扩展性。</span><br><span class=\"line\"></span><br><span class=\"line\">向量数据库在许多领域都具有广泛的应用，包括机器学习、图像识别、自然语言处理、推荐系统等。它们为处理和分析大规模向量数据提供了高效的存储和查询解决方案，推动了向量数据应用领域的发展和创新。</span><br></pre></td></tr></table></figure>\n\n<p>论文开篇就介绍了向量数据库与传统数据库在相应应用场景下的区别：</p>\n<ul>\n<li>向量数据库不太需要支持复杂的事务</li>\n<li>向量数据库需要能调整性能和一致性之间平衡</li>\n<li>向量数据库的硬件开销较大，所以需要足够细粒度的可伸缩性</li>\n</ul>\n<p>文章主要有以下贡献：</p>\n<ul>\n<li>文章总结了过去三年内跟 1200 个工业用户沟通所得到的经验，阐明了向量数据库和传统数据库的区别，并列出了向量数据库需要满足的设计目标</li>\n<li>文章介绍了 Manu 这个云原生向量数据库的关键架构设计，介绍了如何在减少事务实现复杂度之后如何获得可调节的一致性和细粒度可伸缩性</li>\n<li>文章同时还介绍了一些在可使用性（Usability）和性能上的优化设计</li>\n</ul>\n<p>接下来我们系统过一下整篇文章，首先是背景和动机。如上文所述，向量数据库主要应用在一些向量数据相关的场景，比如视频推荐场景下，视频和用户的各类关键信息会被编码成一个高维的向量数据，通过计算向量之间的相似度，我们可以为用户实现视频推荐等功能。然而，在这类场景下，不管是视频或者其他被推荐的内容还是用户数据本身，数据规模都极大。传统的关系型数据库并不能很好地应对这类场景，向量数据库有着不同的需求：</p>\n<p>首先，向量数据库的应用场景在不断地变革当中，因此向量数据库本身也需要能够满足各类场景下的不同需求；其次，向量数据库并不需要复杂事务，因为向量数据往往被编码到一个单独的向量中，并不需要多行或者多列的复杂事务操作，因此只要行级的 ACID 即可满足要求。再者，向量数据库需要灵活的性能与一致性之间的平衡，因为不同场景下用户的需求不同，有的侧重系统吞吐，有的关注一致性，向量数据库需要能够灵活配置这些需求。最后，由于向量数据库的特定场景需求，向量数据库需要能够利用到各类硬件加速能力，同时，由于数据局部性较差，其还需要较大的 RAM，在不同场景下，硬件的需求也不同，有的需要高并发的向量搜索，有的只需要满足离线数据导入和索引需求即可，所以为了应对不同场景，向量数据库需要足够灵活的可伸缩性。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: ACID基本是面试任何数据库团队甚至一些业务团队必考到的内容了，在回答 ACID 是什么的基础上，我们经常还会聊到 ACID 是如何实现的，这类问题网上的解释很多，我随便贴个 chatGPT的回答如下：</span><br><span class=\"line\"></span><br><span class=\"line\">ACID 是数据库事务的四个关键特性的缩写，它们分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。这些特性确保了数据库事务的可靠性、可预测性和完整性。</span><br><span class=\"line\"></span><br><span class=\"line\">1. 原子性（Atomicity）：原子性确保事务中的所有操作要么全部成功完成，要么全部失败回滚。事务被视为一个不可分割的原子单元，要么完全执行，要么完全回滚。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 一致性（Consistency）：一致性确保在事务执行前后数据库的状态保持一致。在事务执行过程中，数据必须满足预定义的完整性约束和业务规则。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 隔离性（Isolation）：隔离性确保事务的并发执行不会相互干扰，每个事务都应该像是在独立运行的环境中执行一样。事务之间的读写操作应该相互隔离，以避免数据不一致或冲突的情况。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 持久性（Durability）：持久性确保一旦事务提交成功，对数据库的改变将永久保存，即使在系统发生故障或重启的情况下也能保持数据的完整性。</span><br><span class=\"line\"></span><br><span class=\"line\">为了实现 ACID 特性，数据库系统采用了一系列技术和机制：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 事务管理：数据库系统提供了事务管理器来管理事务的提交、回滚和并发控制。事务管理器确保事务的原子性和一致性，并协调并发执行的事务之间的隔离性。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 日志记录：数据库使用日志来记录事务的操作和改变。日志记录包括事务的开始和结束、数据的修改和回滚操作等。通过日志记录，可以在系统故障后恢复数据，并确保事务的持久性。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 并发控制：数据库系统使用并发控制机制来处理多个事务同时访问和修改数据时可能出现的冲突。常见的并发控制技术包括锁机制、多版本并发控制（MVCC）、时间戳等。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 数据写入策略：数据库系统通常采用缓冲区和写入策略来提高性能和持久性。数据被缓存在内存中，然后根据策略将数据写入磁盘或其他持久存储介质，以确保数据的持久性。</span><br><span class=\"line\"></span><br><span class=\"line\">综上所述，ACID 是数据库事务的重要特性，通过事务管理、日志记录、并发控制和持久性机制来实现。这些机制确保了事务的原子性、一致性、隔离性和持久性，从而保证了数据库系统的可靠性和数据完整性。</span><br></pre></td></tr></table></figure>\n\n<p>Manu 数据库的设计目标主要有五个：</p>\n<ul>\n<li>长期可进化性：这个系统架构必须保证有足够的可进化性，不仅是系统整体、各个独立模块之间都要能够进化。这里想起马丁大叔书里的关于monolith&#x2F;microservice 的一句论述 “A good architecture will allow a system to be born as a monolith, deployed in a single file, but then to grow into a set of independently deployable units, and then all the way to independent services and&#x2F;or micro-services.”其实好的架构设计就是这样，各个模块要足够独立，具有独立的可迭代性。</li>\n<li>可调的一致性：Manu 引入了一种叫做 Delta consistency 的一致性，介于强一致性和总重一致性之间，用户可以调节 delta 值来决定选择一致性偏好。</li>\n<li>良好的可伸缩性：这个就不多说了，向量数据库需要应用的场景多，需要能够满足比较好的系统伸缩性，以满足不同规模不同场景的需求。</li>\n<li>高可用性：这个更不用说了，现在是个系统都得高可用。</li>\n<li>高性能：这个可以看一下最后的实验对比数据。</li>\n<li>强适配性：要求数据库能够被用于不同的环境，下到 laptop 上到 cloud，各种环境都要能用。</li>\n</ul>\n<p>好了，下面开始看一下整个系统的设计。</p>\n<p>首先是系统内的几个基本概念：</p>\n<ul>\n<li>Schema：Manu 的基本数据类型有向量、字符串、布尔值、整数和浮点数。</li>\n<li>Collection：类似于关系型数据库中的表，但是不同 collection 之间不存在任何关联，所以不存在类似于关系型数据库中的 join 等操作</li>\n<li>Shard：Shard 其实就是数据分片，可以基于主键将一些数据哈希到不同的 shard 中</li>\n<li>Segment：Segment 组成 Shard，其实也很好理解，类似于 LSM tree 中的SSTable，生成块的策略是基于块的大小或者一定时间，为了避免有些块过小，Manu 还会将一些小的块合并成大块。</li>\n</ul>\n<p>接着是整体系统的设计，如下图所示：<br><img src=\"/../images/manu_arch.png\" alt=\"Alt text\"></p>\n<p>Manu总共分四层：访问层、协调层、工作层和存储层。</p>\n<ul>\n<li>访问层：由无状态代理组成，用于提供给用户访问数据库的服务节点。这一层会执行请求分发、结果合并等操作，同时也缓存了一部分元数据，用于验证一些查询请求的合法性（比如表是否存在之类的），保证有问题的请求可以快速失败，从而减少达到下层的请求数量，优化整体的性能</li>\n<li>协调层：管理系统状态、维护 collection 的元数据，协调不同系统组件之间的任务。这一层包含四个 coordinator：Root coordinator 用于处理数据定义的请求，可以维护所有 collection 的元数据信息，新增或删除 collection；Data coordinator 用于记录 collection 的详细信息，比如 segment 在存储层的路由信息，它还会负责协调数据节点将数据更新请求转换成 binlog；Query coordinator 用于管理查询节点，负责整个查询节点的负载均衡；最后是 Index coordinator，顾名思义，负责维护元信息的索引和索引构建工作，由于向量数据库中没什么跨表的操作，所以不同 collection 的请求可以由独立的 coordinator 实例来处理</li>\n<li>工作层：负责执行具体的计算任务，这一层的工作节点都是无状态的，节点之间不需要任何的协作。工作层有多种不同类型的节点，负责不同的任务，比如：查询节点负责查询执行，索引节点负责索引构建，数据节点负责日志存档。由于节点之间任务是相互独立的，所以各类节点可以独立伸缩</li>\n<li>存储层：用于持久化系统状态、元数据、collection 和索引。Manu 使用 etcd 作为元数据存储中心，元数据先写入 etcd，再同步到协调节点。由于数据库内的其他数据（binlog、数据、索引等）非常大，所以 Manu 直接使用 AWS S3来存储，其他很多存储系统的 API 与 S3 的 API 相互兼容，所以 Manu 很容易切换到其他的存储平台。</li>\n</ul>\n<p>Manu 遵循“log as data”的设计理念，所以日志系统是 Manu 的核心，作为 Manu 系统的骨干服务。Manu 将 WAL 和 binlog 暴露出来，作为整个系统的骨干服务。WAL 是负责增量数据，binlog 负责存量数据。Logger 负责将数据写入到 WAL 日志中，数据节点订阅 WAL 日志，将基于行的 WAL 日志转为基于列的 binlog。所有的只读组件（如索引节点和查询节点）缩回分别订阅日志服务来保证数据更新。这种架构完全解耦了读写模块，从而保证各模块可以独立伸缩。</p>\n<p>Manu 会在日志中记录所有更改系统的操作，比如数据定义请求、数据操作请求、系统协调请求等。Manu 使用的是逻辑日志，而非物理日志，逻辑日志记录的是数据操作的事件，而非物理数据页面的操作。日志系统的结构如下：</p>\n<p><img src=\"/../images/manu_log_system.png\" alt=\"Alt text\"></p>\n<p>可以看出，这里用到了一致性哈希，插入请求中的 entity 会被哈希到哈希环上的一个节点。当 logger 接收到一个请求时，它会先验证请求的合法性，TSO（time service oracle）会给这个 entity 提供一个 ID，用于决定这个 entity 应该放在哪个 segment 上，并将这个 entity 写入 WAL 日志。logger 同时也会将这个 entity ID 到 segment ID 的映射写入本地的 LSM tree 中，并周期性将 LSM tree 的增量部分刷入对象存储中。每个 logger 都缓存了它所管理的 shard 的 mapping 关系。</p>\n<p>Manu 的 WAL 日志试试用消息队列（Kafka or Pulsar）来实现的，这里有多个不同的 logical channel 来处理不同类型的请求，实现资源隔离，同时提高整体的数据吞吐。数据节点则会订阅 WAL，将基于行的 WAL 日志转为基于列的 binlog。列存的 binlog 能够保证单个 field 的批量读写效率，同时提高存储和 IO 的性能。索引节点则只需要读必要的 field 来构建索引，避免读放大。</p>\n<p>系统内的协调通过日志来实现，在关键操作完成时，日志系统会广播这些系统事件，日志的时序性也保证了协调消息的有序性。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: 读放大（Read Amplification）和写放大（Write Amplification）是与数据库存储引擎相关的性能指标。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 读放大：读放大指的是实际从磁盘或存储介质中读取的数据量与应用程序所请求的数据量之间的比例关系。当读放大较高时，意味着需要读取更多的数据才能满足应用程序的读取需求，从而增加了磁盘或存储介质的访问负载和读取延迟。</span><br><span class=\"line\"></span><br><span class=\"line\">   读放大通常出现在数据库查询中，特别是在使用索引时。例如，如果查询需要访问多个磁盘块或索引节点才能获取所需的数据，读放大就会增加。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 写放大：写放大指的是实际写入到磁盘或存储介质的数据量与应用程序所请求的数据量之间的比例关系。当写放大较高时，意味着需要写入更多的数据才能满足应用程序的写入需求，从而增加了磁盘或存储介质的写入负载和写入延迟。</span><br><span class=\"line\"></span><br><span class=\"line\">   写放大通常出现在数据库的更新操作中，特别是在使用事务或写入频繁的场景中。例如，如果更新操作需要在磁盘上进行多次写入或写入大量冗余数据，写放大就会增加。</span><br><span class=\"line\"></span><br><span class=\"line\">高读放大和写放大会导致存储引擎性能下降、延迟增加和资源利用率降低。数据库存储引擎通过采用各种技术和优化策略来降低读放大和写放大的程度，以提高数据库系统的性能和效率。例如，使用适当的索引、缓存机制、写入合并和压缩等技术可以减少读放大和写放大的影响，提升数据库的整体性能。</span><br></pre></td></tr></table></figure>\n\n<p>接下来我们来看一下这篇论文提到的另一个关键点，可调的一致性。用户可以通过指定查询和数据的时间偏移量来定义“staleness tolerance”。为了满足用户使用物理时间来定义偏移量的需求，Manu 使用TSO 中的混合逻辑时钟来生成时间戳，每个时间戳包含两个部分，物理部分用于表示物理时间，逻辑部分用于表示时间的顺序。逻辑时间戳用于物理时间相同时判断不同时间的顺序。这里物理时间的时间戳是 Manu 收到这个请求的物理时间。对于一个日志订阅者而言，要实现可调的一致性，需要知道三个值：用户设置容忍的时间偏移值、最后一个数据更新的时间和查询请求签发的时间。基于这三个时间，Manu 可以决定是否需要等待最后一个数据更新的到达用户可容忍的时间区间。在强一致性下，用户可容忍的时间偏移值为 0，在最终一致性下，用户可容忍的时间偏移值为无限长。</p>\n<p>接着我们来谈谈索引构建，Manu 支持的索引类型如下：<br><img src=\"/../images/manu_index.png\" alt=\"Alt text\"></p>\n<p>Vector Quantization 能够压缩向量以降低内存占用，同时能够降低向量距离和相似度的计算。Inverted index 能够将向量分组到不同聚簇，这样在查询时就只需要查询最符合期望的聚簇。Proximity Graph能够将相似的向量构建成一个图，在高内存消耗的情况下实现高准确性和低延迟。</p>\n<p>Manu 的索引构建有两类场景，批量索引和流式索引。批量索引是说用户在给整个 collection 构建索引，这个时候index coordinator 需要从data coordinator 那里拿到所有的 这个 collection 的segment 的路径，然后给每个 segment 构建索引。流式索引则是指用户在数据更新时异步构建索引。整个索引过程 index coordinator、data coordinator 会互相协调完成索引构建，构建完成后通知 query coordinator 使用构建好的索引来执行查询。</p>\n<p>Manu支持传统向量搜索、属性过滤和多向量搜索。传统向量搜索里的相似度计算主要使用欧氏距离、内积或者角距离。属性过滤主要用于向量搜索过程中基于某些属性进行过滤，这种其实和传统关系型数据库的实现类似。多向量搜索主要是用于一个实体被编码成多个向量的场景。在执行向量搜索时，由于数据天然使用 segment 进行切片，所以不过查询节点可以处理不同 segment，以达到并发执行的目的，这样基本就不需要查询节点之间进行协调。对于一些需要聚合的操作，比如 top-k 查询，Manu 会对不同 segment 执行 top-k查询，最后将结果进行汇总。查询节点主要从三个数据源获取数据：WAL、索引文件和 binlog。为了提高查询的整体效率，Manu 将每个 segment 划分成多个切片，每个切片包含 10000 个向量，在每个切片满了的时候就为这个切片生成一个临时索引。这个索引能够带来 10 倍的性能提升。当一个 segment 满了之后，索引节点就会真正生成这个 segment 的索引，替换掉每个切片的临时索引。</p>\n<p>下面是 Manu 的几个关键 feature：</p>\n<ul>\n<li>云原生：Manu 的这种低耦合设计能够方便地将其部署在云环境。</li>\n<li>可使用性（Usability）：Manu 抽象了支持不同语言的查询 API，能够支持向量场景下的各类查询</li>\n<li>时间旅行（Time Travel）：Manu 允许用户基于物理时间戳来对数据库进行恢复。</li>\n<li>硬件优化：Manu 针对不同硬件进行了对应的优化，论文介绍了如何在 内存优先的查询节点利用SSD进行大数据规模的向量查询。</li>\n</ul>\n<p>接下来是 Manu 的几个使用案例，比如推荐、多媒体、语言、安全、药品。论文介绍了几个具体的场景，如电商推荐、病毒扫描、视频去重等，具体性能数据可以直接参考论文，这部分就不一一赘述了。</p>\n<p>下面是论文中几个实验的性能数据，贴上来给大家参考。</p>\n<p>下图是电商推荐场景不同吞吐量下的查询召回率。<br><img src=\"/../images/manu_recommendation_recall.png\" alt=\"Alt text\"></p>\n<p>下图是 24 小时内真实电商流量下的 QPS 和 latency，不同颜色表示使用不同数量的查询节点。<br><img src=\"/../images/manu_e_commer_real_traffic.png\" alt=\"Alt text\"></p>\n<p>下面两个图则分别展示了查询节点数量和数据规模对QPS 的影响</p>\n<p><img src=\"/../images/manu_query_node.png\" alt=\"Alt text\"></p>\n<p>下图展示的是所谓可调节的一致性对查询延迟的影响，可以看出查询延迟容忍越低，查询延迟越大。</p>\n<p><img src=\"/../images/manu_grace_time.png\" alt=\"Alt text\"></p>\n<p>最后是不同数据规模下索引构建时间</p>\n<p><img src=\"/../images/manu_index_build.png\" alt=\"Alt text\"></p>\n","site":{"data":{}},"excerpt":"<p>这篇文章同样是 VLDB 的一篇文章，讲的是云原生向量数据库。</p>","more":"<p>首先按照惯例问一下 chatGPT，什么是向量数据库：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">向量数据库（Vector Database）是一种专门用于存储、管理和查询向量数据的数据库系统。向量数据是由向量（Vector）组成的数据集合，其中每个向量代表了一个数据点或实体的特征表示。</span><br><span class=\"line\"></span><br><span class=\"line\">传统的关系型数据库或文档型数据库主要以标量数据为基础，而向量数据库专注于处理和分析向量数据。它提供了针对向量数据的高效存储和检索机制，以及针对向量的特定操作和查询功能。</span><br><span class=\"line\"></span><br><span class=\"line\">向量数据库通常具备以下特点和功能：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 高维向量存储：向量数据库能够有效地存储和管理高维向量数据。它使用高效的数据结构和索引机制，以支持在大规模向量集合中进行高效的查询和分析。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 向量相似性搜索：向量数据库提供了针对向量相似性搜索的功能。它能够根据向量之间的相似性度量，如欧氏距离、余弦相似度等，快速检索最相似的向量。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 向量索引：为了加速查询速度，向量数据库使用特定的索引结构，如KD-Tree、LSH（局部敏感哈希）等，以支持高效的向量搜索和匹配。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 向量操作和计算：向量数据库提供了针对向量的操作和计算功能，如向量加法、向量乘法、向量投影等。这些功能使得在向量数据上进行复杂的分析和计算成为可能。</span><br><span class=\"line\"></span><br><span class=\"line\">5. 分布式架构：为了应对大规模向量数据的处理需求，一些向量数据库采用分布式架构，允许在多个节点上存储和处理向量数据，以提高吞吐量和可扩展性。</span><br><span class=\"line\"></span><br><span class=\"line\">向量数据库在许多领域都具有广泛的应用，包括机器学习、图像识别、自然语言处理、推荐系统等。它们为处理和分析大规模向量数据提供了高效的存储和查询解决方案，推动了向量数据应用领域的发展和创新。</span><br></pre></td></tr></table></figure>\n\n<p>论文开篇就介绍了向量数据库与传统数据库在相应应用场景下的区别：</p>\n<ul>\n<li>向量数据库不太需要支持复杂的事务</li>\n<li>向量数据库需要能调整性能和一致性之间平衡</li>\n<li>向量数据库的硬件开销较大，所以需要足够细粒度的可伸缩性</li>\n</ul>\n<p>文章主要有以下贡献：</p>\n<ul>\n<li>文章总结了过去三年内跟 1200 个工业用户沟通所得到的经验，阐明了向量数据库和传统数据库的区别，并列出了向量数据库需要满足的设计目标</li>\n<li>文章介绍了 Manu 这个云原生向量数据库的关键架构设计，介绍了如何在减少事务实现复杂度之后如何获得可调节的一致性和细粒度可伸缩性</li>\n<li>文章同时还介绍了一些在可使用性（Usability）和性能上的优化设计</li>\n</ul>\n<p>接下来我们系统过一下整篇文章，首先是背景和动机。如上文所述，向量数据库主要应用在一些向量数据相关的场景，比如视频推荐场景下，视频和用户的各类关键信息会被编码成一个高维的向量数据，通过计算向量之间的相似度，我们可以为用户实现视频推荐等功能。然而，在这类场景下，不管是视频或者其他被推荐的内容还是用户数据本身，数据规模都极大。传统的关系型数据库并不能很好地应对这类场景，向量数据库有着不同的需求：</p>\n<p>首先，向量数据库的应用场景在不断地变革当中，因此向量数据库本身也需要能够满足各类场景下的不同需求；其次，向量数据库并不需要复杂事务，因为向量数据往往被编码到一个单独的向量中，并不需要多行或者多列的复杂事务操作，因此只要行级的 ACID 即可满足要求。再者，向量数据库需要灵活的性能与一致性之间的平衡，因为不同场景下用户的需求不同，有的侧重系统吞吐，有的关注一致性，向量数据库需要能够灵活配置这些需求。最后，由于向量数据库的特定场景需求，向量数据库需要能够利用到各类硬件加速能力，同时，由于数据局部性较差，其还需要较大的 RAM，在不同场景下，硬件的需求也不同，有的需要高并发的向量搜索，有的只需要满足离线数据导入和索引需求即可，所以为了应对不同场景，向量数据库需要足够灵活的可伸缩性。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: ACID基本是面试任何数据库团队甚至一些业务团队必考到的内容了，在回答 ACID 是什么的基础上，我们经常还会聊到 ACID 是如何实现的，这类问题网上的解释很多，我随便贴个 chatGPT的回答如下：</span><br><span class=\"line\"></span><br><span class=\"line\">ACID 是数据库事务的四个关键特性的缩写，它们分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。这些特性确保了数据库事务的可靠性、可预测性和完整性。</span><br><span class=\"line\"></span><br><span class=\"line\">1. 原子性（Atomicity）：原子性确保事务中的所有操作要么全部成功完成，要么全部失败回滚。事务被视为一个不可分割的原子单元，要么完全执行，要么完全回滚。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 一致性（Consistency）：一致性确保在事务执行前后数据库的状态保持一致。在事务执行过程中，数据必须满足预定义的完整性约束和业务规则。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 隔离性（Isolation）：隔离性确保事务的并发执行不会相互干扰，每个事务都应该像是在独立运行的环境中执行一样。事务之间的读写操作应该相互隔离，以避免数据不一致或冲突的情况。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 持久性（Durability）：持久性确保一旦事务提交成功，对数据库的改变将永久保存，即使在系统发生故障或重启的情况下也能保持数据的完整性。</span><br><span class=\"line\"></span><br><span class=\"line\">为了实现 ACID 特性，数据库系统采用了一系列技术和机制：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 事务管理：数据库系统提供了事务管理器来管理事务的提交、回滚和并发控制。事务管理器确保事务的原子性和一致性，并协调并发执行的事务之间的隔离性。</span><br><span class=\"line\"></span><br><span class=\"line\">2. 日志记录：数据库使用日志来记录事务的操作和改变。日志记录包括事务的开始和结束、数据的修改和回滚操作等。通过日志记录，可以在系统故障后恢复数据，并确保事务的持久性。</span><br><span class=\"line\"></span><br><span class=\"line\">3. 并发控制：数据库系统使用并发控制机制来处理多个事务同时访问和修改数据时可能出现的冲突。常见的并发控制技术包括锁机制、多版本并发控制（MVCC）、时间戳等。</span><br><span class=\"line\"></span><br><span class=\"line\">4. 数据写入策略：数据库系统通常采用缓冲区和写入策略来提高性能和持久性。数据被缓存在内存中，然后根据策略将数据写入磁盘或其他持久存储介质，以确保数据的持久性。</span><br><span class=\"line\"></span><br><span class=\"line\">综上所述，ACID 是数据库事务的重要特性，通过事务管理、日志记录、并发控制和持久性机制来实现。这些机制确保了事务的原子性、一致性、隔离性和持久性，从而保证了数据库系统的可靠性和数据完整性。</span><br></pre></td></tr></table></figure>\n\n<p>Manu 数据库的设计目标主要有五个：</p>\n<ul>\n<li>长期可进化性：这个系统架构必须保证有足够的可进化性，不仅是系统整体、各个独立模块之间都要能够进化。这里想起马丁大叔书里的关于monolith&#x2F;microservice 的一句论述 “A good architecture will allow a system to be born as a monolith, deployed in a single file, but then to grow into a set of independently deployable units, and then all the way to independent services and&#x2F;or micro-services.”其实好的架构设计就是这样，各个模块要足够独立，具有独立的可迭代性。</li>\n<li>可调的一致性：Manu 引入了一种叫做 Delta consistency 的一致性，介于强一致性和总重一致性之间，用户可以调节 delta 值来决定选择一致性偏好。</li>\n<li>良好的可伸缩性：这个就不多说了，向量数据库需要应用的场景多，需要能够满足比较好的系统伸缩性，以满足不同规模不同场景的需求。</li>\n<li>高可用性：这个更不用说了，现在是个系统都得高可用。</li>\n<li>高性能：这个可以看一下最后的实验对比数据。</li>\n<li>强适配性：要求数据库能够被用于不同的环境，下到 laptop 上到 cloud，各种环境都要能用。</li>\n</ul>\n<p>好了，下面开始看一下整个系统的设计。</p>\n<p>首先是系统内的几个基本概念：</p>\n<ul>\n<li>Schema：Manu 的基本数据类型有向量、字符串、布尔值、整数和浮点数。</li>\n<li>Collection：类似于关系型数据库中的表，但是不同 collection 之间不存在任何关联，所以不存在类似于关系型数据库中的 join 等操作</li>\n<li>Shard：Shard 其实就是数据分片，可以基于主键将一些数据哈希到不同的 shard 中</li>\n<li>Segment：Segment 组成 Shard，其实也很好理解，类似于 LSM tree 中的SSTable，生成块的策略是基于块的大小或者一定时间，为了避免有些块过小，Manu 还会将一些小的块合并成大块。</li>\n</ul>\n<p>接着是整体系统的设计，如下图所示：<br><img src=\"/../images/manu_arch.png\" alt=\"Alt text\"></p>\n<p>Manu总共分四层：访问层、协调层、工作层和存储层。</p>\n<ul>\n<li>访问层：由无状态代理组成，用于提供给用户访问数据库的服务节点。这一层会执行请求分发、结果合并等操作，同时也缓存了一部分元数据，用于验证一些查询请求的合法性（比如表是否存在之类的），保证有问题的请求可以快速失败，从而减少达到下层的请求数量，优化整体的性能</li>\n<li>协调层：管理系统状态、维护 collection 的元数据，协调不同系统组件之间的任务。这一层包含四个 coordinator：Root coordinator 用于处理数据定义的请求，可以维护所有 collection 的元数据信息，新增或删除 collection；Data coordinator 用于记录 collection 的详细信息，比如 segment 在存储层的路由信息，它还会负责协调数据节点将数据更新请求转换成 binlog；Query coordinator 用于管理查询节点，负责整个查询节点的负载均衡；最后是 Index coordinator，顾名思义，负责维护元信息的索引和索引构建工作，由于向量数据库中没什么跨表的操作，所以不同 collection 的请求可以由独立的 coordinator 实例来处理</li>\n<li>工作层：负责执行具体的计算任务，这一层的工作节点都是无状态的，节点之间不需要任何的协作。工作层有多种不同类型的节点，负责不同的任务，比如：查询节点负责查询执行，索引节点负责索引构建，数据节点负责日志存档。由于节点之间任务是相互独立的，所以各类节点可以独立伸缩</li>\n<li>存储层：用于持久化系统状态、元数据、collection 和索引。Manu 使用 etcd 作为元数据存储中心，元数据先写入 etcd，再同步到协调节点。由于数据库内的其他数据（binlog、数据、索引等）非常大，所以 Manu 直接使用 AWS S3来存储，其他很多存储系统的 API 与 S3 的 API 相互兼容，所以 Manu 很容易切换到其他的存储平台。</li>\n</ul>\n<p>Manu 遵循“log as data”的设计理念，所以日志系统是 Manu 的核心，作为 Manu 系统的骨干服务。Manu 将 WAL 和 binlog 暴露出来，作为整个系统的骨干服务。WAL 是负责增量数据，binlog 负责存量数据。Logger 负责将数据写入到 WAL 日志中，数据节点订阅 WAL 日志，将基于行的 WAL 日志转为基于列的 binlog。所有的只读组件（如索引节点和查询节点）缩回分别订阅日志服务来保证数据更新。这种架构完全解耦了读写模块，从而保证各模块可以独立伸缩。</p>\n<p>Manu 会在日志中记录所有更改系统的操作，比如数据定义请求、数据操作请求、系统协调请求等。Manu 使用的是逻辑日志，而非物理日志，逻辑日志记录的是数据操作的事件，而非物理数据页面的操作。日志系统的结构如下：</p>\n<p><img src=\"/../images/manu_log_system.png\" alt=\"Alt text\"></p>\n<p>可以看出，这里用到了一致性哈希，插入请求中的 entity 会被哈希到哈希环上的一个节点。当 logger 接收到一个请求时，它会先验证请求的合法性，TSO（time service oracle）会给这个 entity 提供一个 ID，用于决定这个 entity 应该放在哪个 segment 上，并将这个 entity 写入 WAL 日志。logger 同时也会将这个 entity ID 到 segment ID 的映射写入本地的 LSM tree 中，并周期性将 LSM tree 的增量部分刷入对象存储中。每个 logger 都缓存了它所管理的 shard 的 mapping 关系。</p>\n<p>Manu 的 WAL 日志试试用消息队列（Kafka or Pulsar）来实现的，这里有多个不同的 logical channel 来处理不同类型的请求，实现资源隔离，同时提高整体的数据吞吐。数据节点则会订阅 WAL，将基于行的 WAL 日志转为基于列的 binlog。列存的 binlog 能够保证单个 field 的批量读写效率，同时提高存储和 IO 的性能。索引节点则只需要读必要的 field 来构建索引，避免读放大。</p>\n<p>系统内的协调通过日志来实现，在关键操作完成时，日志系统会广播这些系统事件，日志的时序性也保证了协调消息的有序性。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: 读放大（Read Amplification）和写放大（Write Amplification）是与数据库存储引擎相关的性能指标。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 读放大：读放大指的是实际从磁盘或存储介质中读取的数据量与应用程序所请求的数据量之间的比例关系。当读放大较高时，意味着需要读取更多的数据才能满足应用程序的读取需求，从而增加了磁盘或存储介质的访问负载和读取延迟。</span><br><span class=\"line\"></span><br><span class=\"line\">   读放大通常出现在数据库查询中，特别是在使用索引时。例如，如果查询需要访问多个磁盘块或索引节点才能获取所需的数据，读放大就会增加。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 写放大：写放大指的是实际写入到磁盘或存储介质的数据量与应用程序所请求的数据量之间的比例关系。当写放大较高时，意味着需要写入更多的数据才能满足应用程序的写入需求，从而增加了磁盘或存储介质的写入负载和写入延迟。</span><br><span class=\"line\"></span><br><span class=\"line\">   写放大通常出现在数据库的更新操作中，特别是在使用事务或写入频繁的场景中。例如，如果更新操作需要在磁盘上进行多次写入或写入大量冗余数据，写放大就会增加。</span><br><span class=\"line\"></span><br><span class=\"line\">高读放大和写放大会导致存储引擎性能下降、延迟增加和资源利用率降低。数据库存储引擎通过采用各种技术和优化策略来降低读放大和写放大的程度，以提高数据库系统的性能和效率。例如，使用适当的索引、缓存机制、写入合并和压缩等技术可以减少读放大和写放大的影响，提升数据库的整体性能。</span><br></pre></td></tr></table></figure>\n\n<p>接下来我们来看一下这篇论文提到的另一个关键点，可调的一致性。用户可以通过指定查询和数据的时间偏移量来定义“staleness tolerance”。为了满足用户使用物理时间来定义偏移量的需求，Manu 使用TSO 中的混合逻辑时钟来生成时间戳，每个时间戳包含两个部分，物理部分用于表示物理时间，逻辑部分用于表示时间的顺序。逻辑时间戳用于物理时间相同时判断不同时间的顺序。这里物理时间的时间戳是 Manu 收到这个请求的物理时间。对于一个日志订阅者而言，要实现可调的一致性，需要知道三个值：用户设置容忍的时间偏移值、最后一个数据更新的时间和查询请求签发的时间。基于这三个时间，Manu 可以决定是否需要等待最后一个数据更新的到达用户可容忍的时间区间。在强一致性下，用户可容忍的时间偏移值为 0，在最终一致性下，用户可容忍的时间偏移值为无限长。</p>\n<p>接着我们来谈谈索引构建，Manu 支持的索引类型如下：<br><img src=\"/../images/manu_index.png\" alt=\"Alt text\"></p>\n<p>Vector Quantization 能够压缩向量以降低内存占用，同时能够降低向量距离和相似度的计算。Inverted index 能够将向量分组到不同聚簇，这样在查询时就只需要查询最符合期望的聚簇。Proximity Graph能够将相似的向量构建成一个图，在高内存消耗的情况下实现高准确性和低延迟。</p>\n<p>Manu 的索引构建有两类场景，批量索引和流式索引。批量索引是说用户在给整个 collection 构建索引，这个时候index coordinator 需要从data coordinator 那里拿到所有的 这个 collection 的segment 的路径，然后给每个 segment 构建索引。流式索引则是指用户在数据更新时异步构建索引。整个索引过程 index coordinator、data coordinator 会互相协调完成索引构建，构建完成后通知 query coordinator 使用构建好的索引来执行查询。</p>\n<p>Manu支持传统向量搜索、属性过滤和多向量搜索。传统向量搜索里的相似度计算主要使用欧氏距离、内积或者角距离。属性过滤主要用于向量搜索过程中基于某些属性进行过滤，这种其实和传统关系型数据库的实现类似。多向量搜索主要是用于一个实体被编码成多个向量的场景。在执行向量搜索时，由于数据天然使用 segment 进行切片，所以不过查询节点可以处理不同 segment，以达到并发执行的目的，这样基本就不需要查询节点之间进行协调。对于一些需要聚合的操作，比如 top-k 查询，Manu 会对不同 segment 执行 top-k查询，最后将结果进行汇总。查询节点主要从三个数据源获取数据：WAL、索引文件和 binlog。为了提高查询的整体效率，Manu 将每个 segment 划分成多个切片，每个切片包含 10000 个向量，在每个切片满了的时候就为这个切片生成一个临时索引。这个索引能够带来 10 倍的性能提升。当一个 segment 满了之后，索引节点就会真正生成这个 segment 的索引，替换掉每个切片的临时索引。</p>\n<p>下面是 Manu 的几个关键 feature：</p>\n<ul>\n<li>云原生：Manu 的这种低耦合设计能够方便地将其部署在云环境。</li>\n<li>可使用性（Usability）：Manu 抽象了支持不同语言的查询 API，能够支持向量场景下的各类查询</li>\n<li>时间旅行（Time Travel）：Manu 允许用户基于物理时间戳来对数据库进行恢复。</li>\n<li>硬件优化：Manu 针对不同硬件进行了对应的优化，论文介绍了如何在 内存优先的查询节点利用SSD进行大数据规模的向量查询。</li>\n</ul>\n<p>接下来是 Manu 的几个使用案例，比如推荐、多媒体、语言、安全、药品。论文介绍了几个具体的场景，如电商推荐、病毒扫描、视频去重等，具体性能数据可以直接参考论文，这部分就不一一赘述了。</p>\n<p>下面是论文中几个实验的性能数据，贴上来给大家参考。</p>\n<p>下图是电商推荐场景不同吞吐量下的查询召回率。<br><img src=\"/../images/manu_recommendation_recall.png\" alt=\"Alt text\"></p>\n<p>下图是 24 小时内真实电商流量下的 QPS 和 latency，不同颜色表示使用不同数量的查询节点。<br><img src=\"/../images/manu_e_commer_real_traffic.png\" alt=\"Alt text\"></p>\n<p>下面两个图则分别展示了查询节点数量和数据规模对QPS 的影响</p>\n<p><img src=\"/../images/manu_query_node.png\" alt=\"Alt text\"></p>\n<p>下图展示的是所谓可调节的一致性对查询延迟的影响，可以看出查询延迟容忍越低，查询延迟越大。</p>\n<p><img src=\"/../images/manu_grace_time.png\" alt=\"Alt text\"></p>\n<p>最后是不同数据规模下索引构建时间</p>\n<p><img src=\"/../images/manu_index_build.png\" alt=\"Alt text\"></p>"},{"title":"Berkeley DB -- 软件设计的十点经验","_content":"\n### 设计经验一 -- 软件必须被设计为多个有边界的互相协作的模块\n```\nIt is vital for any complex software package's testing and maintenance that the software be designed and built as a cooperating set of modules with well-defined API boundaries. The boundaries can (and should!) shift as needs dictate, but they always need to be there. The existence of those boundaries prevents the software from becoming an unmaintainable pile of spaghetti. Butler Lampson once said that all problems in computer science can be solved by another level of indirection. More to the point, when asked what it meant for something to be object-oriented, Lampson said it meant being able to have multiple implementations behind an API. The Berkeley DB design and implementation embody this approach of permitting multiple implementations behind a common interface, providing an object-oriented look and feel, even though the library is written in C.\n```\n对于任何复杂软件的测试和维护而言，这一点是至关重要的；软件必须被设计和构建为具有明确 API边界的一系列相互协作的模块。这些边界可以灵活调整，但是必须存在。这些边界的存在能够避免该软件变得不可维护。Butler Lampson 曾说过， 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。当被问到这在面向对象系统中意味着什么，Lampson 进一步阐述到，这意味着API 背后要能够有多种不同的实现。Berkeley DB 的设计和实现体现了这种允许通用接口背后有不同实现的设计方式，尽管系统是用 C 语言实现的，它仍然能给人一种面向对象的感觉。\n\n### 设计经验二 -- \n```\nA software design is simply one of several ways to force yourself to think through the entire problem before attempting to solve it. Skilled programmers use different techniques to this end: some write a first version and throw it away, some write extensive manual pages or design documents, others fill out a code template where every requirement is identified and assigned to a specific function or comment. For example, in Berkeley DB, we created a complete set of Unix-style manual pages for the access methods and underlying components before writing any code. Regardless of the technique used, it's difficult to think clearly about program architecture after code debugging begins, not to mention that large architectural changes often waste previous debugging effort. Software architecture requires a different mind set from debugging code, and the architecture you have when you begin debugging is usually the architecture you'll deliver in that release.\n```\n软件设计是一种强迫自己在尝试解决问题之前深入思考整个问题的一种方式。有经验的程序员会用不同的方式来达到这个目的：一些人会写下第一个版本然后丢掉，一些人会写下操作手册或者设计文档，另外一些人会尝试填满一个能够定位和结算一些通用方法的代码模版。例如，在编写 Berkeley DB时，我们创建了一套完整的 Unix 风格的说明手册，用来在写代码之前描述这些访问方法和内部模块。不管使用哪种技术，在开始代码调试之后都很难思考清楚程序的架构，更不用说有些大型的架构变化经常会浪费前期的调试工作。软件架构需要与调试代码不同的思维方式。当你开始调试代码时候的软件架构往往就是你最终交付的软件架构。\n\n### 设计经验三 -- \n```\nSoftware architecture does not age gracefully. Software architecture degrades in direct proportion to the number of changes made to the software: bug fixes corrode the layering and new features stress design. Deciding when the software architecture has degraded sufficiently that you should re-design or re-write a module is a hard decision. On one hand, as the architecture degrades, maintenance and development become more difficult and at the end of that path is a legacy piece of software maintainable only by having an army of brute-force testers for every release, because nobody understands how the software works inside. On the other hand, users will bitterly complain over the instability and incompatibilities that result from fundamental changes. As a software architect, your only guarantee is that someone will be angry with you no matter which path you choose.\n```\n软件架构并不会优雅地衰老。软件架构降级与其中发生 change 的数量成正比，修复 bug 会腐蚀分层，新功能会强迫设计。决定软件何时降级到需要重新设计或者重写一个模块是一个艰难的决定。一方面，随着架构的降级，维护和开发变得更难，最终是一个庞大的软件维护的只能由大量测试者暴力测试来保证，因为没有人会理解软件内部是如何运作的。另一方面，用户会痛苦地抱怨软件的不稳定性和不兼容性，一些来自来自底层的结果会发生变化。作为一个架构师，你唯一能够保证的是总会有人抱怨你的选择，无论你选择了哪条路。\n\n### 设计经验四 --\n```\nIt doesn't matter how you name your variables, methods, functions, or what comments or code style you use; that is, there are a large number of formats and styles that are \"good enough.\" What does matter, and matters very much, is that naming and style be consistent. Skilled programmers derive a tremendous amount of information from code format and object naming. You should view naming and style inconsistencies as some programmers investing time and effort to lie to the other programmers, and vice versa. Failing to follow house coding conventions is a firing offense.\n```\n无论您如何命名变量、方法、函数，以及使用何种注释或代码风格，这并不重要；也就是说，存在许多足够好的格式和风格。真正重要的是，命名和风格必须保持一致。熟练的程序员可以从代码格式和对象命名中获取大量的信息。您应该将命名和风格的不一致视为一些程序员花费时间和精力欺骗其他程序员的行为，反之亦然。不遵守内部的编码规范是会导致被解雇的违规行为。\n\n### 设计经验五 --\n```\nSoftware architects must choose their upgrade battles carefully: users will accept minor changes to upgrade to new releases (if you guarantee compile-time errors, that is, obvious failures until the upgrade is complete; upgrade changes should never fail in subtle ways). But to make truly fundamental changes, you must admit it's a new code base and requires a port of your user base. Obviously, new code bases and application ports are not cheap in time or resources, but neither is angering your user base by telling them a huge overhaul is really a minor upgrade.\n```\n软件架构师必须慎重选择升级战斗：用户将接受小的变化以升级到新版本（如果您能保证编译时错误，也就是明显的故障，直到升级完成为止；升级变化绝不能以微妙的方式失败）。但是，要进行真正的基本变更，您必须承认这是一个新的代码基础，并需要对用户基础进行移植。显然，新的代码基础和应用程序移植在时间或资源上都不便宜，但是通过告诉用户一个巨大的改进实际上只是一个小的升级来激怒他们，同样也是得不偿失的。","source":"_posts/aosabook/bdb.md","raw":"---\ntitle: Berkeley DB -- 软件设计的十点经验\ntags:\n    - TBD\n---\n\n### 设计经验一 -- 软件必须被设计为多个有边界的互相协作的模块\n```\nIt is vital for any complex software package's testing and maintenance that the software be designed and built as a cooperating set of modules with well-defined API boundaries. The boundaries can (and should!) shift as needs dictate, but they always need to be there. The existence of those boundaries prevents the software from becoming an unmaintainable pile of spaghetti. Butler Lampson once said that all problems in computer science can be solved by another level of indirection. More to the point, when asked what it meant for something to be object-oriented, Lampson said it meant being able to have multiple implementations behind an API. The Berkeley DB design and implementation embody this approach of permitting multiple implementations behind a common interface, providing an object-oriented look and feel, even though the library is written in C.\n```\n对于任何复杂软件的测试和维护而言，这一点是至关重要的；软件必须被设计和构建为具有明确 API边界的一系列相互协作的模块。这些边界可以灵活调整，但是必须存在。这些边界的存在能够避免该软件变得不可维护。Butler Lampson 曾说过， 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。当被问到这在面向对象系统中意味着什么，Lampson 进一步阐述到，这意味着API 背后要能够有多种不同的实现。Berkeley DB 的设计和实现体现了这种允许通用接口背后有不同实现的设计方式，尽管系统是用 C 语言实现的，它仍然能给人一种面向对象的感觉。\n\n### 设计经验二 -- \n```\nA software design is simply one of several ways to force yourself to think through the entire problem before attempting to solve it. Skilled programmers use different techniques to this end: some write a first version and throw it away, some write extensive manual pages or design documents, others fill out a code template where every requirement is identified and assigned to a specific function or comment. For example, in Berkeley DB, we created a complete set of Unix-style manual pages for the access methods and underlying components before writing any code. Regardless of the technique used, it's difficult to think clearly about program architecture after code debugging begins, not to mention that large architectural changes often waste previous debugging effort. Software architecture requires a different mind set from debugging code, and the architecture you have when you begin debugging is usually the architecture you'll deliver in that release.\n```\n软件设计是一种强迫自己在尝试解决问题之前深入思考整个问题的一种方式。有经验的程序员会用不同的方式来达到这个目的：一些人会写下第一个版本然后丢掉，一些人会写下操作手册或者设计文档，另外一些人会尝试填满一个能够定位和结算一些通用方法的代码模版。例如，在编写 Berkeley DB时，我们创建了一套完整的 Unix 风格的说明手册，用来在写代码之前描述这些访问方法和内部模块。不管使用哪种技术，在开始代码调试之后都很难思考清楚程序的架构，更不用说有些大型的架构变化经常会浪费前期的调试工作。软件架构需要与调试代码不同的思维方式。当你开始调试代码时候的软件架构往往就是你最终交付的软件架构。\n\n### 设计经验三 -- \n```\nSoftware architecture does not age gracefully. Software architecture degrades in direct proportion to the number of changes made to the software: bug fixes corrode the layering and new features stress design. Deciding when the software architecture has degraded sufficiently that you should re-design or re-write a module is a hard decision. On one hand, as the architecture degrades, maintenance and development become more difficult and at the end of that path is a legacy piece of software maintainable only by having an army of brute-force testers for every release, because nobody understands how the software works inside. On the other hand, users will bitterly complain over the instability and incompatibilities that result from fundamental changes. As a software architect, your only guarantee is that someone will be angry with you no matter which path you choose.\n```\n软件架构并不会优雅地衰老。软件架构降级与其中发生 change 的数量成正比，修复 bug 会腐蚀分层，新功能会强迫设计。决定软件何时降级到需要重新设计或者重写一个模块是一个艰难的决定。一方面，随着架构的降级，维护和开发变得更难，最终是一个庞大的软件维护的只能由大量测试者暴力测试来保证，因为没有人会理解软件内部是如何运作的。另一方面，用户会痛苦地抱怨软件的不稳定性和不兼容性，一些来自来自底层的结果会发生变化。作为一个架构师，你唯一能够保证的是总会有人抱怨你的选择，无论你选择了哪条路。\n\n### 设计经验四 --\n```\nIt doesn't matter how you name your variables, methods, functions, or what comments or code style you use; that is, there are a large number of formats and styles that are \"good enough.\" What does matter, and matters very much, is that naming and style be consistent. Skilled programmers derive a tremendous amount of information from code format and object naming. You should view naming and style inconsistencies as some programmers investing time and effort to lie to the other programmers, and vice versa. Failing to follow house coding conventions is a firing offense.\n```\n无论您如何命名变量、方法、函数，以及使用何种注释或代码风格，这并不重要；也就是说，存在许多足够好的格式和风格。真正重要的是，命名和风格必须保持一致。熟练的程序员可以从代码格式和对象命名中获取大量的信息。您应该将命名和风格的不一致视为一些程序员花费时间和精力欺骗其他程序员的行为，反之亦然。不遵守内部的编码规范是会导致被解雇的违规行为。\n\n### 设计经验五 --\n```\nSoftware architects must choose their upgrade battles carefully: users will accept minor changes to upgrade to new releases (if you guarantee compile-time errors, that is, obvious failures until the upgrade is complete; upgrade changes should never fail in subtle ways). But to make truly fundamental changes, you must admit it's a new code base and requires a port of your user base. Obviously, new code bases and application ports are not cheap in time or resources, but neither is angering your user base by telling them a huge overhaul is really a minor upgrade.\n```\n软件架构师必须慎重选择升级战斗：用户将接受小的变化以升级到新版本（如果您能保证编译时错误，也就是明显的故障，直到升级完成为止；升级变化绝不能以微妙的方式失败）。但是，要进行真正的基本变更，您必须承认这是一个新的代码基础，并需要对用户基础进行移植。显然，新的代码基础和应用程序移植在时间或资源上都不便宜，但是通过告诉用户一个巨大的改进实际上只是一个小的升级来激怒他们，同样也是得不偿失的。","slug":"aosabook/bdb","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6ix000b1ts16sus4dsl","content":"<h3 id=\"设计经验一-–-软件必须被设计为多个有边界的互相协作的模块\"><a href=\"#设计经验一-–-软件必须被设计为多个有边界的互相协作的模块\" class=\"headerlink\" title=\"设计经验一 – 软件必须被设计为多个有边界的互相协作的模块\"></a>设计经验一 – 软件必须被设计为多个有边界的互相协作的模块</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">It is vital for any complex software package&#x27;s testing and maintenance that the software be designed and built as a cooperating set of modules with well-defined API boundaries. The boundaries can (and should!) shift as needs dictate, but they always need to be there. The existence of those boundaries prevents the software from becoming an unmaintainable pile of spaghetti. Butler Lampson once said that all problems in computer science can be solved by another level of indirection. More to the point, when asked what it meant for something to be object-oriented, Lampson said it meant being able to have multiple implementations behind an API. The Berkeley DB design and implementation embody this approach of permitting multiple implementations behind a common interface, providing an object-oriented look and feel, even though the library is written in C.</span><br></pre></td></tr></table></figure>\n<p>对于任何复杂软件的测试和维护而言，这一点是至关重要的；软件必须被设计和构建为具有明确 API边界的一系列相互协作的模块。这些边界可以灵活调整，但是必须存在。这些边界的存在能够避免该软件变得不可维护。Butler Lampson 曾说过， 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。当被问到这在面向对象系统中意味着什么，Lampson 进一步阐述到，这意味着API 背后要能够有多种不同的实现。Berkeley DB 的设计和实现体现了这种允许通用接口背后有不同实现的设计方式，尽管系统是用 C 语言实现的，它仍然能给人一种面向对象的感觉。</p>\n<h3 id=\"设计经验二-–\"><a href=\"#设计经验二-–\" class=\"headerlink\" title=\"设计经验二 –\"></a>设计经验二 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A software design is simply one of several ways to force yourself to think through the entire problem before attempting to solve it. Skilled programmers use different techniques to this end: some write a first version and throw it away, some write extensive manual pages or design documents, others fill out a code template where every requirement is identified and assigned to a specific function or comment. For example, in Berkeley DB, we created a complete set of Unix-style manual pages for the access methods and underlying components before writing any code. Regardless of the technique used, it&#x27;s difficult to think clearly about program architecture after code debugging begins, not to mention that large architectural changes often waste previous debugging effort. Software architecture requires a different mind set from debugging code, and the architecture you have when you begin debugging is usually the architecture you&#x27;ll deliver in that release.</span><br></pre></td></tr></table></figure>\n<p>软件设计是一种强迫自己在尝试解决问题之前深入思考整个问题的一种方式。有经验的程序员会用不同的方式来达到这个目的：一些人会写下第一个版本然后丢掉，一些人会写下操作手册或者设计文档，另外一些人会尝试填满一个能够定位和结算一些通用方法的代码模版。例如，在编写 Berkeley DB时，我们创建了一套完整的 Unix 风格的说明手册，用来在写代码之前描述这些访问方法和内部模块。不管使用哪种技术，在开始代码调试之后都很难思考清楚程序的架构，更不用说有些大型的架构变化经常会浪费前期的调试工作。软件架构需要与调试代码不同的思维方式。当你开始调试代码时候的软件架构往往就是你最终交付的软件架构。</p>\n<h3 id=\"设计经验三-–\"><a href=\"#设计经验三-–\" class=\"headerlink\" title=\"设计经验三 –\"></a>设计经验三 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Software architecture does not age gracefully. Software architecture degrades in direct proportion to the number of changes made to the software: bug fixes corrode the layering and new features stress design. Deciding when the software architecture has degraded sufficiently that you should re-design or re-write a module is a hard decision. On one hand, as the architecture degrades, maintenance and development become more difficult and at the end of that path is a legacy piece of software maintainable only by having an army of brute-force testers for every release, because nobody understands how the software works inside. On the other hand, users will bitterly complain over the instability and incompatibilities that result from fundamental changes. As a software architect, your only guarantee is that someone will be angry with you no matter which path you choose.</span><br></pre></td></tr></table></figure>\n<p>软件架构并不会优雅地衰老。软件架构降级与其中发生 change 的数量成正比，修复 bug 会腐蚀分层，新功能会强迫设计。决定软件何时降级到需要重新设计或者重写一个模块是一个艰难的决定。一方面，随着架构的降级，维护和开发变得更难，最终是一个庞大的软件维护的只能由大量测试者暴力测试来保证，因为没有人会理解软件内部是如何运作的。另一方面，用户会痛苦地抱怨软件的不稳定性和不兼容性，一些来自来自底层的结果会发生变化。作为一个架构师，你唯一能够保证的是总会有人抱怨你的选择，无论你选择了哪条路。</p>\n<h3 id=\"设计经验四-–\"><a href=\"#设计经验四-–\" class=\"headerlink\" title=\"设计经验四 –\"></a>设计经验四 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">It doesn&#x27;t matter how you name your variables, methods, functions, or what comments or code style you use; that is, there are a large number of formats and styles that are &quot;good enough.&quot; What does matter, and matters very much, is that naming and style be consistent. Skilled programmers derive a tremendous amount of information from code format and object naming. You should view naming and style inconsistencies as some programmers investing time and effort to lie to the other programmers, and vice versa. Failing to follow house coding conventions is a firing offense.</span><br></pre></td></tr></table></figure>\n<p>无论您如何命名变量、方法、函数，以及使用何种注释或代码风格，这并不重要；也就是说，存在许多足够好的格式和风格。真正重要的是，命名和风格必须保持一致。熟练的程序员可以从代码格式和对象命名中获取大量的信息。您应该将命名和风格的不一致视为一些程序员花费时间和精力欺骗其他程序员的行为，反之亦然。不遵守内部的编码规范是会导致被解雇的违规行为。</p>\n<h3 id=\"设计经验五-–\"><a href=\"#设计经验五-–\" class=\"headerlink\" title=\"设计经验五 –\"></a>设计经验五 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Software architects must choose their upgrade battles carefully: users will accept minor changes to upgrade to new releases (if you guarantee compile-time errors, that is, obvious failures until the upgrade is complete; upgrade changes should never fail in subtle ways). But to make truly fundamental changes, you must admit it&#x27;s a new code base and requires a port of your user base. Obviously, new code bases and application ports are not cheap in time or resources, but neither is angering your user base by telling them a huge overhaul is really a minor upgrade.</span><br></pre></td></tr></table></figure>\n<p>软件架构师必须慎重选择升级战斗：用户将接受小的变化以升级到新版本（如果您能保证编译时错误，也就是明显的故障，直到升级完成为止；升级变化绝不能以微妙的方式失败）。但是，要进行真正的基本变更，您必须承认这是一个新的代码基础，并需要对用户基础进行移植。显然，新的代码基础和应用程序移植在时间或资源上都不便宜，但是通过告诉用户一个巨大的改进实际上只是一个小的升级来激怒他们，同样也是得不偿失的。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"设计经验一-–-软件必须被设计为多个有边界的互相协作的模块\"><a href=\"#设计经验一-–-软件必须被设计为多个有边界的互相协作的模块\" class=\"headerlink\" title=\"设计经验一 – 软件必须被设计为多个有边界的互相协作的模块\"></a>设计经验一 – 软件必须被设计为多个有边界的互相协作的模块</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">It is vital for any complex software package&#x27;s testing and maintenance that the software be designed and built as a cooperating set of modules with well-defined API boundaries. The boundaries can (and should!) shift as needs dictate, but they always need to be there. The existence of those boundaries prevents the software from becoming an unmaintainable pile of spaghetti. Butler Lampson once said that all problems in computer science can be solved by another level of indirection. More to the point, when asked what it meant for something to be object-oriented, Lampson said it meant being able to have multiple implementations behind an API. The Berkeley DB design and implementation embody this approach of permitting multiple implementations behind a common interface, providing an object-oriented look and feel, even though the library is written in C.</span><br></pre></td></tr></table></figure>\n<p>对于任何复杂软件的测试和维护而言，这一点是至关重要的；软件必须被设计和构建为具有明确 API边界的一系列相互协作的模块。这些边界可以灵活调整，但是必须存在。这些边界的存在能够避免该软件变得不可维护。Butler Lampson 曾说过， 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。当被问到这在面向对象系统中意味着什么，Lampson 进一步阐述到，这意味着API 背后要能够有多种不同的实现。Berkeley DB 的设计和实现体现了这种允许通用接口背后有不同实现的设计方式，尽管系统是用 C 语言实现的，它仍然能给人一种面向对象的感觉。</p>\n<h3 id=\"设计经验二-–\"><a href=\"#设计经验二-–\" class=\"headerlink\" title=\"设计经验二 –\"></a>设计经验二 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A software design is simply one of several ways to force yourself to think through the entire problem before attempting to solve it. Skilled programmers use different techniques to this end: some write a first version and throw it away, some write extensive manual pages or design documents, others fill out a code template where every requirement is identified and assigned to a specific function or comment. For example, in Berkeley DB, we created a complete set of Unix-style manual pages for the access methods and underlying components before writing any code. Regardless of the technique used, it&#x27;s difficult to think clearly about program architecture after code debugging begins, not to mention that large architectural changes often waste previous debugging effort. Software architecture requires a different mind set from debugging code, and the architecture you have when you begin debugging is usually the architecture you&#x27;ll deliver in that release.</span><br></pre></td></tr></table></figure>\n<p>软件设计是一种强迫自己在尝试解决问题之前深入思考整个问题的一种方式。有经验的程序员会用不同的方式来达到这个目的：一些人会写下第一个版本然后丢掉，一些人会写下操作手册或者设计文档，另外一些人会尝试填满一个能够定位和结算一些通用方法的代码模版。例如，在编写 Berkeley DB时，我们创建了一套完整的 Unix 风格的说明手册，用来在写代码之前描述这些访问方法和内部模块。不管使用哪种技术，在开始代码调试之后都很难思考清楚程序的架构，更不用说有些大型的架构变化经常会浪费前期的调试工作。软件架构需要与调试代码不同的思维方式。当你开始调试代码时候的软件架构往往就是你最终交付的软件架构。</p>\n<h3 id=\"设计经验三-–\"><a href=\"#设计经验三-–\" class=\"headerlink\" title=\"设计经验三 –\"></a>设计经验三 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Software architecture does not age gracefully. Software architecture degrades in direct proportion to the number of changes made to the software: bug fixes corrode the layering and new features stress design. Deciding when the software architecture has degraded sufficiently that you should re-design or re-write a module is a hard decision. On one hand, as the architecture degrades, maintenance and development become more difficult and at the end of that path is a legacy piece of software maintainable only by having an army of brute-force testers for every release, because nobody understands how the software works inside. On the other hand, users will bitterly complain over the instability and incompatibilities that result from fundamental changes. As a software architect, your only guarantee is that someone will be angry with you no matter which path you choose.</span><br></pre></td></tr></table></figure>\n<p>软件架构并不会优雅地衰老。软件架构降级与其中发生 change 的数量成正比，修复 bug 会腐蚀分层，新功能会强迫设计。决定软件何时降级到需要重新设计或者重写一个模块是一个艰难的决定。一方面，随着架构的降级，维护和开发变得更难，最终是一个庞大的软件维护的只能由大量测试者暴力测试来保证，因为没有人会理解软件内部是如何运作的。另一方面，用户会痛苦地抱怨软件的不稳定性和不兼容性，一些来自来自底层的结果会发生变化。作为一个架构师，你唯一能够保证的是总会有人抱怨你的选择，无论你选择了哪条路。</p>\n<h3 id=\"设计经验四-–\"><a href=\"#设计经验四-–\" class=\"headerlink\" title=\"设计经验四 –\"></a>设计经验四 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">It doesn&#x27;t matter how you name your variables, methods, functions, or what comments or code style you use; that is, there are a large number of formats and styles that are &quot;good enough.&quot; What does matter, and matters very much, is that naming and style be consistent. Skilled programmers derive a tremendous amount of information from code format and object naming. You should view naming and style inconsistencies as some programmers investing time and effort to lie to the other programmers, and vice versa. Failing to follow house coding conventions is a firing offense.</span><br></pre></td></tr></table></figure>\n<p>无论您如何命名变量、方法、函数，以及使用何种注释或代码风格，这并不重要；也就是说，存在许多足够好的格式和风格。真正重要的是，命名和风格必须保持一致。熟练的程序员可以从代码格式和对象命名中获取大量的信息。您应该将命名和风格的不一致视为一些程序员花费时间和精力欺骗其他程序员的行为，反之亦然。不遵守内部的编码规范是会导致被解雇的违规行为。</p>\n<h3 id=\"设计经验五-–\"><a href=\"#设计经验五-–\" class=\"headerlink\" title=\"设计经验五 –\"></a>设计经验五 –</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Software architects must choose their upgrade battles carefully: users will accept minor changes to upgrade to new releases (if you guarantee compile-time errors, that is, obvious failures until the upgrade is complete; upgrade changes should never fail in subtle ways). But to make truly fundamental changes, you must admit it&#x27;s a new code base and requires a port of your user base. Obviously, new code bases and application ports are not cheap in time or resources, but neither is angering your user base by telling them a huge overhaul is really a minor upgrade.</span><br></pre></td></tr></table></figure>\n<p>软件架构师必须慎重选择升级战斗：用户将接受小的变化以升级到新版本（如果您能保证编译时错误，也就是明显的故障，直到升级完成为止；升级变化绝不能以微妙的方式失败）。但是，要进行真正的基本变更，您必须承认这是一个新的代码基础，并需要对用户基础进行移植。显然，新的代码基础和应用程序移植在时间或资源上都不便宜，但是通过告诉用户一个巨大的改进实际上只是一个小的升级来激怒他们，同样也是得不偿失的。</p>\n"},{"title":"(Paper Reading) SQLite: Past, Present, Future","date":"2023-07-30T02:10:33.000Z","_content":"\n# SQLite: Past, Present, Future\n\n这篇文章是 22 年 VLDB 的一篇文章，文章主要介绍了 SQLite 的历史沿革及在 OLAP 领域的应用和优化。\n\n<!-- more -->\n\n我是第一次听说DuckDB这个名字，问了一下 chatGPT，下面是 chatGPT 的回答：\n```\nDuckDB是一个开源的内存列存储数据库管理系统（DBMS），专为高性能和低延迟的分析查询而设计。它的目标是提供类似传统数据库系统的SQL查询能力，同时在处理大规模数据集时保持快速响应时间。\n\nDuckDB的设计着重于内存处理，它将数据存储在计算机的内存中，以便快速读取和查询。相比磁盘存储的数据库系统，内存存储具有更快的访问速度，因为内存中的数据可以直接读取，而无需磁盘I/O操作。这使得DuckDB在需要实时查询和交互式分析的场景中非常有用。\n\n此外，DuckDB还采用了列存储的方式来组织和管理数据。与传统的行存储不同，列存储将每个列的数据连续存储在一起，这种存储方式在分析查询中具有更好的性能。列存储可以有效地压缩数据，减少存储空间，并且在处理只涉及部分列的查询时更加高效。\n\nDuckDB支持标准的SQL查询语言，可以进行复杂的查询、连接和聚合操作。它还提供了对Python、R和其他编程语言的接口，使得开发人员可以方便地在自己熟悉的编程环境中使用DuckDB进行数据分析和处理。\n\n总而言之，DuckDB是一个专注于内存处理和列存储的高性能数据库系统，适用于需要快速查询和分析大规模数据集的场景。\n```\n\n这篇文章主要贡献如下：\n\n- 介绍了 SQLite 的历史沿革\n- 对 SQLite 的特性进行了系统的评估\n- 在数据分析工作场景下对 SQLite 进行了优化\n- 确定了一些嵌入式数据引擎性能衡量指标\n- 对未来 SQLite 的进一步性能优化进行了方向性的叙述\n\n下面按照文章整体脉络梳理一下文章的内容。\n\n## SQLite 的架构\n![SQLite 的整体架构](/images/SQLite_Architecture.png)\n\nSQLite 主要包括四个大的模块：\n\n- SQL Complier：SQLite 中 SQL 编译模块的运行类似一个编译器，通过词法分析、语法分析和语义分析来编译 SQL 语句，形成一个字节码的可执行程序，由一系列虚拟指令构成。\n- Core：SQLite的核心执行引擎负责处理所有数据库的底层操作。它以一个虚拟机的形式存在，会对 compiler 生成的字节码逐一执行。\n- Backend：存储引擎，负责将数据持久化磁盘上。SQLite使用B树（B-tree）作为其默认的存储引擎，包括索引 B 树和表 B 树。B树是一种用于高效存储和检索数据的数据结构，它允许快速的索引查找和范围查询。 SQLite 使用叫做虚拟文件系统（virtual file system, VFS）的抽象对象来实现不同操作系统的可移植性，对于不同的操作系统，它会有不同的 VFS。\n- Accessories：SQLite的附加模块，包括一些 UT 和工具函数：包括内存分配、字符串操作、随机数操作等。\n\n## 事务\n\nSQLite 是一个支持事务的数据库引擎，通过回滚和 WAL 模式，能够满足 ACID 四个特性。（这是面试数据库团队经常会考到的一个八股文）\n\n### 回滚模式\n在回滚模式中，SQLite 在执行事务时需要获取数据库文件的共享锁，当事务涉及对数据库的更改时，SQLite 就会将读锁升级为保留锁(reserved lock)，从而阻塞其他写入的事务，但是仍然允许读操作。在执行写操作前，SQLite 会创建一个回滚日志。对于每个页面，SQLite 会将其原始数据写入回滚日志，并将更新后的页面保留在用户空间。当 SQLite 提交事务时，它就会把回滚日志刷入持久化存储。然后，SQLite 会获取一个数据库文件的排他锁，用来 block 其他的读写操作，同时写入当前更改。更改后的页面会刷入持久化存储中。回滚日志接着会通过多个机制中的某一个来作废掉，取决于日志模式。在 DELETE 模式中，SQLite会将回滚日志删除掉，但是由于删除操作本身成本较高，SQLite 同时也会提供其他方式来使日志无效，比如在 TRUNCATE 模式中，回滚日志会被截断而非删除；在 PERSIST 模式中，会被日志头会被覆写成 0。作废回滚日志操作会提交当前事务。最后 SQLite 会释放这个排他锁。\n```markdown\nNote: 在SQLite中，\"reserved lock\"（保留锁）是一种用于数据库文件的文件级别锁定机制。它是SQLite中的一种锁定状态，用于控制对数据库文件的并发访问。\n\n当一个进程（或连接）以写模式打开一个SQLite数据库文件时，它会尝试获取一个保留锁。这个锁阻止其他进程以写模式打开同一个数据库文件。也就是说，只有一个进程可以以写模式打开数据库文件，以防止多个进程同时修改数据库并导致数据损坏或不一致。\n\n当一个进程成功获取了保留锁并以写模式打开数据库文件时，其他进程只能以只读模式打开该文件，或者等待保留锁释放后才能以写模式打开。这样可以确保在一个时间点只有一个进程进行写操作，而其他进程可以并发地读取数据库。\n\n需要注意的是，SQLite的保留锁是在文件级别上进行的，而不是在表或行级别上。这意味着一个进程可以以写模式修改数据库中的任何表和行，而其他进程在持有只读锁时可以读取整个数据库的内容。\n\n保留锁是SQLite内部用于实现并发控制的机制，开发人员通常不需要直接操作或处理保留锁。它是SQLite的一部分，用于确保数据库的一致性和并发访问的正确性。\n```\n\n### WAL模式\n\nWrite-Ahead Log（WAL）是数据库中另一个重要机制，概念上属于回滚模式的倒置。回滚模式试讲原始页面内容写入回滚日志，然后在数据库文件上修改页面数据。而在 WAL 模式中，SQLite则是维护原有页面数据，而将修改信息写入到单独的 WAL 文件中。当开始一个事务时，SQLite 会记录最后一次有效提交的位置，作为 end mark。当 SQLite 需要一个页面时，它会尝试搜索 最近版本的WAL。如果页面不存在于 WAL 中，SQLite 就会从数据库文件中拉取页。对数据库的修改会仅仅写入到 WAL log 的最后面。这里就会提到一个 checkpoint 机制，当某次提交导致 WAL日志达到某个特定大小时，SQLite 就会将WAL 中更新的页面写回数据库文件。在提交之后，系统也不会直接删除 WAL 文件，而是会反复写入 WAL 文件，以达到文件复用的目的，降低因新建WAL 文件等操作带来的开销。（这个机制有点类似于循环缓冲区的实现逻辑，类似思想在很多其他场景也有应用）\n\nWAL模式有两大优点：第一可以显著提高并发度，因为读操作仍然可以继续执行，只有在 WAL 提交时才需要阻塞读。第二就是 WAL 由于减少了对持久化存储的写入操作，它明显更快一些。\n\n但是 WAL 同时也有不可忽视的缺点。为了加速 WAL 的搜索，SQLite 在共享内存中创建了 WAL index，用于优化读事务性能。但是，共享内存要求所有读都要在同一台机器上。另外 WAL 模式无法在网络文件系统中工作；在进入 WAL 模式后，我们也无法修改页面大小（？）。另外 WAL 模式也增加了系统的复杂复，包括 checkpoint 操作和其他与 WAL 相关的操作。\n\n## SQLite 的workload 和硬件变化\n\n过去这些年，随着电子设备不断发展，SQLite 运行的平台也发生了很大的性能变化，与此同时，基于对 SQLite 使用的统计，SQLite 的使用场景和最初涉及目标场景已经有了很大的区别，一部分是简单的键值对查找，然而存在一个长尾场景，有许多复杂的 OLAP 操作也运行在 SQLite 中，这些 query 里面有很多都会涉及到多张表的 join 操作。此外大概有 25% 左右的语句涉及到数据库的写操作，大部分写是 UPSERT 操作。\n\n```markdown\n当涉及JOIN操作时，数据库系统通常会使用以下算法和技术来实现不同类型的JOIN：\n\n1. 嵌套循环连接（Nested Loop Join）：\n   - 对于每个外部表的行，遍历内部表的每一行，并检查连接条件是否满足。\n   - 如果连接条件成立，则将两个行组合在一起形成结果集。\n   - 这种算法的时间复杂度为O(N*M)，其中N是外部表的行数，M是内部表的行数。\n   - 嵌套循环连接适用于小型表或连接条件能够有效筛选出匹配行的情况。\n\n2. 哈希连接（Hash Join）：\n   - 将一个表的连接列进行哈希处理，并构建哈希表。\n   - 遍历另一个表的每一行，并使用哈希表快速查找匹配的行。\n   - 如果连接条件成立，则将两个行组合在一起形成结果集。\n   - 哈希连接适用于大型表的连接，尤其是在内存中可以容纳哈希表的情况下。\n   - 这种算法的时间复杂度取决于哈希表的构建和查询性能。\n\n3. 排序合并连接（Merge Join）：\n   - 对连接列进行排序，使得两个表的连接列按升序排列。\n   - 使用双指针来同时遍历两个已排序的连接列，并进行比较。\n   - 如果连接条件成立，则将两个行组合在一起形成结果集。\n   - 排序合并连接适用于已经有序的表或结果集。\n   - 这种算法的时间复杂度为O(NlogN)，其中N是连接的行数。\n\n除了这些基本的JOIN算法，数据库系统还可能使用其他优化技术来提高JOIN操作的性能，例如：\n\n- 索引优化：使用索引来加速JOIN操作，特别是在连接列上创建适当的索引。\n- 并行处理：将JOIN操作分成多个并行任务，以提高查询的执行效率。\n- 物化视图（Materialized Views）：创建预计算的中间结果集，以减少JOIN操作的计算量。\n- 布隆过滤器（Bloom Filter）：使用布隆过滤器来过滤不可能匹配的行，减少实际的比较操作。\n\n这些技术的选择和应用取决于数据库系统的实现和优化策略，以及查询的特性和表的大小。数据库系统的优化器通常会根据统计信息、成本估算和查询优化规则来选择最合适的JOIN算法，并生成最优的查询计划。\n\n```\n\n现在的硬件扩展对 SQLite 的性能有了更高的要求。SQLite 一般不使用多线程，以达到更高的性能。为了给海量数据排序，SQLite 可以选择开启一个多线程的外部归并排序。对于其他操作，SQLite 一般直接在调用线程中完成。这种设计能够最小化其他线程的资源竞用。正常来说，SQLite 与其他 OLAP 数据库相比并不具有竞争力，但是 DuckDB 集成了向量化引擎和并行查询处理，给 DuckDB 提供了良好的 OLAP 性能。\n\n```markdown\n向量化引擎（Vectorized Engine）是一种优化技术，用于执行数据处理和计算任务。它是在现代计算机体系结构中针对数据密集型操作的一种高效执行方式。\n\n传统上，计算机的指令集（Instruction Set Architecture，ISA）主要是以标量操作为基础，即一次只处理一个数据元素。然而，随着计算机硬件的发展和数据密集型计算需求的增加，引入向量化引擎成为一种优化策略。\n\n向量化引擎通过将一组数据元素作为一个向量，同时执行相同的操作，以并行处理多个数据元素。这种向量操作可以在同一指令下处理多个数据元素，从而提高计算效率和性能。\n\n向量化引擎的工作原理是利用特定的硬件指令集和并行计算技术，如SIMD（Single Instruction, Multiple Data）指令集。SIMD指令集允许在单个指令中同时操作多个数据元素，减少了指令级别的开销，并且能够在一个时钟周期内处理多个数据。\n\n在向量化引擎中，数据通常以连续的存储方式进行排列，这样可以充分利用硬件的高速缓存和数据预取技术，提高数据访问效率。\n\n向量化引擎广泛应用于许多数据密集型任务，例如科学计算、图像处理、音频处理、机器学习和数据库查询等。它能够显著加速这些任务的执行速度，并提高计算机系统的吞吐量。\n\n需要注意的是，向量化引擎的有效性取决于具体的硬件支持和编程模型。软件开发人员需要使用适当的编程技术和工具，如使用向量化指令集的编程语言扩展或优化的库，以利用向量化引擎的优势。\n\n\n并行查询处理是一种数据库查询优化和执行技术，通过同时在多个处理单元上执行查询任务的不同部分来加快查询的执行速度。\n\n在并行查询处理中，查询被分解成多个子任务，并且这些子任务可以并行地在不同的处理单元上执行。每个处理单元可以是独立的线程、进程或计算节点，以利用系统中的多核处理器、多个计算节点或并行计算集群。\n\n并行查询处理的目标是最大限度地利用系统的计算资源，从而加速查询的执行。通过并行执行不同的查询操作，如并行连接、并行排序、并行聚合等，可以减少查询的总体执行时间，并提高数据库系统的并发性能和吞吐量。\n\n并行查询处理的优势包括：\n\n1. 提高查询性能：通过并行执行查询的不同部分，可以有效利用多个处理单元的计算资源，从而减少查询的总体执行时间。\n\n2. 处理大规模数据：对于大型数据集，通过并行查询处理可以分摊数据处理的负载，更高效地处理大规模数据。\n\n3. 并发执行：并行查询处理可以支持并发查询执行，多个查询可以同时进行，提高系统的并发性能和用户的响应时间。\n\n需要注意的是，并行查询处理的实现和效果取决于具体的数据库系统和硬件架构。数据库系统需要具备适当的并行查询优化器和调度器，以及支持并行计算的硬件资源。同时，数据的划分、分布和访问模式也会影响并行查询处理的性能和效果。\n\n总结而言，并行查询处理是一种利用多个处理单元并行执行查询任务的技术，旨在提高查询的执行速度和系统的并发性能。它在大规模数据处理和高并发查询场景下具有重要的作用，可以显著提升数据库系统的效率和性能。\n```\n\n## 性能评估实验\n\n作者接下来使用 SQLite 和 DuckDB 来评估不同场景下的性能。首先使用了 TATP benchmark 来评估 OLTP 场景下的性能。由于 DuckDB 主要是设计满足 OLAP 场景下的需求，因此其吞吐量在实验中远远不及 SQLite 的吞吐量。在数据规模达到百万级别时，SQLite的在 Cloud server 上的TPS能达到 10k左右，比 DuckDB 高了几个数量级。接着又使用了 Star Schema Benchmark 来评估了 OLAP 场景下的性能。在这一场景下，DuckDB 展示了极佳的性能，在延迟上 比 SQLite 快了 10 倍到数十倍不等。\n\n为了理解这一性能差距，作者同时对 SQLite 的执行引擎做了profiling，分析得出主要是`SeekRowid`和`Column`操作耗费了大量时间。`SeekRowid`是为了在 B-tree 上找到对应 row id 的行，用来执行 join 操作；而 `Column`是为了提取给定记录的列值。基于这一结果，作者给出了两个关键的优化目标：避免不必要的 B-tree探测同时流化值提取过程。\n\n### 避免不必要的 B-tree 探测\n\nSQLite 使用嵌套循环来实现 join 操作，内循环往往可以通过索引来加速。为了优化 join 操作的效率，作者通过布隆过滤器来实现 SQLite 的Lookahead Information Passing（LIP）。说白了其实就是通过布隆过滤器来加速 join 操作中对内表的检索操作，使用布隆过滤器后，实验观测到可最多十倍的性能提升。\n\n```markdown\n在数据库领域中，Lookahead Information Passing（LIP）是一种查询优化技术，用于改善查询执行的效率和性能。\n\n在数据库查询优化过程中，查询优化器需要决定查询的执行计划，即确定查询中各个操作的执行顺序和方法。这涉及到选择合适的连接算法、访问方法、排序策略等，以便在给定的查询条件下，尽量高效地访问和处理数据。\n\nLIP技术在查询优化中的作用是提前获取和传递后续操作的信息，以辅助当前操作的执行计划选择。它基于对查询语句和数据库统计信息的分析，预测和收集后续操作的属性、选择性、数据分布等特征，并将这些信息传递给当前操作的优化过程。\n\n通过使用LIP技术，查询优化器可以更好地理解查询的整体语义和后续操作的特性，从而在制定执行计划时做出更准确的决策。例如，当优化器决定连接两个表时，LIP技术可以提供关于后续操作的信息，如后续操作中涉及的列、选择性、数据分布等，以便优化器选择最佳的连接算法和连接顺序。\n\nLIP技术在数据库查询优化中的应用有助于生成更高效的查询执行计划，从而提升查询的执行性能和效率。它可以减少不必要的计算和数据访问操作，优化查询的资源利用和数据处理方式，以适应特定的查询场景和优化目标。\n\n需要指出的是，LIP技术在数据库查询优化中可能涉及到多个方面，包括查询解析、查询重写、代价估算等。不同的数据库管理系统和查询优化器可能采用不同的LIP策略和实现方式，以适应特定的数据库架构和查询优化需求。\n\n```\n\n### 流化值提取过程\n\n这部分逻辑相对应的会涉及到更具体的 SQLite 存储模式。SQLite record 由两部分组成：header 和 body。header 中存储了记录的类型码等元数据信息，body 中存储了记录的数据信息。为了提取值信息，SQLite 首先回到 head 里面找到一个指针，然后通过header 中的类型码遍历数据，直到找到对应的列。这种模式显然不适合 OLAP 场景下的流化数据提取。作者也尝试了其他方式去优化其数据提取过程，但是为了避免破坏 SQLite 在不同平台的稳定性，作者放弃了这部分优化。\n\n与此同时，作者又比较了BLOB 场景下的吞吐量，发现 SQLite 在 10KB 大小 blob 时吞吐量最佳，TPS 能够达到 9k 左右。随着 blob 的增大，其性能逐渐拉跨，甚至比不上文件系统的吞吐。这是由于 WAL 只允许 1000 个页，相当于大约 4MB 的大小限制，这带来了额外的写开销。\n\n作者同时比较了SQLite 和 DuckDB 的资源使用情况，比较有意思的点是 SQLite 在load 实验数据时虽然最终产生的数据库文件大约是 DuckDB 的两倍，但加载时间明显快于 DuckDB，作者没有详细解释这是为什么。\n\n在文章最后，作者提到了为什么没有对 SQLite 做 OLAP 场景下的优化，这是由于 SQLite 是一个通用型的数据引擎，为了保证不同场景下的性能和兼容性，不得不放弃一部分优化方式。然而，通过一些空间换时间的方式也能加速 OLAP 场景下的性能。通过向量化执行、数据压缩、运行时代码生成、和物化聚集等方式可以对一个传统的 OLTP 引擎进行 OLAP 场景下的优化，但是哪种方式能够最大化优化性能、哪些没有太大的优化价值，就需要这篇文章中的各类性能评估实验。这应该也是作者写这篇文章的动机。\n\n总的来说，这篇文章介绍了 SQLite 大致的历史沿革、系统架构和性能评估数据，虽然创新性上感觉稍显不足，但是比较扎实地进行了一系列实验比较，为 SQLite 的优化提供了比较好的参考数据。","source":"_posts/papers/SQLite.md","raw":"---\ntitle: '(Paper Reading) SQLite: Past, Present, Future'\ndate: 2023-07-30 10:10:33\ntags: \"Paper Reading\"\n---\n\n# SQLite: Past, Present, Future\n\n这篇文章是 22 年 VLDB 的一篇文章，文章主要介绍了 SQLite 的历史沿革及在 OLAP 领域的应用和优化。\n\n<!-- more -->\n\n我是第一次听说DuckDB这个名字，问了一下 chatGPT，下面是 chatGPT 的回答：\n```\nDuckDB是一个开源的内存列存储数据库管理系统（DBMS），专为高性能和低延迟的分析查询而设计。它的目标是提供类似传统数据库系统的SQL查询能力，同时在处理大规模数据集时保持快速响应时间。\n\nDuckDB的设计着重于内存处理，它将数据存储在计算机的内存中，以便快速读取和查询。相比磁盘存储的数据库系统，内存存储具有更快的访问速度，因为内存中的数据可以直接读取，而无需磁盘I/O操作。这使得DuckDB在需要实时查询和交互式分析的场景中非常有用。\n\n此外，DuckDB还采用了列存储的方式来组织和管理数据。与传统的行存储不同，列存储将每个列的数据连续存储在一起，这种存储方式在分析查询中具有更好的性能。列存储可以有效地压缩数据，减少存储空间，并且在处理只涉及部分列的查询时更加高效。\n\nDuckDB支持标准的SQL查询语言，可以进行复杂的查询、连接和聚合操作。它还提供了对Python、R和其他编程语言的接口，使得开发人员可以方便地在自己熟悉的编程环境中使用DuckDB进行数据分析和处理。\n\n总而言之，DuckDB是一个专注于内存处理和列存储的高性能数据库系统，适用于需要快速查询和分析大规模数据集的场景。\n```\n\n这篇文章主要贡献如下：\n\n- 介绍了 SQLite 的历史沿革\n- 对 SQLite 的特性进行了系统的评估\n- 在数据分析工作场景下对 SQLite 进行了优化\n- 确定了一些嵌入式数据引擎性能衡量指标\n- 对未来 SQLite 的进一步性能优化进行了方向性的叙述\n\n下面按照文章整体脉络梳理一下文章的内容。\n\n## SQLite 的架构\n![SQLite 的整体架构](/images/SQLite_Architecture.png)\n\nSQLite 主要包括四个大的模块：\n\n- SQL Complier：SQLite 中 SQL 编译模块的运行类似一个编译器，通过词法分析、语法分析和语义分析来编译 SQL 语句，形成一个字节码的可执行程序，由一系列虚拟指令构成。\n- Core：SQLite的核心执行引擎负责处理所有数据库的底层操作。它以一个虚拟机的形式存在，会对 compiler 生成的字节码逐一执行。\n- Backend：存储引擎，负责将数据持久化磁盘上。SQLite使用B树（B-tree）作为其默认的存储引擎，包括索引 B 树和表 B 树。B树是一种用于高效存储和检索数据的数据结构，它允许快速的索引查找和范围查询。 SQLite 使用叫做虚拟文件系统（virtual file system, VFS）的抽象对象来实现不同操作系统的可移植性，对于不同的操作系统，它会有不同的 VFS。\n- Accessories：SQLite的附加模块，包括一些 UT 和工具函数：包括内存分配、字符串操作、随机数操作等。\n\n## 事务\n\nSQLite 是一个支持事务的数据库引擎，通过回滚和 WAL 模式，能够满足 ACID 四个特性。（这是面试数据库团队经常会考到的一个八股文）\n\n### 回滚模式\n在回滚模式中，SQLite 在执行事务时需要获取数据库文件的共享锁，当事务涉及对数据库的更改时，SQLite 就会将读锁升级为保留锁(reserved lock)，从而阻塞其他写入的事务，但是仍然允许读操作。在执行写操作前，SQLite 会创建一个回滚日志。对于每个页面，SQLite 会将其原始数据写入回滚日志，并将更新后的页面保留在用户空间。当 SQLite 提交事务时，它就会把回滚日志刷入持久化存储。然后，SQLite 会获取一个数据库文件的排他锁，用来 block 其他的读写操作，同时写入当前更改。更改后的页面会刷入持久化存储中。回滚日志接着会通过多个机制中的某一个来作废掉，取决于日志模式。在 DELETE 模式中，SQLite会将回滚日志删除掉，但是由于删除操作本身成本较高，SQLite 同时也会提供其他方式来使日志无效，比如在 TRUNCATE 模式中，回滚日志会被截断而非删除；在 PERSIST 模式中，会被日志头会被覆写成 0。作废回滚日志操作会提交当前事务。最后 SQLite 会释放这个排他锁。\n```markdown\nNote: 在SQLite中，\"reserved lock\"（保留锁）是一种用于数据库文件的文件级别锁定机制。它是SQLite中的一种锁定状态，用于控制对数据库文件的并发访问。\n\n当一个进程（或连接）以写模式打开一个SQLite数据库文件时，它会尝试获取一个保留锁。这个锁阻止其他进程以写模式打开同一个数据库文件。也就是说，只有一个进程可以以写模式打开数据库文件，以防止多个进程同时修改数据库并导致数据损坏或不一致。\n\n当一个进程成功获取了保留锁并以写模式打开数据库文件时，其他进程只能以只读模式打开该文件，或者等待保留锁释放后才能以写模式打开。这样可以确保在一个时间点只有一个进程进行写操作，而其他进程可以并发地读取数据库。\n\n需要注意的是，SQLite的保留锁是在文件级别上进行的，而不是在表或行级别上。这意味着一个进程可以以写模式修改数据库中的任何表和行，而其他进程在持有只读锁时可以读取整个数据库的内容。\n\n保留锁是SQLite内部用于实现并发控制的机制，开发人员通常不需要直接操作或处理保留锁。它是SQLite的一部分，用于确保数据库的一致性和并发访问的正确性。\n```\n\n### WAL模式\n\nWrite-Ahead Log（WAL）是数据库中另一个重要机制，概念上属于回滚模式的倒置。回滚模式试讲原始页面内容写入回滚日志，然后在数据库文件上修改页面数据。而在 WAL 模式中，SQLite则是维护原有页面数据，而将修改信息写入到单独的 WAL 文件中。当开始一个事务时，SQLite 会记录最后一次有效提交的位置，作为 end mark。当 SQLite 需要一个页面时，它会尝试搜索 最近版本的WAL。如果页面不存在于 WAL 中，SQLite 就会从数据库文件中拉取页。对数据库的修改会仅仅写入到 WAL log 的最后面。这里就会提到一个 checkpoint 机制，当某次提交导致 WAL日志达到某个特定大小时，SQLite 就会将WAL 中更新的页面写回数据库文件。在提交之后，系统也不会直接删除 WAL 文件，而是会反复写入 WAL 文件，以达到文件复用的目的，降低因新建WAL 文件等操作带来的开销。（这个机制有点类似于循环缓冲区的实现逻辑，类似思想在很多其他场景也有应用）\n\nWAL模式有两大优点：第一可以显著提高并发度，因为读操作仍然可以继续执行，只有在 WAL 提交时才需要阻塞读。第二就是 WAL 由于减少了对持久化存储的写入操作，它明显更快一些。\n\n但是 WAL 同时也有不可忽视的缺点。为了加速 WAL 的搜索，SQLite 在共享内存中创建了 WAL index，用于优化读事务性能。但是，共享内存要求所有读都要在同一台机器上。另外 WAL 模式无法在网络文件系统中工作；在进入 WAL 模式后，我们也无法修改页面大小（？）。另外 WAL 模式也增加了系统的复杂复，包括 checkpoint 操作和其他与 WAL 相关的操作。\n\n## SQLite 的workload 和硬件变化\n\n过去这些年，随着电子设备不断发展，SQLite 运行的平台也发生了很大的性能变化，与此同时，基于对 SQLite 使用的统计，SQLite 的使用场景和最初涉及目标场景已经有了很大的区别，一部分是简单的键值对查找，然而存在一个长尾场景，有许多复杂的 OLAP 操作也运行在 SQLite 中，这些 query 里面有很多都会涉及到多张表的 join 操作。此外大概有 25% 左右的语句涉及到数据库的写操作，大部分写是 UPSERT 操作。\n\n```markdown\n当涉及JOIN操作时，数据库系统通常会使用以下算法和技术来实现不同类型的JOIN：\n\n1. 嵌套循环连接（Nested Loop Join）：\n   - 对于每个外部表的行，遍历内部表的每一行，并检查连接条件是否满足。\n   - 如果连接条件成立，则将两个行组合在一起形成结果集。\n   - 这种算法的时间复杂度为O(N*M)，其中N是外部表的行数，M是内部表的行数。\n   - 嵌套循环连接适用于小型表或连接条件能够有效筛选出匹配行的情况。\n\n2. 哈希连接（Hash Join）：\n   - 将一个表的连接列进行哈希处理，并构建哈希表。\n   - 遍历另一个表的每一行，并使用哈希表快速查找匹配的行。\n   - 如果连接条件成立，则将两个行组合在一起形成结果集。\n   - 哈希连接适用于大型表的连接，尤其是在内存中可以容纳哈希表的情况下。\n   - 这种算法的时间复杂度取决于哈希表的构建和查询性能。\n\n3. 排序合并连接（Merge Join）：\n   - 对连接列进行排序，使得两个表的连接列按升序排列。\n   - 使用双指针来同时遍历两个已排序的连接列，并进行比较。\n   - 如果连接条件成立，则将两个行组合在一起形成结果集。\n   - 排序合并连接适用于已经有序的表或结果集。\n   - 这种算法的时间复杂度为O(NlogN)，其中N是连接的行数。\n\n除了这些基本的JOIN算法，数据库系统还可能使用其他优化技术来提高JOIN操作的性能，例如：\n\n- 索引优化：使用索引来加速JOIN操作，特别是在连接列上创建适当的索引。\n- 并行处理：将JOIN操作分成多个并行任务，以提高查询的执行效率。\n- 物化视图（Materialized Views）：创建预计算的中间结果集，以减少JOIN操作的计算量。\n- 布隆过滤器（Bloom Filter）：使用布隆过滤器来过滤不可能匹配的行，减少实际的比较操作。\n\n这些技术的选择和应用取决于数据库系统的实现和优化策略，以及查询的特性和表的大小。数据库系统的优化器通常会根据统计信息、成本估算和查询优化规则来选择最合适的JOIN算法，并生成最优的查询计划。\n\n```\n\n现在的硬件扩展对 SQLite 的性能有了更高的要求。SQLite 一般不使用多线程，以达到更高的性能。为了给海量数据排序，SQLite 可以选择开启一个多线程的外部归并排序。对于其他操作，SQLite 一般直接在调用线程中完成。这种设计能够最小化其他线程的资源竞用。正常来说，SQLite 与其他 OLAP 数据库相比并不具有竞争力，但是 DuckDB 集成了向量化引擎和并行查询处理，给 DuckDB 提供了良好的 OLAP 性能。\n\n```markdown\n向量化引擎（Vectorized Engine）是一种优化技术，用于执行数据处理和计算任务。它是在现代计算机体系结构中针对数据密集型操作的一种高效执行方式。\n\n传统上，计算机的指令集（Instruction Set Architecture，ISA）主要是以标量操作为基础，即一次只处理一个数据元素。然而，随着计算机硬件的发展和数据密集型计算需求的增加，引入向量化引擎成为一种优化策略。\n\n向量化引擎通过将一组数据元素作为一个向量，同时执行相同的操作，以并行处理多个数据元素。这种向量操作可以在同一指令下处理多个数据元素，从而提高计算效率和性能。\n\n向量化引擎的工作原理是利用特定的硬件指令集和并行计算技术，如SIMD（Single Instruction, Multiple Data）指令集。SIMD指令集允许在单个指令中同时操作多个数据元素，减少了指令级别的开销，并且能够在一个时钟周期内处理多个数据。\n\n在向量化引擎中，数据通常以连续的存储方式进行排列，这样可以充分利用硬件的高速缓存和数据预取技术，提高数据访问效率。\n\n向量化引擎广泛应用于许多数据密集型任务，例如科学计算、图像处理、音频处理、机器学习和数据库查询等。它能够显著加速这些任务的执行速度，并提高计算机系统的吞吐量。\n\n需要注意的是，向量化引擎的有效性取决于具体的硬件支持和编程模型。软件开发人员需要使用适当的编程技术和工具，如使用向量化指令集的编程语言扩展或优化的库，以利用向量化引擎的优势。\n\n\n并行查询处理是一种数据库查询优化和执行技术，通过同时在多个处理单元上执行查询任务的不同部分来加快查询的执行速度。\n\n在并行查询处理中，查询被分解成多个子任务，并且这些子任务可以并行地在不同的处理单元上执行。每个处理单元可以是独立的线程、进程或计算节点，以利用系统中的多核处理器、多个计算节点或并行计算集群。\n\n并行查询处理的目标是最大限度地利用系统的计算资源，从而加速查询的执行。通过并行执行不同的查询操作，如并行连接、并行排序、并行聚合等，可以减少查询的总体执行时间，并提高数据库系统的并发性能和吞吐量。\n\n并行查询处理的优势包括：\n\n1. 提高查询性能：通过并行执行查询的不同部分，可以有效利用多个处理单元的计算资源，从而减少查询的总体执行时间。\n\n2. 处理大规模数据：对于大型数据集，通过并行查询处理可以分摊数据处理的负载，更高效地处理大规模数据。\n\n3. 并发执行：并行查询处理可以支持并发查询执行，多个查询可以同时进行，提高系统的并发性能和用户的响应时间。\n\n需要注意的是，并行查询处理的实现和效果取决于具体的数据库系统和硬件架构。数据库系统需要具备适当的并行查询优化器和调度器，以及支持并行计算的硬件资源。同时，数据的划分、分布和访问模式也会影响并行查询处理的性能和效果。\n\n总结而言，并行查询处理是一种利用多个处理单元并行执行查询任务的技术，旨在提高查询的执行速度和系统的并发性能。它在大规模数据处理和高并发查询场景下具有重要的作用，可以显著提升数据库系统的效率和性能。\n```\n\n## 性能评估实验\n\n作者接下来使用 SQLite 和 DuckDB 来评估不同场景下的性能。首先使用了 TATP benchmark 来评估 OLTP 场景下的性能。由于 DuckDB 主要是设计满足 OLAP 场景下的需求，因此其吞吐量在实验中远远不及 SQLite 的吞吐量。在数据规模达到百万级别时，SQLite的在 Cloud server 上的TPS能达到 10k左右，比 DuckDB 高了几个数量级。接着又使用了 Star Schema Benchmark 来评估了 OLAP 场景下的性能。在这一场景下，DuckDB 展示了极佳的性能，在延迟上 比 SQLite 快了 10 倍到数十倍不等。\n\n为了理解这一性能差距，作者同时对 SQLite 的执行引擎做了profiling，分析得出主要是`SeekRowid`和`Column`操作耗费了大量时间。`SeekRowid`是为了在 B-tree 上找到对应 row id 的行，用来执行 join 操作；而 `Column`是为了提取给定记录的列值。基于这一结果，作者给出了两个关键的优化目标：避免不必要的 B-tree探测同时流化值提取过程。\n\n### 避免不必要的 B-tree 探测\n\nSQLite 使用嵌套循环来实现 join 操作，内循环往往可以通过索引来加速。为了优化 join 操作的效率，作者通过布隆过滤器来实现 SQLite 的Lookahead Information Passing（LIP）。说白了其实就是通过布隆过滤器来加速 join 操作中对内表的检索操作，使用布隆过滤器后，实验观测到可最多十倍的性能提升。\n\n```markdown\n在数据库领域中，Lookahead Information Passing（LIP）是一种查询优化技术，用于改善查询执行的效率和性能。\n\n在数据库查询优化过程中，查询优化器需要决定查询的执行计划，即确定查询中各个操作的执行顺序和方法。这涉及到选择合适的连接算法、访问方法、排序策略等，以便在给定的查询条件下，尽量高效地访问和处理数据。\n\nLIP技术在查询优化中的作用是提前获取和传递后续操作的信息，以辅助当前操作的执行计划选择。它基于对查询语句和数据库统计信息的分析，预测和收集后续操作的属性、选择性、数据分布等特征，并将这些信息传递给当前操作的优化过程。\n\n通过使用LIP技术，查询优化器可以更好地理解查询的整体语义和后续操作的特性，从而在制定执行计划时做出更准确的决策。例如，当优化器决定连接两个表时，LIP技术可以提供关于后续操作的信息，如后续操作中涉及的列、选择性、数据分布等，以便优化器选择最佳的连接算法和连接顺序。\n\nLIP技术在数据库查询优化中的应用有助于生成更高效的查询执行计划，从而提升查询的执行性能和效率。它可以减少不必要的计算和数据访问操作，优化查询的资源利用和数据处理方式，以适应特定的查询场景和优化目标。\n\n需要指出的是，LIP技术在数据库查询优化中可能涉及到多个方面，包括查询解析、查询重写、代价估算等。不同的数据库管理系统和查询优化器可能采用不同的LIP策略和实现方式，以适应特定的数据库架构和查询优化需求。\n\n```\n\n### 流化值提取过程\n\n这部分逻辑相对应的会涉及到更具体的 SQLite 存储模式。SQLite record 由两部分组成：header 和 body。header 中存储了记录的类型码等元数据信息，body 中存储了记录的数据信息。为了提取值信息，SQLite 首先回到 head 里面找到一个指针，然后通过header 中的类型码遍历数据，直到找到对应的列。这种模式显然不适合 OLAP 场景下的流化数据提取。作者也尝试了其他方式去优化其数据提取过程，但是为了避免破坏 SQLite 在不同平台的稳定性，作者放弃了这部分优化。\n\n与此同时，作者又比较了BLOB 场景下的吞吐量，发现 SQLite 在 10KB 大小 blob 时吞吐量最佳，TPS 能够达到 9k 左右。随着 blob 的增大，其性能逐渐拉跨，甚至比不上文件系统的吞吐。这是由于 WAL 只允许 1000 个页，相当于大约 4MB 的大小限制，这带来了额外的写开销。\n\n作者同时比较了SQLite 和 DuckDB 的资源使用情况，比较有意思的点是 SQLite 在load 实验数据时虽然最终产生的数据库文件大约是 DuckDB 的两倍，但加载时间明显快于 DuckDB，作者没有详细解释这是为什么。\n\n在文章最后，作者提到了为什么没有对 SQLite 做 OLAP 场景下的优化，这是由于 SQLite 是一个通用型的数据引擎，为了保证不同场景下的性能和兼容性，不得不放弃一部分优化方式。然而，通过一些空间换时间的方式也能加速 OLAP 场景下的性能。通过向量化执行、数据压缩、运行时代码生成、和物化聚集等方式可以对一个传统的 OLTP 引擎进行 OLAP 场景下的优化，但是哪种方式能够最大化优化性能、哪些没有太大的优化价值，就需要这篇文章中的各类性能评估实验。这应该也是作者写这篇文章的动机。\n\n总的来说，这篇文章介绍了 SQLite 大致的历史沿革、系统架构和性能评估数据，虽然创新性上感觉稍显不足，但是比较扎实地进行了一系列实验比较，为 SQLite 的优化提供了比较好的参考数据。","slug":"papers/SQLite","published":1,"updated":"2023-07-30T06:11:37.246Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6ix000e1ts14nucc7cv","content":"<h1 id=\"SQLite-Past-Present-Future\"><a href=\"#SQLite-Past-Present-Future\" class=\"headerlink\" title=\"SQLite: Past, Present, Future\"></a>SQLite: Past, Present, Future</h1><p>这篇文章是 22 年 VLDB 的一篇文章，文章主要介绍了 SQLite 的历史沿革及在 OLAP 领域的应用和优化。</p>\n<span id=\"more\"></span>\n\n<p>我是第一次听说DuckDB这个名字，问了一下 chatGPT，下面是 chatGPT 的回答：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DuckDB是一个开源的内存列存储数据库管理系统（DBMS），专为高性能和低延迟的分析查询而设计。它的目标是提供类似传统数据库系统的SQL查询能力，同时在处理大规模数据集时保持快速响应时间。</span><br><span class=\"line\"></span><br><span class=\"line\">DuckDB的设计着重于内存处理，它将数据存储在计算机的内存中，以便快速读取和查询。相比磁盘存储的数据库系统，内存存储具有更快的访问速度，因为内存中的数据可以直接读取，而无需磁盘I/O操作。这使得DuckDB在需要实时查询和交互式分析的场景中非常有用。</span><br><span class=\"line\"></span><br><span class=\"line\">此外，DuckDB还采用了列存储的方式来组织和管理数据。与传统的行存储不同，列存储将每个列的数据连续存储在一起，这种存储方式在分析查询中具有更好的性能。列存储可以有效地压缩数据，减少存储空间，并且在处理只涉及部分列的查询时更加高效。</span><br><span class=\"line\"></span><br><span class=\"line\">DuckDB支持标准的SQL查询语言，可以进行复杂的查询、连接和聚合操作。它还提供了对Python、R和其他编程语言的接口，使得开发人员可以方便地在自己熟悉的编程环境中使用DuckDB进行数据分析和处理。</span><br><span class=\"line\"></span><br><span class=\"line\">总而言之，DuckDB是一个专注于内存处理和列存储的高性能数据库系统，适用于需要快速查询和分析大规模数据集的场景。</span><br></pre></td></tr></table></figure>\n\n<p>这篇文章主要贡献如下：</p>\n<ul>\n<li>介绍了 SQLite 的历史沿革</li>\n<li>对 SQLite 的特性进行了系统的评估</li>\n<li>在数据分析工作场景下对 SQLite 进行了优化</li>\n<li>确定了一些嵌入式数据引擎性能衡量指标</li>\n<li>对未来 SQLite 的进一步性能优化进行了方向性的叙述</li>\n</ul>\n<p>下面按照文章整体脉络梳理一下文章的内容。</p>\n<h2 id=\"SQLite-的架构\"><a href=\"#SQLite-的架构\" class=\"headerlink\" title=\"SQLite 的架构\"></a>SQLite 的架构</h2><p><img src=\"/images/SQLite_Architecture.png\" alt=\"SQLite 的整体架构\"></p>\n<p>SQLite 主要包括四个大的模块：</p>\n<ul>\n<li>SQL Complier：SQLite 中 SQL 编译模块的运行类似一个编译器，通过词法分析、语法分析和语义分析来编译 SQL 语句，形成一个字节码的可执行程序，由一系列虚拟指令构成。</li>\n<li>Core：SQLite的核心执行引擎负责处理所有数据库的底层操作。它以一个虚拟机的形式存在，会对 compiler 生成的字节码逐一执行。</li>\n<li>Backend：存储引擎，负责将数据持久化磁盘上。SQLite使用B树（B-tree）作为其默认的存储引擎，包括索引 B 树和表 B 树。B树是一种用于高效存储和检索数据的数据结构，它允许快速的索引查找和范围查询。 SQLite 使用叫做虚拟文件系统（virtual file system, VFS）的抽象对象来实现不同操作系统的可移植性，对于不同的操作系统，它会有不同的 VFS。</li>\n<li>Accessories：SQLite的附加模块，包括一些 UT 和工具函数：包括内存分配、字符串操作、随机数操作等。</li>\n</ul>\n<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><p>SQLite 是一个支持事务的数据库引擎，通过回滚和 WAL 模式，能够满足 ACID 四个特性。（这是面试数据库团队经常会考到的一个八股文）</p>\n<h3 id=\"回滚模式\"><a href=\"#回滚模式\" class=\"headerlink\" title=\"回滚模式\"></a>回滚模式</h3><p>在回滚模式中，SQLite 在执行事务时需要获取数据库文件的共享锁，当事务涉及对数据库的更改时，SQLite 就会将读锁升级为保留锁(reserved lock)，从而阻塞其他写入的事务，但是仍然允许读操作。在执行写操作前，SQLite 会创建一个回滚日志。对于每个页面，SQLite 会将其原始数据写入回滚日志，并将更新后的页面保留在用户空间。当 SQLite 提交事务时，它就会把回滚日志刷入持久化存储。然后，SQLite 会获取一个数据库文件的排他锁，用来 block 其他的读写操作，同时写入当前更改。更改后的页面会刷入持久化存储中。回滚日志接着会通过多个机制中的某一个来作废掉，取决于日志模式。在 DELETE 模式中，SQLite会将回滚日志删除掉，但是由于删除操作本身成本较高，SQLite 同时也会提供其他方式来使日志无效，比如在 TRUNCATE 模式中，回滚日志会被截断而非删除；在 PERSIST 模式中，会被日志头会被覆写成 0。作废回滚日志操作会提交当前事务。最后 SQLite 会释放这个排他锁。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: 在SQLite中，&quot;reserved lock&quot;（保留锁）是一种用于数据库文件的文件级别锁定机制。它是SQLite中的一种锁定状态，用于控制对数据库文件的并发访问。</span><br><span class=\"line\"></span><br><span class=\"line\">当一个进程（或连接）以写模式打开一个SQLite数据库文件时，它会尝试获取一个保留锁。这个锁阻止其他进程以写模式打开同一个数据库文件。也就是说，只有一个进程可以以写模式打开数据库文件，以防止多个进程同时修改数据库并导致数据损坏或不一致。</span><br><span class=\"line\"></span><br><span class=\"line\">当一个进程成功获取了保留锁并以写模式打开数据库文件时，其他进程只能以只读模式打开该文件，或者等待保留锁释放后才能以写模式打开。这样可以确保在一个时间点只有一个进程进行写操作，而其他进程可以并发地读取数据库。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，SQLite的保留锁是在文件级别上进行的，而不是在表或行级别上。这意味着一个进程可以以写模式修改数据库中的任何表和行，而其他进程在持有只读锁时可以读取整个数据库的内容。</span><br><span class=\"line\"></span><br><span class=\"line\">保留锁是SQLite内部用于实现并发控制的机制，开发人员通常不需要直接操作或处理保留锁。它是SQLite的一部分，用于确保数据库的一致性和并发访问的正确性。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"WAL模式\"><a href=\"#WAL模式\" class=\"headerlink\" title=\"WAL模式\"></a>WAL模式</h3><p>Write-Ahead Log（WAL）是数据库中另一个重要机制，概念上属于回滚模式的倒置。回滚模式试讲原始页面内容写入回滚日志，然后在数据库文件上修改页面数据。而在 WAL 模式中，SQLite则是维护原有页面数据，而将修改信息写入到单独的 WAL 文件中。当开始一个事务时，SQLite 会记录最后一次有效提交的位置，作为 end mark。当 SQLite 需要一个页面时，它会尝试搜索 最近版本的WAL。如果页面不存在于 WAL 中，SQLite 就会从数据库文件中拉取页。对数据库的修改会仅仅写入到 WAL log 的最后面。这里就会提到一个 checkpoint 机制，当某次提交导致 WAL日志达到某个特定大小时，SQLite 就会将WAL 中更新的页面写回数据库文件。在提交之后，系统也不会直接删除 WAL 文件，而是会反复写入 WAL 文件，以达到文件复用的目的，降低因新建WAL 文件等操作带来的开销。（这个机制有点类似于循环缓冲区的实现逻辑，类似思想在很多其他场景也有应用）</p>\n<p>WAL模式有两大优点：第一可以显著提高并发度，因为读操作仍然可以继续执行，只有在 WAL 提交时才需要阻塞读。第二就是 WAL 由于减少了对持久化存储的写入操作，它明显更快一些。</p>\n<p>但是 WAL 同时也有不可忽视的缺点。为了加速 WAL 的搜索，SQLite 在共享内存中创建了 WAL index，用于优化读事务性能。但是，共享内存要求所有读都要在同一台机器上。另外 WAL 模式无法在网络文件系统中工作；在进入 WAL 模式后，我们也无法修改页面大小（？）。另外 WAL 模式也增加了系统的复杂复，包括 checkpoint 操作和其他与 WAL 相关的操作。</p>\n<h2 id=\"SQLite-的workload-和硬件变化\"><a href=\"#SQLite-的workload-和硬件变化\" class=\"headerlink\" title=\"SQLite 的workload 和硬件变化\"></a>SQLite 的workload 和硬件变化</h2><p>过去这些年，随着电子设备不断发展，SQLite 运行的平台也发生了很大的性能变化，与此同时，基于对 SQLite 使用的统计，SQLite 的使用场景和最初涉及目标场景已经有了很大的区别，一部分是简单的键值对查找，然而存在一个长尾场景，有许多复杂的 OLAP 操作也运行在 SQLite 中，这些 query 里面有很多都会涉及到多张表的 join 操作。此外大概有 25% 左右的语句涉及到数据库的写操作，大部分写是 UPSERT 操作。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">当涉及JOIN操作时，数据库系统通常会使用以下算法和技术来实现不同类型的JOIN：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 嵌套循环连接（Nested Loop Join）：</span><br><span class=\"line\"><span class=\"bullet\">   -</span> 对于每个外部表的行，遍历内部表的每一行，并检查连接条件是否满足。</span><br><span class=\"line\"><span class=\"bullet\">   -</span> 如果连接条件成立，则将两个行组合在一起形成结果集。</span><br><span class=\"line\"><span class=\"bullet\">   -</span> 这种算法的时间复杂度为O(N<span class=\"emphasis\">*M)，其中N是外部表的行数，M是内部表的行数。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 嵌套循环连接适用于小型表或连接条件能够有效筛选出匹配行的情况。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">2. 哈希连接（Hash Join）：</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 将一个表的连接列进行哈希处理，并构建哈希表。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 遍历另一个表的每一行，并使用哈希表快速查找匹配的行。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 如果连接条件成立，则将两个行组合在一起形成结果集。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 哈希连接适用于大型表的连接，尤其是在内存中可以容纳哈希表的情况下。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 这种算法的时间复杂度取决于哈希表的构建和查询性能。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">3. 排序合并连接（Merge Join）：</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 对连接列进行排序，使得两个表的连接列按升序排列。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 使用双指针来同时遍历两个已排序的连接列，并进行比较。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 如果连接条件成立，则将两个行组合在一起形成结果集。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 排序合并连接适用于已经有序的表或结果集。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 这种算法的时间复杂度为O(NlogN)，其中N是连接的行数。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">除了这些基本的JOIN算法，数据库系统还可能使用其他优化技术来提高JOIN操作的性能，例如：</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">- 索引优化：使用索引来加速JOIN操作，特别是在连接列上创建适当的索引。</span></span><br><span class=\"line\"><span class=\"emphasis\">- 并行处理：将JOIN操作分成多个并行任务，以提高查询的执行效率。</span></span><br><span class=\"line\"><span class=\"emphasis\">- 物化视图（Materialized Views）：创建预计算的中间结果集，以减少JOIN操作的计算量。</span></span><br><span class=\"line\"><span class=\"emphasis\">- 布隆过滤器（Bloom Filter）：使用布隆过滤器来过滤不可能匹配的行，减少实际的比较操作。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">这些技术的选择和应用取决于数据库系统的实现和优化策略，以及查询的特性和表的大小。数据库系统的优化器通常会根据统计信息、成本估算和查询优化规则来选择最合适的JOIN算法，并生成最优的查询计划。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br></pre></td></tr></table></figure>\n\n<p>现在的硬件扩展对 SQLite 的性能有了更高的要求。SQLite 一般不使用多线程，以达到更高的性能。为了给海量数据排序，SQLite 可以选择开启一个多线程的外部归并排序。对于其他操作，SQLite 一般直接在调用线程中完成。这种设计能够最小化其他线程的资源竞用。正常来说，SQLite 与其他 OLAP 数据库相比并不具有竞争力，但是 DuckDB 集成了向量化引擎和并行查询处理，给 DuckDB 提供了良好的 OLAP 性能。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">向量化引擎（Vectorized Engine）是一种优化技术，用于执行数据处理和计算任务。它是在现代计算机体系结构中针对数据密集型操作的一种高效执行方式。</span><br><span class=\"line\"></span><br><span class=\"line\">传统上，计算机的指令集（Instruction Set Architecture，ISA）主要是以标量操作为基础，即一次只处理一个数据元素。然而，随着计算机硬件的发展和数据密集型计算需求的增加，引入向量化引擎成为一种优化策略。</span><br><span class=\"line\"></span><br><span class=\"line\">向量化引擎通过将一组数据元素作为一个向量，同时执行相同的操作，以并行处理多个数据元素。这种向量操作可以在同一指令下处理多个数据元素，从而提高计算效率和性能。</span><br><span class=\"line\"></span><br><span class=\"line\">向量化引擎的工作原理是利用特定的硬件指令集和并行计算技术，如SIMD（Single Instruction, Multiple Data）指令集。SIMD指令集允许在单个指令中同时操作多个数据元素，减少了指令级别的开销，并且能够在一个时钟周期内处理多个数据。</span><br><span class=\"line\"></span><br><span class=\"line\">在向量化引擎中，数据通常以连续的存储方式进行排列，这样可以充分利用硬件的高速缓存和数据预取技术，提高数据访问效率。</span><br><span class=\"line\"></span><br><span class=\"line\">向量化引擎广泛应用于许多数据密集型任务，例如科学计算、图像处理、音频处理、机器学习和数据库查询等。它能够显著加速这些任务的执行速度，并提高计算机系统的吞吐量。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，向量化引擎的有效性取决于具体的硬件支持和编程模型。软件开发人员需要使用适当的编程技术和工具，如使用向量化指令集的编程语言扩展或优化的库，以利用向量化引擎的优势。</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">并行查询处理是一种数据库查询优化和执行技术，通过同时在多个处理单元上执行查询任务的不同部分来加快查询的执行速度。</span><br><span class=\"line\"></span><br><span class=\"line\">在并行查询处理中，查询被分解成多个子任务，并且这些子任务可以并行地在不同的处理单元上执行。每个处理单元可以是独立的线程、进程或计算节点，以利用系统中的多核处理器、多个计算节点或并行计算集群。</span><br><span class=\"line\"></span><br><span class=\"line\">并行查询处理的目标是最大限度地利用系统的计算资源，从而加速查询的执行。通过并行执行不同的查询操作，如并行连接、并行排序、并行聚合等，可以减少查询的总体执行时间，并提高数据库系统的并发性能和吞吐量。</span><br><span class=\"line\"></span><br><span class=\"line\">并行查询处理的优势包括：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 提高查询性能：通过并行执行查询的不同部分，可以有效利用多个处理单元的计算资源，从而减少查询的总体执行时间。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 处理大规模数据：对于大型数据集，通过并行查询处理可以分摊数据处理的负载，更高效地处理大规模数据。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 并发执行：并行查询处理可以支持并发查询执行，多个查询可以同时进行，提高系统的并发性能和用户的响应时间。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，并行查询处理的实现和效果取决于具体的数据库系统和硬件架构。数据库系统需要具备适当的并行查询优化器和调度器，以及支持并行计算的硬件资源。同时，数据的划分、分布和访问模式也会影响并行查询处理的性能和效果。</span><br><span class=\"line\"></span><br><span class=\"line\">总结而言，并行查询处理是一种利用多个处理单元并行执行查询任务的技术，旨在提高查询的执行速度和系统的并发性能。它在大规模数据处理和高并发查询场景下具有重要的作用，可以显著提升数据库系统的效率和性能。</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"性能评估实验\"><a href=\"#性能评估实验\" class=\"headerlink\" title=\"性能评估实验\"></a>性能评估实验</h2><p>作者接下来使用 SQLite 和 DuckDB 来评估不同场景下的性能。首先使用了 TATP benchmark 来评估 OLTP 场景下的性能。由于 DuckDB 主要是设计满足 OLAP 场景下的需求，因此其吞吐量在实验中远远不及 SQLite 的吞吐量。在数据规模达到百万级别时，SQLite的在 Cloud server 上的TPS能达到 10k左右，比 DuckDB 高了几个数量级。接着又使用了 Star Schema Benchmark 来评估了 OLAP 场景下的性能。在这一场景下，DuckDB 展示了极佳的性能，在延迟上 比 SQLite 快了 10 倍到数十倍不等。</p>\n<p>为了理解这一性能差距，作者同时对 SQLite 的执行引擎做了profiling，分析得出主要是<code>SeekRowid</code>和<code>Column</code>操作耗费了大量时间。<code>SeekRowid</code>是为了在 B-tree 上找到对应 row id 的行，用来执行 join 操作；而 <code>Column</code>是为了提取给定记录的列值。基于这一结果，作者给出了两个关键的优化目标：避免不必要的 B-tree探测同时流化值提取过程。</p>\n<h3 id=\"避免不必要的-B-tree-探测\"><a href=\"#避免不必要的-B-tree-探测\" class=\"headerlink\" title=\"避免不必要的 B-tree 探测\"></a>避免不必要的 B-tree 探测</h3><p>SQLite 使用嵌套循环来实现 join 操作，内循环往往可以通过索引来加速。为了优化 join 操作的效率，作者通过布隆过滤器来实现 SQLite 的Lookahead Information Passing（LIP）。说白了其实就是通过布隆过滤器来加速 join 操作中对内表的检索操作，使用布隆过滤器后，实验观测到可最多十倍的性能提升。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在数据库领域中，Lookahead Information Passing（LIP）是一种查询优化技术，用于改善查询执行的效率和性能。</span><br><span class=\"line\"></span><br><span class=\"line\">在数据库查询优化过程中，查询优化器需要决定查询的执行计划，即确定查询中各个操作的执行顺序和方法。这涉及到选择合适的连接算法、访问方法、排序策略等，以便在给定的查询条件下，尽量高效地访问和处理数据。</span><br><span class=\"line\"></span><br><span class=\"line\">LIP技术在查询优化中的作用是提前获取和传递后续操作的信息，以辅助当前操作的执行计划选择。它基于对查询语句和数据库统计信息的分析，预测和收集后续操作的属性、选择性、数据分布等特征，并将这些信息传递给当前操作的优化过程。</span><br><span class=\"line\"></span><br><span class=\"line\">通过使用LIP技术，查询优化器可以更好地理解查询的整体语义和后续操作的特性，从而在制定执行计划时做出更准确的决策。例如，当优化器决定连接两个表时，LIP技术可以提供关于后续操作的信息，如后续操作中涉及的列、选择性、数据分布等，以便优化器选择最佳的连接算法和连接顺序。</span><br><span class=\"line\"></span><br><span class=\"line\">LIP技术在数据库查询优化中的应用有助于生成更高效的查询执行计划，从而提升查询的执行性能和效率。它可以减少不必要的计算和数据访问操作，优化查询的资源利用和数据处理方式，以适应特定的查询场景和优化目标。</span><br><span class=\"line\"></span><br><span class=\"line\">需要指出的是，LIP技术在数据库查询优化中可能涉及到多个方面，包括查询解析、查询重写、代价估算等。不同的数据库管理系统和查询优化器可能采用不同的LIP策略和实现方式，以适应特定的数据库架构和查询优化需求。</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"流化值提取过程\"><a href=\"#流化值提取过程\" class=\"headerlink\" title=\"流化值提取过程\"></a>流化值提取过程</h3><p>这部分逻辑相对应的会涉及到更具体的 SQLite 存储模式。SQLite record 由两部分组成：header 和 body。header 中存储了记录的类型码等元数据信息，body 中存储了记录的数据信息。为了提取值信息，SQLite 首先回到 head 里面找到一个指针，然后通过header 中的类型码遍历数据，直到找到对应的列。这种模式显然不适合 OLAP 场景下的流化数据提取。作者也尝试了其他方式去优化其数据提取过程，但是为了避免破坏 SQLite 在不同平台的稳定性，作者放弃了这部分优化。</p>\n<p>与此同时，作者又比较了BLOB 场景下的吞吐量，发现 SQLite 在 10KB 大小 blob 时吞吐量最佳，TPS 能够达到 9k 左右。随着 blob 的增大，其性能逐渐拉跨，甚至比不上文件系统的吞吐。这是由于 WAL 只允许 1000 个页，相当于大约 4MB 的大小限制，这带来了额外的写开销。</p>\n<p>作者同时比较了SQLite 和 DuckDB 的资源使用情况，比较有意思的点是 SQLite 在load 实验数据时虽然最终产生的数据库文件大约是 DuckDB 的两倍，但加载时间明显快于 DuckDB，作者没有详细解释这是为什么。</p>\n<p>在文章最后，作者提到了为什么没有对 SQLite 做 OLAP 场景下的优化，这是由于 SQLite 是一个通用型的数据引擎，为了保证不同场景下的性能和兼容性，不得不放弃一部分优化方式。然而，通过一些空间换时间的方式也能加速 OLAP 场景下的性能。通过向量化执行、数据压缩、运行时代码生成、和物化聚集等方式可以对一个传统的 OLTP 引擎进行 OLAP 场景下的优化，但是哪种方式能够最大化优化性能、哪些没有太大的优化价值，就需要这篇文章中的各类性能评估实验。这应该也是作者写这篇文章的动机。</p>\n<p>总的来说，这篇文章介绍了 SQLite 大致的历史沿革、系统架构和性能评估数据，虽然创新性上感觉稍显不足，但是比较扎实地进行了一系列实验比较，为 SQLite 的优化提供了比较好的参考数据。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"SQLite-Past-Present-Future\"><a href=\"#SQLite-Past-Present-Future\" class=\"headerlink\" title=\"SQLite: Past, Present, Future\"></a>SQLite: Past, Present, Future</h1><p>这篇文章是 22 年 VLDB 的一篇文章，文章主要介绍了 SQLite 的历史沿革及在 OLAP 领域的应用和优化。</p>","more":"<p>我是第一次听说DuckDB这个名字，问了一下 chatGPT，下面是 chatGPT 的回答：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DuckDB是一个开源的内存列存储数据库管理系统（DBMS），专为高性能和低延迟的分析查询而设计。它的目标是提供类似传统数据库系统的SQL查询能力，同时在处理大规模数据集时保持快速响应时间。</span><br><span class=\"line\"></span><br><span class=\"line\">DuckDB的设计着重于内存处理，它将数据存储在计算机的内存中，以便快速读取和查询。相比磁盘存储的数据库系统，内存存储具有更快的访问速度，因为内存中的数据可以直接读取，而无需磁盘I/O操作。这使得DuckDB在需要实时查询和交互式分析的场景中非常有用。</span><br><span class=\"line\"></span><br><span class=\"line\">此外，DuckDB还采用了列存储的方式来组织和管理数据。与传统的行存储不同，列存储将每个列的数据连续存储在一起，这种存储方式在分析查询中具有更好的性能。列存储可以有效地压缩数据，减少存储空间，并且在处理只涉及部分列的查询时更加高效。</span><br><span class=\"line\"></span><br><span class=\"line\">DuckDB支持标准的SQL查询语言，可以进行复杂的查询、连接和聚合操作。它还提供了对Python、R和其他编程语言的接口，使得开发人员可以方便地在自己熟悉的编程环境中使用DuckDB进行数据分析和处理。</span><br><span class=\"line\"></span><br><span class=\"line\">总而言之，DuckDB是一个专注于内存处理和列存储的高性能数据库系统，适用于需要快速查询和分析大规模数据集的场景。</span><br></pre></td></tr></table></figure>\n\n<p>这篇文章主要贡献如下：</p>\n<ul>\n<li>介绍了 SQLite 的历史沿革</li>\n<li>对 SQLite 的特性进行了系统的评估</li>\n<li>在数据分析工作场景下对 SQLite 进行了优化</li>\n<li>确定了一些嵌入式数据引擎性能衡量指标</li>\n<li>对未来 SQLite 的进一步性能优化进行了方向性的叙述</li>\n</ul>\n<p>下面按照文章整体脉络梳理一下文章的内容。</p>\n<h2 id=\"SQLite-的架构\"><a href=\"#SQLite-的架构\" class=\"headerlink\" title=\"SQLite 的架构\"></a>SQLite 的架构</h2><p><img src=\"/images/SQLite_Architecture.png\" alt=\"SQLite 的整体架构\"></p>\n<p>SQLite 主要包括四个大的模块：</p>\n<ul>\n<li>SQL Complier：SQLite 中 SQL 编译模块的运行类似一个编译器，通过词法分析、语法分析和语义分析来编译 SQL 语句，形成一个字节码的可执行程序，由一系列虚拟指令构成。</li>\n<li>Core：SQLite的核心执行引擎负责处理所有数据库的底层操作。它以一个虚拟机的形式存在，会对 compiler 生成的字节码逐一执行。</li>\n<li>Backend：存储引擎，负责将数据持久化磁盘上。SQLite使用B树（B-tree）作为其默认的存储引擎，包括索引 B 树和表 B 树。B树是一种用于高效存储和检索数据的数据结构，它允许快速的索引查找和范围查询。 SQLite 使用叫做虚拟文件系统（virtual file system, VFS）的抽象对象来实现不同操作系统的可移植性，对于不同的操作系统，它会有不同的 VFS。</li>\n<li>Accessories：SQLite的附加模块，包括一些 UT 和工具函数：包括内存分配、字符串操作、随机数操作等。</li>\n</ul>\n<h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2><p>SQLite 是一个支持事务的数据库引擎，通过回滚和 WAL 模式，能够满足 ACID 四个特性。（这是面试数据库团队经常会考到的一个八股文）</p>\n<h3 id=\"回滚模式\"><a href=\"#回滚模式\" class=\"headerlink\" title=\"回滚模式\"></a>回滚模式</h3><p>在回滚模式中，SQLite 在执行事务时需要获取数据库文件的共享锁，当事务涉及对数据库的更改时，SQLite 就会将读锁升级为保留锁(reserved lock)，从而阻塞其他写入的事务，但是仍然允许读操作。在执行写操作前，SQLite 会创建一个回滚日志。对于每个页面，SQLite 会将其原始数据写入回滚日志，并将更新后的页面保留在用户空间。当 SQLite 提交事务时，它就会把回滚日志刷入持久化存储。然后，SQLite 会获取一个数据库文件的排他锁，用来 block 其他的读写操作，同时写入当前更改。更改后的页面会刷入持久化存储中。回滚日志接着会通过多个机制中的某一个来作废掉，取决于日志模式。在 DELETE 模式中，SQLite会将回滚日志删除掉，但是由于删除操作本身成本较高，SQLite 同时也会提供其他方式来使日志无效，比如在 TRUNCATE 模式中，回滚日志会被截断而非删除；在 PERSIST 模式中，会被日志头会被覆写成 0。作废回滚日志操作会提交当前事务。最后 SQLite 会释放这个排他锁。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: 在SQLite中，&quot;reserved lock&quot;（保留锁）是一种用于数据库文件的文件级别锁定机制。它是SQLite中的一种锁定状态，用于控制对数据库文件的并发访问。</span><br><span class=\"line\"></span><br><span class=\"line\">当一个进程（或连接）以写模式打开一个SQLite数据库文件时，它会尝试获取一个保留锁。这个锁阻止其他进程以写模式打开同一个数据库文件。也就是说，只有一个进程可以以写模式打开数据库文件，以防止多个进程同时修改数据库并导致数据损坏或不一致。</span><br><span class=\"line\"></span><br><span class=\"line\">当一个进程成功获取了保留锁并以写模式打开数据库文件时，其他进程只能以只读模式打开该文件，或者等待保留锁释放后才能以写模式打开。这样可以确保在一个时间点只有一个进程进行写操作，而其他进程可以并发地读取数据库。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，SQLite的保留锁是在文件级别上进行的，而不是在表或行级别上。这意味着一个进程可以以写模式修改数据库中的任何表和行，而其他进程在持有只读锁时可以读取整个数据库的内容。</span><br><span class=\"line\"></span><br><span class=\"line\">保留锁是SQLite内部用于实现并发控制的机制，开发人员通常不需要直接操作或处理保留锁。它是SQLite的一部分，用于确保数据库的一致性和并发访问的正确性。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"WAL模式\"><a href=\"#WAL模式\" class=\"headerlink\" title=\"WAL模式\"></a>WAL模式</h3><p>Write-Ahead Log（WAL）是数据库中另一个重要机制，概念上属于回滚模式的倒置。回滚模式试讲原始页面内容写入回滚日志，然后在数据库文件上修改页面数据。而在 WAL 模式中，SQLite则是维护原有页面数据，而将修改信息写入到单独的 WAL 文件中。当开始一个事务时，SQLite 会记录最后一次有效提交的位置，作为 end mark。当 SQLite 需要一个页面时，它会尝试搜索 最近版本的WAL。如果页面不存在于 WAL 中，SQLite 就会从数据库文件中拉取页。对数据库的修改会仅仅写入到 WAL log 的最后面。这里就会提到一个 checkpoint 机制，当某次提交导致 WAL日志达到某个特定大小时，SQLite 就会将WAL 中更新的页面写回数据库文件。在提交之后，系统也不会直接删除 WAL 文件，而是会反复写入 WAL 文件，以达到文件复用的目的，降低因新建WAL 文件等操作带来的开销。（这个机制有点类似于循环缓冲区的实现逻辑，类似思想在很多其他场景也有应用）</p>\n<p>WAL模式有两大优点：第一可以显著提高并发度，因为读操作仍然可以继续执行，只有在 WAL 提交时才需要阻塞读。第二就是 WAL 由于减少了对持久化存储的写入操作，它明显更快一些。</p>\n<p>但是 WAL 同时也有不可忽视的缺点。为了加速 WAL 的搜索，SQLite 在共享内存中创建了 WAL index，用于优化读事务性能。但是，共享内存要求所有读都要在同一台机器上。另外 WAL 模式无法在网络文件系统中工作；在进入 WAL 模式后，我们也无法修改页面大小（？）。另外 WAL 模式也增加了系统的复杂复，包括 checkpoint 操作和其他与 WAL 相关的操作。</p>\n<h2 id=\"SQLite-的workload-和硬件变化\"><a href=\"#SQLite-的workload-和硬件变化\" class=\"headerlink\" title=\"SQLite 的workload 和硬件变化\"></a>SQLite 的workload 和硬件变化</h2><p>过去这些年，随着电子设备不断发展，SQLite 运行的平台也发生了很大的性能变化，与此同时，基于对 SQLite 使用的统计，SQLite 的使用场景和最初涉及目标场景已经有了很大的区别，一部分是简单的键值对查找，然而存在一个长尾场景，有许多复杂的 OLAP 操作也运行在 SQLite 中，这些 query 里面有很多都会涉及到多张表的 join 操作。此外大概有 25% 左右的语句涉及到数据库的写操作，大部分写是 UPSERT 操作。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">当涉及JOIN操作时，数据库系统通常会使用以下算法和技术来实现不同类型的JOIN：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 嵌套循环连接（Nested Loop Join）：</span><br><span class=\"line\"><span class=\"bullet\">   -</span> 对于每个外部表的行，遍历内部表的每一行，并检查连接条件是否满足。</span><br><span class=\"line\"><span class=\"bullet\">   -</span> 如果连接条件成立，则将两个行组合在一起形成结果集。</span><br><span class=\"line\"><span class=\"bullet\">   -</span> 这种算法的时间复杂度为O(N<span class=\"emphasis\">*M)，其中N是外部表的行数，M是内部表的行数。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 嵌套循环连接适用于小型表或连接条件能够有效筛选出匹配行的情况。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">2. 哈希连接（Hash Join）：</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 将一个表的连接列进行哈希处理，并构建哈希表。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 遍历另一个表的每一行，并使用哈希表快速查找匹配的行。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 如果连接条件成立，则将两个行组合在一起形成结果集。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 哈希连接适用于大型表的连接，尤其是在内存中可以容纳哈希表的情况下。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 这种算法的时间复杂度取决于哈希表的构建和查询性能。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">3. 排序合并连接（Merge Join）：</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 对连接列进行排序，使得两个表的连接列按升序排列。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 使用双指针来同时遍历两个已排序的连接列，并进行比较。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 如果连接条件成立，则将两个行组合在一起形成结果集。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 排序合并连接适用于已经有序的表或结果集。</span></span><br><span class=\"line\"><span class=\"emphasis\">   - 这种算法的时间复杂度为O(NlogN)，其中N是连接的行数。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">除了这些基本的JOIN算法，数据库系统还可能使用其他优化技术来提高JOIN操作的性能，例如：</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">- 索引优化：使用索引来加速JOIN操作，特别是在连接列上创建适当的索引。</span></span><br><span class=\"line\"><span class=\"emphasis\">- 并行处理：将JOIN操作分成多个并行任务，以提高查询的执行效率。</span></span><br><span class=\"line\"><span class=\"emphasis\">- 物化视图（Materialized Views）：创建预计算的中间结果集，以减少JOIN操作的计算量。</span></span><br><span class=\"line\"><span class=\"emphasis\">- 布隆过滤器（Bloom Filter）：使用布隆过滤器来过滤不可能匹配的行，减少实际的比较操作。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br><span class=\"line\"><span class=\"emphasis\">这些技术的选择和应用取决于数据库系统的实现和优化策略，以及查询的特性和表的大小。数据库系统的优化器通常会根据统计信息、成本估算和查询优化规则来选择最合适的JOIN算法，并生成最优的查询计划。</span></span><br><span class=\"line\"><span class=\"emphasis\"></span></span><br></pre></td></tr></table></figure>\n\n<p>现在的硬件扩展对 SQLite 的性能有了更高的要求。SQLite 一般不使用多线程，以达到更高的性能。为了给海量数据排序，SQLite 可以选择开启一个多线程的外部归并排序。对于其他操作，SQLite 一般直接在调用线程中完成。这种设计能够最小化其他线程的资源竞用。正常来说，SQLite 与其他 OLAP 数据库相比并不具有竞争力，但是 DuckDB 集成了向量化引擎和并行查询处理，给 DuckDB 提供了良好的 OLAP 性能。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">向量化引擎（Vectorized Engine）是一种优化技术，用于执行数据处理和计算任务。它是在现代计算机体系结构中针对数据密集型操作的一种高效执行方式。</span><br><span class=\"line\"></span><br><span class=\"line\">传统上，计算机的指令集（Instruction Set Architecture，ISA）主要是以标量操作为基础，即一次只处理一个数据元素。然而，随着计算机硬件的发展和数据密集型计算需求的增加，引入向量化引擎成为一种优化策略。</span><br><span class=\"line\"></span><br><span class=\"line\">向量化引擎通过将一组数据元素作为一个向量，同时执行相同的操作，以并行处理多个数据元素。这种向量操作可以在同一指令下处理多个数据元素，从而提高计算效率和性能。</span><br><span class=\"line\"></span><br><span class=\"line\">向量化引擎的工作原理是利用特定的硬件指令集和并行计算技术，如SIMD（Single Instruction, Multiple Data）指令集。SIMD指令集允许在单个指令中同时操作多个数据元素，减少了指令级别的开销，并且能够在一个时钟周期内处理多个数据。</span><br><span class=\"line\"></span><br><span class=\"line\">在向量化引擎中，数据通常以连续的存储方式进行排列，这样可以充分利用硬件的高速缓存和数据预取技术，提高数据访问效率。</span><br><span class=\"line\"></span><br><span class=\"line\">向量化引擎广泛应用于许多数据密集型任务，例如科学计算、图像处理、音频处理、机器学习和数据库查询等。它能够显著加速这些任务的执行速度，并提高计算机系统的吞吐量。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，向量化引擎的有效性取决于具体的硬件支持和编程模型。软件开发人员需要使用适当的编程技术和工具，如使用向量化指令集的编程语言扩展或优化的库，以利用向量化引擎的优势。</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">并行查询处理是一种数据库查询优化和执行技术，通过同时在多个处理单元上执行查询任务的不同部分来加快查询的执行速度。</span><br><span class=\"line\"></span><br><span class=\"line\">在并行查询处理中，查询被分解成多个子任务，并且这些子任务可以并行地在不同的处理单元上执行。每个处理单元可以是独立的线程、进程或计算节点，以利用系统中的多核处理器、多个计算节点或并行计算集群。</span><br><span class=\"line\"></span><br><span class=\"line\">并行查询处理的目标是最大限度地利用系统的计算资源，从而加速查询的执行。通过并行执行不同的查询操作，如并行连接、并行排序、并行聚合等，可以减少查询的总体执行时间，并提高数据库系统的并发性能和吞吐量。</span><br><span class=\"line\"></span><br><span class=\"line\">并行查询处理的优势包括：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 提高查询性能：通过并行执行查询的不同部分，可以有效利用多个处理单元的计算资源，从而减少查询的总体执行时间。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 处理大规模数据：对于大型数据集，通过并行查询处理可以分摊数据处理的负载，更高效地处理大规模数据。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 并发执行：并行查询处理可以支持并发查询执行，多个查询可以同时进行，提高系统的并发性能和用户的响应时间。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，并行查询处理的实现和效果取决于具体的数据库系统和硬件架构。数据库系统需要具备适当的并行查询优化器和调度器，以及支持并行计算的硬件资源。同时，数据的划分、分布和访问模式也会影响并行查询处理的性能和效果。</span><br><span class=\"line\"></span><br><span class=\"line\">总结而言，并行查询处理是一种利用多个处理单元并行执行查询任务的技术，旨在提高查询的执行速度和系统的并发性能。它在大规模数据处理和高并发查询场景下具有重要的作用，可以显著提升数据库系统的效率和性能。</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"性能评估实验\"><a href=\"#性能评估实验\" class=\"headerlink\" title=\"性能评估实验\"></a>性能评估实验</h2><p>作者接下来使用 SQLite 和 DuckDB 来评估不同场景下的性能。首先使用了 TATP benchmark 来评估 OLTP 场景下的性能。由于 DuckDB 主要是设计满足 OLAP 场景下的需求，因此其吞吐量在实验中远远不及 SQLite 的吞吐量。在数据规模达到百万级别时，SQLite的在 Cloud server 上的TPS能达到 10k左右，比 DuckDB 高了几个数量级。接着又使用了 Star Schema Benchmark 来评估了 OLAP 场景下的性能。在这一场景下，DuckDB 展示了极佳的性能，在延迟上 比 SQLite 快了 10 倍到数十倍不等。</p>\n<p>为了理解这一性能差距，作者同时对 SQLite 的执行引擎做了profiling，分析得出主要是<code>SeekRowid</code>和<code>Column</code>操作耗费了大量时间。<code>SeekRowid</code>是为了在 B-tree 上找到对应 row id 的行，用来执行 join 操作；而 <code>Column</code>是为了提取给定记录的列值。基于这一结果，作者给出了两个关键的优化目标：避免不必要的 B-tree探测同时流化值提取过程。</p>\n<h3 id=\"避免不必要的-B-tree-探测\"><a href=\"#避免不必要的-B-tree-探测\" class=\"headerlink\" title=\"避免不必要的 B-tree 探测\"></a>避免不必要的 B-tree 探测</h3><p>SQLite 使用嵌套循环来实现 join 操作，内循环往往可以通过索引来加速。为了优化 join 操作的效率，作者通过布隆过滤器来实现 SQLite 的Lookahead Information Passing（LIP）。说白了其实就是通过布隆过滤器来加速 join 操作中对内表的检索操作，使用布隆过滤器后，实验观测到可最多十倍的性能提升。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在数据库领域中，Lookahead Information Passing（LIP）是一种查询优化技术，用于改善查询执行的效率和性能。</span><br><span class=\"line\"></span><br><span class=\"line\">在数据库查询优化过程中，查询优化器需要决定查询的执行计划，即确定查询中各个操作的执行顺序和方法。这涉及到选择合适的连接算法、访问方法、排序策略等，以便在给定的查询条件下，尽量高效地访问和处理数据。</span><br><span class=\"line\"></span><br><span class=\"line\">LIP技术在查询优化中的作用是提前获取和传递后续操作的信息，以辅助当前操作的执行计划选择。它基于对查询语句和数据库统计信息的分析，预测和收集后续操作的属性、选择性、数据分布等特征，并将这些信息传递给当前操作的优化过程。</span><br><span class=\"line\"></span><br><span class=\"line\">通过使用LIP技术，查询优化器可以更好地理解查询的整体语义和后续操作的特性，从而在制定执行计划时做出更准确的决策。例如，当优化器决定连接两个表时，LIP技术可以提供关于后续操作的信息，如后续操作中涉及的列、选择性、数据分布等，以便优化器选择最佳的连接算法和连接顺序。</span><br><span class=\"line\"></span><br><span class=\"line\">LIP技术在数据库查询优化中的应用有助于生成更高效的查询执行计划，从而提升查询的执行性能和效率。它可以减少不必要的计算和数据访问操作，优化查询的资源利用和数据处理方式，以适应特定的查询场景和优化目标。</span><br><span class=\"line\"></span><br><span class=\"line\">需要指出的是，LIP技术在数据库查询优化中可能涉及到多个方面，包括查询解析、查询重写、代价估算等。不同的数据库管理系统和查询优化器可能采用不同的LIP策略和实现方式，以适应特定的数据库架构和查询优化需求。</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"流化值提取过程\"><a href=\"#流化值提取过程\" class=\"headerlink\" title=\"流化值提取过程\"></a>流化值提取过程</h3><p>这部分逻辑相对应的会涉及到更具体的 SQLite 存储模式。SQLite record 由两部分组成：header 和 body。header 中存储了记录的类型码等元数据信息，body 中存储了记录的数据信息。为了提取值信息，SQLite 首先回到 head 里面找到一个指针，然后通过header 中的类型码遍历数据，直到找到对应的列。这种模式显然不适合 OLAP 场景下的流化数据提取。作者也尝试了其他方式去优化其数据提取过程，但是为了避免破坏 SQLite 在不同平台的稳定性，作者放弃了这部分优化。</p>\n<p>与此同时，作者又比较了BLOB 场景下的吞吐量，发现 SQLite 在 10KB 大小 blob 时吞吐量最佳，TPS 能够达到 9k 左右。随着 blob 的增大，其性能逐渐拉跨，甚至比不上文件系统的吞吐。这是由于 WAL 只允许 1000 个页，相当于大约 4MB 的大小限制，这带来了额外的写开销。</p>\n<p>作者同时比较了SQLite 和 DuckDB 的资源使用情况，比较有意思的点是 SQLite 在load 实验数据时虽然最终产生的数据库文件大约是 DuckDB 的两倍，但加载时间明显快于 DuckDB，作者没有详细解释这是为什么。</p>\n<p>在文章最后，作者提到了为什么没有对 SQLite 做 OLAP 场景下的优化，这是由于 SQLite 是一个通用型的数据引擎，为了保证不同场景下的性能和兼容性，不得不放弃一部分优化方式。然而，通过一些空间换时间的方式也能加速 OLAP 场景下的性能。通过向量化执行、数据压缩、运行时代码生成、和物化聚集等方式可以对一个传统的 OLTP 引擎进行 OLAP 场景下的优化，但是哪种方式能够最大化优化性能、哪些没有太大的优化价值，就需要这篇文章中的各类性能评估实验。这应该也是作者写这篇文章的动机。</p>\n<p>总的来说，这篇文章介绍了 SQLite 大致的历史沿革、系统架构和性能评估数据，虽然创新性上感觉稍显不足，但是比较扎实地进行了一系列实验比较，为 SQLite 的优化提供了比较好的参考数据。</p>"},{"title":"etcd 源码分析 - Raft 是如何实现的","_content":"","source":"_posts/interview/etcd 源码分析-raft.md","raw":"---\ntitle: etcd 源码分析 - Raft 是如何实现的\ntags:\n    - TBD\n---","slug":"interview/etcd 源码分析-raft","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iy000n1ts1eeilf9o2","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"你知道哪些数据结构？他们的时间复杂度和空间复杂度是多少？","_content":"\n这是一个经久不衰的题目，不管你是校招新人还是资深大牛，面试过程中都有可能被问到这个问题，这篇文章会梳理一下常见的数据结构和排序算法，以及相关操作的时间复杂度和空间复杂度。\n\n<!-- more -->\n\n这个问题要答出花样的话，只能展示一下你的博闻强记。正常来说讲一下数组、栈、队列、单链表、双链表、哈希表就差不多了，不过有些比较常用的数据结构，比如用在 redis 和 RocksDB里面的跳表，比如数据库里常用来组织数据的 B tree，聊到这些之后下一步也可以引申着聊一聊 redis 和 RocksDB 的源码实现，这部分会在以后的文章聊到。面试说到底是公司和候选人的互相匹配，在面试过程中候选人必须要尽量避免面试官过于发散地提问，这样才能够保证面试过程能够尽可能完整地展示候选人自己的知识积累。\n\n收敛面试范围有两种方式，一是要在简历上提到的项目必须是自己真实做过的项目（当然有些同学会包装一些自己没有做过的项目，不做评价），必须保证自己对简历上的项目足够熟悉，高级别的同学同时还需要对简历上涉及的项目在业界的同类方案也要有相当深入的了解。第二就是在面试过程中要学会引导面试官向一些特定的点提问，这一点也很重要。大多数人都不是维基百科，面试官发散的提问也是为了找到候选人比较熟悉和擅长的方向来深入挖掘，如果候选人能够自己积极主导这一过程，整个面试过程就能更加顺利。\n\n好了话不多说，下面就是一些常见的数据结构和排序算法的时间复杂度和空间复杂度。\n\n## 基本数据结构\n\n| 数据结构 | 时间复杂度 ||||||| | 空间复杂度 |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|      |  平均 ||| |  最优  ||||  最坏  |\n||访问|查找|插入|删除|访问|查找|插入|删除|||\n|  数组 | $\\Theta$(1) | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(n) | O(1) | O(n) | O(n) | O(n) | O(n) |\n| 栈    |$\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) | \n| 队列  | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) |\n| 单链表 | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) |\n| 双链表 | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) |\n| 跳表 |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(n) | O(n) | O(n) | O(n) | O(n log(n)) |\n| 哈希表| N/A | $\\Theta$(1) | $\\Theta$(1) | $\\Theta$(1) | N/A | O(n) | O(n) | O(n) | O(n) |\n| 二叉查找树 |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(n) | O(n) | O(n) | O(n) | O(n) |\n| 笛卡尔树 | N/A | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | N/A | O(n) | O(n) | O(n) | O(n) |\n| B树 | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| 红黑树|$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| 伸展树（Splay tree） | N/A | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | N/A | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| 自平衡二叉搜索树（AVL tree） |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| K-D树 |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(n) | O(n) | O(n) | O(n) | O(n) |\n\n```markdown\n学习笔记：\n1. 笛卡尔树（Cartesian Tree）是一种特殊的二叉树，它具有以下两个性质：\n    - 二叉搜索树性质：对于笛卡尔树中的每个节点，其左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。因此，笛卡尔树也是一个有效的二叉搜索树。\n    - 笛卡尔性质：对于笛卡尔树中的每个节点，其根节点在中序遍历中的位置对应于原始数据数组中对应元素的位置。换句话说，笛卡尔树的根节点对应于原始数组中最大（或最小）的元素，根节点的左子树对应于原始数组中根节点左边的部分，右子树对应于原始数组中根节点右边的部分。\n\n    笛卡尔树通常用于解决与序列相关的问题，如最大矩形面积、下一个更大元素等。通过构建笛卡尔树，可以在O(n)的时间复杂度内解决这些问题。\n\n    构建笛卡尔树的常用方法是使用单调栈。具体步骤如下：\n        1. 从左到右遍历原始数据数组。\n        2. 对于每个元素，将其作为新节点插入笛卡尔树中。\n            - 如果当前节点的值大于栈顶节点的值，将当前节点作为栈顶节点的右子节点，并将栈顶节点弹出栈，直到栈为空或当前节点的值小于栈顶节点的值。\n            - 如果当前节点的值小于栈顶节点的值，将当前节点作为栈顶节点的左子节点。\n        3. 将所有剩余的节点依次作为栈顶节点的右子节点，并弹出栈中的节点。\n    最终得到的树即为笛卡尔树。\n\n    笛卡尔树的特性使得它在某些问题上具有高效的解决方案，但并不是所有问题都适合使用笛卡尔树。在实际应用中，需要根据具体问题的特点和要求来选择合适的数据结构和算法。\n\n2. 伸展树（Splay Tree）是一种自平衡的二叉搜索树，它通过重新组织树的结构来优化频繁访问的节点，使得这些节点更接近根节点，从而提高查找、插入和删除操作的性能。\n\n    伸展树的主要特点是每次对节点的访问（查找、插入、删除）都会将被访问的节点旋转至根节点，这个过程称为\"伸展\"。通过伸展操作，伸展树会调整树的形状，使得最近被访问的节点移动到树的根部，以期望在之后的操作中更快地访问到这些节点。\n\n    伸展树的伸展操作通过一系列的旋转来改变树的结构。旋转操作包括\"左旋\"和\"右旋\"，通过交换节点的位置来调整树的平衡性。伸展树的伸展操作基于\"近似二叉树\"（Approximate Binary Tree）的思想，通过将节点向上移动，使得频繁访问的节点更靠近根节点，同时保持树的有序性。\n\n    伸展树的优点在于它适应了访问模式的变化，将频繁访问的节点放置在树的上层，从而减少了访问路径的长度，提高了操作的效率。另外，伸展树没有复杂的平衡因子或调整操作，相对于其他平衡二叉搜索树（如AVL树、红黑树），实现起来更加简单。\n\n    然而，伸展树的最坏情况时间复杂度为O(n)，其中n为树中的节点数，因为伸展操作可能导致树的高度线性增长。因此，在某些特定的访问模式下，伸展树的性能可能不如其他平衡二叉搜索树稳定。此外，伸展树的平均性能与操作的访问模式密切相关。\n\n    伸展树在实际应用中常用于缓存、动态搜索和频繁访问的数据结构等场景，但需要根据具体情况评估其适用性，并注意控制树的深度，避免退化为链表。\n\n3. 自平衡二叉搜索树（Self-Balancing Binary Search Tree）是一种二叉搜索树，在插入和删除操作后可以自动调整树的结构，以保持树的平衡性，从而提供较为稳定的性能。\n\n    二叉搜索树是一种有序的二叉树，其中每个节点的左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。它的主要优点是在具有良好平衡性的情况下，查找、插入和删除等操作的平均时间复杂度为O(log n)，其中n为树中节点的数量。\n\n    然而，普通的二叉搜索树在频繁的插入和删除操作后，可能会出现不平衡的情况，导致树的高度增加，进而降低了性能。为了解决这个问题，自平衡二叉搜索树引入了各种自平衡的算法和数据结构，以在操作后保持树的平衡。\n\n    常见的自平衡二叉搜索树包括：\n\n    1. AVL树：通过旋转操作来保持树的平衡，确保左子树和右子树的高度差不超过1。\n    2. 红黑树：使用颜色标记和旋转操作来保持树的平衡，保证树的高度近似平衡，并满足一些附加条件。\n    3. B树和B+树：多路搜索树，通过调整节点的数量来保持树的平衡，适用于大规模数据存储和检索场景。\n    4. Splay树：通过伸展操作将访问的节点移动到根节点，实现最近访问的节点更容易访问到，提高访问性能。\n\n    这些自平衡二叉搜索树的具体实现方式和调整策略有所不同，但它们的共同目标是通过动态调整树的结构，使得树的高度保持较小，从而提供较高的性能和效率。\n\n    根据具体应用场景和需求，选择合适的自平衡二叉搜索树可以提供更稳定和高效的数据存储和检索能力。\n\n4. KD树（K-Dimensional Tree）是一种用于对k维空间中的点集进行分割和组织的数据结构。它是二叉搜索树的一种扩展形式，用于支持高维数据的快速搜索和近邻查找。\n\n    在KD树中，每个节点代表k维空间中的一个点，并根据该点的坐标进行分割。具体来说，树的每一层根据一个维度（坐标轴）选择一个切分超平面，将空间划分为两个子空间。左子树表示切分超平面左侧的子空间，右子树表示切分超平面右侧的子空间。\n\n    构建KD树的过程如下：\n\n        1. 选择切分维度：从k个维度中选择一个维度作为当前层的切分维度。\n        2. 选择切分值：在选定的切分维度上选择一个值作为切分超平面。\n        3. 划分子空间：将当前层的点集根据切分超平面分割为左右两个子空间，并将点集中小于等于切分值的点放入左子树，大于切分值的点放入右子树。\n        4. 递归构建子树：对左右子空间递归执行以上步骤，构建子树。\n\n    构建完成后，KD树可以提供以下常见操作：\n\n        - 搜索：根据给定的查询点，在KD树中进行搜索，找到最近的点或满足某种条件的点。\n        - 插入：向KD树中插入一个新的点。\n        - 删除：从KD树中删除一个指定的点。\n\n    KD树在高维数据集中可以高效地进行搜索和近邻查找，因为它可以根据数据在不同维度上的切分进行快速剪枝和定位。然而，在数据维度非常高时，KD树的效率可能会下降，这时可以考虑其他数据结构或使用降维等方法来处理高维数据。\n```\n\n## 排序算法\n\n聊完数据结构，基本上都会聊一聊排序算法了，说起来其实挺羞耻的，我只会写个快排，我自己的经验是面试基本不会考这个，考的话最多也只会写个快排。不过技多不压身，多看看总没有坏处。\n\n| 排序算法 | 时间复杂度 | | | 空间复杂度 |\n| :--: | :--: | :--: | :--: | :--: |\n| 快速排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n^2) | O(log(n)) |\n| 归并排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n log(n)) | O(n) |\n| 归并插入排序 | $\\Omega$(n) | $\\Theta$(n log(n)) | O(n log(n)) | O(n) |\n| 堆排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n log(n)) | O(1) |\n| 冒泡排序 | $\\Omega$(n) | $\\Theta$(n^2) | O(n^2) | O(1) |\n| 插入排序 | $\\Omega$(n) | $\\Theta$(n^2) | O(n^2) | O(1) |\n| 选择排序 | $\\Omega$(n^2) | $\\Theta$(n^2) | O(n^2) | O(1) |\n| 树排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n^2) | O(n) |\n| 希尔排序 | $\\Omega$(n log(n)) | $\\Theta$(n(log(n))^2) | O(n(log(n))^2) | O(1) |\n| 桶排序 | $\\Omega$(n+k) | $\\Theta$(n+k) | O(n^2) | O(n) |\n| 基数排序 | $\\Omega$(nk) | $\\Theta$(nk) | O(nk) | O(n+k) |\n| 计数排序 | $\\Omega$(n+k) | $\\Theta$(n+k) | O(n+k) | O(k) |\n| 立方体排序 | $\\Omega$(n) | $\\Theta$(n log(n)) | O(n log(n)) | O(n) |\n\n```markdown\n1. 归并插入排序（Merge Insertion Sort）是一种结合了归并排序和插入排序思想的排序算法。它利用了归并排序在处理大规模数据时的高效性能，同时又利用了插入排序在小规模数据上的优势。\n\n    归并插入排序的基本思想是：对于待排序的数组，首先将数组分割成较小的子数组，然后对每个子数组使用插入排序进行排序，最后再使用归并操作将子数组合并成一个有序的数组。\n\n    具体步骤如下：\n\n        1. 初始状态下，将待排序数组分割成多个较小的子数组（通常是递归地将数组分成两半）。\n        2. 对每个子数组应用插入排序算法进行排序。当子数组的长度小于等于一定阈值时，切换到插入排序算法。\n        3. 合并操作：通过不断合并相邻的有序子数组，将子数组合并成一个有序的数组。这一过程类似于归并排序中的合并操作。\n\n    归并插入排序的关键在于确定合适的子数组大小，通常当子数组的长度小于一定阈值时，切换到插入排序算法。因为插入排序对于小规模数据具有较好的性能，而归并排序在大规模数据上具有较好的性能。通过合理划分子数组大小，可以在排序过程中充分利用两种排序算法的优势。\n\n    归并插入排序算法的时间复杂度为O(n log n)，其中n为待排序数组的长度。由于归并排序和插入排序的时间复杂度都是O(n log n)和O(n^2)级别，归并插入排序在实际应用中的性能与具体实现和问题规模有关。它适用于各种数据分布情况下的排序需求，并且在实践中往往能够提供较好的性能和稳定性。\n\n2. 桶排序（Bucket Sort）是一种排序算法，它将待排序的元素分到不同的桶（或称为容器）中，然后对每个桶中的元素分别进行排序，最后将各个桶中的元素按顺序合并得到有序的结果。\n\n    桶排序的基本思想是将待排序的元素均匀地分布到若干个桶中，每个桶内部使用一个较快的排序算法（如插入排序、快速排序等）对元素进行排序。具体的步骤如下：\n\n        1. 确定桶的数量和范围：根据待排序元素的分布情况，确定桶的数量，可以是固定的数量，也可以根据元素的范围动态确定。\n        2. 将元素分配到桶中：遍历待排序的元素，根据元素的值将其分配到相应的桶中。\n        3. 对每个桶中的元素进行排序：对每个桶内部的元素使用一个较快的排序算法进行排序，可以选择插入排序、快速排序等。\n        4. 合并桶中的元素：按照桶的顺序，将每个桶中的元素按顺序合并成一个有序的结果数组。\n\n    桶排序的时间复杂度取决于分配到桶中的元素的分布情况，以及每个桶内部排序算法的选择。在最理想的情况下，当元素均匀分布在不同的桶中，并且每个桶内部的排序时间复杂度为O(nlogn)时，桶排序的时间复杂度可以达到O(n)。然而，在某些情况下，如果元素分布不均匀，可能会导致较大的空间复杂度或较长的排序时间。\n\n    桶排序适用于待排序元素分布较均匀的情况，尤其适合外部排序，即待排序元素无法全部加载到内存中。在实践中，可以根据具体应用场景和数据特点选择合适的桶排序算法的实现方式和参数设置。\n\n3. 立方体排序（Cube Sort），也称为三维排序或多关键字排序，是一种用于对具有多个关键字的记录进行排序的算法。它在三维空间中对记录进行排序，每个记录具有三个关键字，分别对应三个维度。\n\n    立方体排序的基本思想是通过多次应用稳定的排序算法，先按照一个维度对记录进行排序，然后按照另一个维度对已排序的记录进行排序，依此类推，直到所有关键字都按照指定顺序排列为止。可以类比为将记录组成一个立方体，按照某个维度逐层进行切割和排序。\n\n    具体步骤如下：\n\n        1. 确定排序顺序：确定按照哪个维度的关键字先进行排序，然后依次确定其他维度的排序顺序。\n        2. 应用稳定的排序算法：按照确定的顺序依次对记录进行稳定的排序，通常使用的排序算法有插入排序、冒泡排序、归并排序等。\n        3. 重复步骤2：对已排序的记录再次按照下一个维度的关键字进行排序，直到所有关键字都按照指定顺序排列。\n\n    立方体排序的时间复杂度取决于所使用的稳定排序算法的复杂度和记录的数量。如果记录的数量为n，每个维度的排序所使用的算法复杂度为O(f(n))，那么立方体排序的总时间复杂度为O(d * f(n))，其中d为关键字的维度。\n\n    立方体排序适用于多关键字排序的情况，特别适合于具有三个或更多关键字的记录的排序。它可以保持记录之间的相对顺序，并根据每个关键字的重要性进行排序。然而，立方体排序在维度较高和记录数量较大时，可能会面临性能和空间上的挑战。在实际应用中，可以根据具体情况选择合适的排序算法和优化策略。\n```\n\n## Reference\n\n1. [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)\n2. [Splay tree](https://en.wikipedia.org/wiki/Splay_tree)\n3. [K-d tree](https://en.wikipedia.org/wiki/K-d_tree)\n4. [ChatGPT](https://chat.openai.com)","source":"_posts/interview/常见数据结构的时间复杂度和空间复杂度.md","raw":"---\ntitle: 你知道哪些数据结构？他们的时间复杂度和空间复杂度是多少？\ntags:\n    - 技术杂谈\n---\n\n这是一个经久不衰的题目，不管你是校招新人还是资深大牛，面试过程中都有可能被问到这个问题，这篇文章会梳理一下常见的数据结构和排序算法，以及相关操作的时间复杂度和空间复杂度。\n\n<!-- more -->\n\n这个问题要答出花样的话，只能展示一下你的博闻强记。正常来说讲一下数组、栈、队列、单链表、双链表、哈希表就差不多了，不过有些比较常用的数据结构，比如用在 redis 和 RocksDB里面的跳表，比如数据库里常用来组织数据的 B tree，聊到这些之后下一步也可以引申着聊一聊 redis 和 RocksDB 的源码实现，这部分会在以后的文章聊到。面试说到底是公司和候选人的互相匹配，在面试过程中候选人必须要尽量避免面试官过于发散地提问，这样才能够保证面试过程能够尽可能完整地展示候选人自己的知识积累。\n\n收敛面试范围有两种方式，一是要在简历上提到的项目必须是自己真实做过的项目（当然有些同学会包装一些自己没有做过的项目，不做评价），必须保证自己对简历上的项目足够熟悉，高级别的同学同时还需要对简历上涉及的项目在业界的同类方案也要有相当深入的了解。第二就是在面试过程中要学会引导面试官向一些特定的点提问，这一点也很重要。大多数人都不是维基百科，面试官发散的提问也是为了找到候选人比较熟悉和擅长的方向来深入挖掘，如果候选人能够自己积极主导这一过程，整个面试过程就能更加顺利。\n\n好了话不多说，下面就是一些常见的数据结构和排序算法的时间复杂度和空间复杂度。\n\n## 基本数据结构\n\n| 数据结构 | 时间复杂度 ||||||| | 空间复杂度 |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|      |  平均 ||| |  最优  ||||  最坏  |\n||访问|查找|插入|删除|访问|查找|插入|删除|||\n|  数组 | $\\Theta$(1) | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(n) | O(1) | O(n) | O(n) | O(n) | O(n) |\n| 栈    |$\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) | \n| 队列  | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) |\n| 单链表 | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) |\n| 双链表 | $\\Theta$(n) | $\\Theta$(n) | $\\Theta$(1) | $\\Theta$(1) | O(n) | O(n) | O(1) | O(1) | O(n) |\n| 跳表 |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(n) | O(n) | O(n) | O(n) | O(n log(n)) |\n| 哈希表| N/A | $\\Theta$(1) | $\\Theta$(1) | $\\Theta$(1) | N/A | O(n) | O(n) | O(n) | O(n) |\n| 二叉查找树 |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(n) | O(n) | O(n) | O(n) | O(n) |\n| 笛卡尔树 | N/A | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | N/A | O(n) | O(n) | O(n) | O(n) |\n| B树 | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| 红黑树|$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| 伸展树（Splay tree） | N/A | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | N/A | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| 自平衡二叉搜索树（AVL tree） |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(log(n)) | O(n) |\n| K-D树 |$\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | $\\Theta$(log(n)) | O(n) | O(n) | O(n) | O(n) | O(n) |\n\n```markdown\n学习笔记：\n1. 笛卡尔树（Cartesian Tree）是一种特殊的二叉树，它具有以下两个性质：\n    - 二叉搜索树性质：对于笛卡尔树中的每个节点，其左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。因此，笛卡尔树也是一个有效的二叉搜索树。\n    - 笛卡尔性质：对于笛卡尔树中的每个节点，其根节点在中序遍历中的位置对应于原始数据数组中对应元素的位置。换句话说，笛卡尔树的根节点对应于原始数组中最大（或最小）的元素，根节点的左子树对应于原始数组中根节点左边的部分，右子树对应于原始数组中根节点右边的部分。\n\n    笛卡尔树通常用于解决与序列相关的问题，如最大矩形面积、下一个更大元素等。通过构建笛卡尔树，可以在O(n)的时间复杂度内解决这些问题。\n\n    构建笛卡尔树的常用方法是使用单调栈。具体步骤如下：\n        1. 从左到右遍历原始数据数组。\n        2. 对于每个元素，将其作为新节点插入笛卡尔树中。\n            - 如果当前节点的值大于栈顶节点的值，将当前节点作为栈顶节点的右子节点，并将栈顶节点弹出栈，直到栈为空或当前节点的值小于栈顶节点的值。\n            - 如果当前节点的值小于栈顶节点的值，将当前节点作为栈顶节点的左子节点。\n        3. 将所有剩余的节点依次作为栈顶节点的右子节点，并弹出栈中的节点。\n    最终得到的树即为笛卡尔树。\n\n    笛卡尔树的特性使得它在某些问题上具有高效的解决方案，但并不是所有问题都适合使用笛卡尔树。在实际应用中，需要根据具体问题的特点和要求来选择合适的数据结构和算法。\n\n2. 伸展树（Splay Tree）是一种自平衡的二叉搜索树，它通过重新组织树的结构来优化频繁访问的节点，使得这些节点更接近根节点，从而提高查找、插入和删除操作的性能。\n\n    伸展树的主要特点是每次对节点的访问（查找、插入、删除）都会将被访问的节点旋转至根节点，这个过程称为\"伸展\"。通过伸展操作，伸展树会调整树的形状，使得最近被访问的节点移动到树的根部，以期望在之后的操作中更快地访问到这些节点。\n\n    伸展树的伸展操作通过一系列的旋转来改变树的结构。旋转操作包括\"左旋\"和\"右旋\"，通过交换节点的位置来调整树的平衡性。伸展树的伸展操作基于\"近似二叉树\"（Approximate Binary Tree）的思想，通过将节点向上移动，使得频繁访问的节点更靠近根节点，同时保持树的有序性。\n\n    伸展树的优点在于它适应了访问模式的变化，将频繁访问的节点放置在树的上层，从而减少了访问路径的长度，提高了操作的效率。另外，伸展树没有复杂的平衡因子或调整操作，相对于其他平衡二叉搜索树（如AVL树、红黑树），实现起来更加简单。\n\n    然而，伸展树的最坏情况时间复杂度为O(n)，其中n为树中的节点数，因为伸展操作可能导致树的高度线性增长。因此，在某些特定的访问模式下，伸展树的性能可能不如其他平衡二叉搜索树稳定。此外，伸展树的平均性能与操作的访问模式密切相关。\n\n    伸展树在实际应用中常用于缓存、动态搜索和频繁访问的数据结构等场景，但需要根据具体情况评估其适用性，并注意控制树的深度，避免退化为链表。\n\n3. 自平衡二叉搜索树（Self-Balancing Binary Search Tree）是一种二叉搜索树，在插入和删除操作后可以自动调整树的结构，以保持树的平衡性，从而提供较为稳定的性能。\n\n    二叉搜索树是一种有序的二叉树，其中每个节点的左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。它的主要优点是在具有良好平衡性的情况下，查找、插入和删除等操作的平均时间复杂度为O(log n)，其中n为树中节点的数量。\n\n    然而，普通的二叉搜索树在频繁的插入和删除操作后，可能会出现不平衡的情况，导致树的高度增加，进而降低了性能。为了解决这个问题，自平衡二叉搜索树引入了各种自平衡的算法和数据结构，以在操作后保持树的平衡。\n\n    常见的自平衡二叉搜索树包括：\n\n    1. AVL树：通过旋转操作来保持树的平衡，确保左子树和右子树的高度差不超过1。\n    2. 红黑树：使用颜色标记和旋转操作来保持树的平衡，保证树的高度近似平衡，并满足一些附加条件。\n    3. B树和B+树：多路搜索树，通过调整节点的数量来保持树的平衡，适用于大规模数据存储和检索场景。\n    4. Splay树：通过伸展操作将访问的节点移动到根节点，实现最近访问的节点更容易访问到，提高访问性能。\n\n    这些自平衡二叉搜索树的具体实现方式和调整策略有所不同，但它们的共同目标是通过动态调整树的结构，使得树的高度保持较小，从而提供较高的性能和效率。\n\n    根据具体应用场景和需求，选择合适的自平衡二叉搜索树可以提供更稳定和高效的数据存储和检索能力。\n\n4. KD树（K-Dimensional Tree）是一种用于对k维空间中的点集进行分割和组织的数据结构。它是二叉搜索树的一种扩展形式，用于支持高维数据的快速搜索和近邻查找。\n\n    在KD树中，每个节点代表k维空间中的一个点，并根据该点的坐标进行分割。具体来说，树的每一层根据一个维度（坐标轴）选择一个切分超平面，将空间划分为两个子空间。左子树表示切分超平面左侧的子空间，右子树表示切分超平面右侧的子空间。\n\n    构建KD树的过程如下：\n\n        1. 选择切分维度：从k个维度中选择一个维度作为当前层的切分维度。\n        2. 选择切分值：在选定的切分维度上选择一个值作为切分超平面。\n        3. 划分子空间：将当前层的点集根据切分超平面分割为左右两个子空间，并将点集中小于等于切分值的点放入左子树，大于切分值的点放入右子树。\n        4. 递归构建子树：对左右子空间递归执行以上步骤，构建子树。\n\n    构建完成后，KD树可以提供以下常见操作：\n\n        - 搜索：根据给定的查询点，在KD树中进行搜索，找到最近的点或满足某种条件的点。\n        - 插入：向KD树中插入一个新的点。\n        - 删除：从KD树中删除一个指定的点。\n\n    KD树在高维数据集中可以高效地进行搜索和近邻查找，因为它可以根据数据在不同维度上的切分进行快速剪枝和定位。然而，在数据维度非常高时，KD树的效率可能会下降，这时可以考虑其他数据结构或使用降维等方法来处理高维数据。\n```\n\n## 排序算法\n\n聊完数据结构，基本上都会聊一聊排序算法了，说起来其实挺羞耻的，我只会写个快排，我自己的经验是面试基本不会考这个，考的话最多也只会写个快排。不过技多不压身，多看看总没有坏处。\n\n| 排序算法 | 时间复杂度 | | | 空间复杂度 |\n| :--: | :--: | :--: | :--: | :--: |\n| 快速排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n^2) | O(log(n)) |\n| 归并排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n log(n)) | O(n) |\n| 归并插入排序 | $\\Omega$(n) | $\\Theta$(n log(n)) | O(n log(n)) | O(n) |\n| 堆排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n log(n)) | O(1) |\n| 冒泡排序 | $\\Omega$(n) | $\\Theta$(n^2) | O(n^2) | O(1) |\n| 插入排序 | $\\Omega$(n) | $\\Theta$(n^2) | O(n^2) | O(1) |\n| 选择排序 | $\\Omega$(n^2) | $\\Theta$(n^2) | O(n^2) | O(1) |\n| 树排序 | $\\Omega$(n log(n)) | $\\Theta$(n log(n)) | O(n^2) | O(n) |\n| 希尔排序 | $\\Omega$(n log(n)) | $\\Theta$(n(log(n))^2) | O(n(log(n))^2) | O(1) |\n| 桶排序 | $\\Omega$(n+k) | $\\Theta$(n+k) | O(n^2) | O(n) |\n| 基数排序 | $\\Omega$(nk) | $\\Theta$(nk) | O(nk) | O(n+k) |\n| 计数排序 | $\\Omega$(n+k) | $\\Theta$(n+k) | O(n+k) | O(k) |\n| 立方体排序 | $\\Omega$(n) | $\\Theta$(n log(n)) | O(n log(n)) | O(n) |\n\n```markdown\n1. 归并插入排序（Merge Insertion Sort）是一种结合了归并排序和插入排序思想的排序算法。它利用了归并排序在处理大规模数据时的高效性能，同时又利用了插入排序在小规模数据上的优势。\n\n    归并插入排序的基本思想是：对于待排序的数组，首先将数组分割成较小的子数组，然后对每个子数组使用插入排序进行排序，最后再使用归并操作将子数组合并成一个有序的数组。\n\n    具体步骤如下：\n\n        1. 初始状态下，将待排序数组分割成多个较小的子数组（通常是递归地将数组分成两半）。\n        2. 对每个子数组应用插入排序算法进行排序。当子数组的长度小于等于一定阈值时，切换到插入排序算法。\n        3. 合并操作：通过不断合并相邻的有序子数组，将子数组合并成一个有序的数组。这一过程类似于归并排序中的合并操作。\n\n    归并插入排序的关键在于确定合适的子数组大小，通常当子数组的长度小于一定阈值时，切换到插入排序算法。因为插入排序对于小规模数据具有较好的性能，而归并排序在大规模数据上具有较好的性能。通过合理划分子数组大小，可以在排序过程中充分利用两种排序算法的优势。\n\n    归并插入排序算法的时间复杂度为O(n log n)，其中n为待排序数组的长度。由于归并排序和插入排序的时间复杂度都是O(n log n)和O(n^2)级别，归并插入排序在实际应用中的性能与具体实现和问题规模有关。它适用于各种数据分布情况下的排序需求，并且在实践中往往能够提供较好的性能和稳定性。\n\n2. 桶排序（Bucket Sort）是一种排序算法，它将待排序的元素分到不同的桶（或称为容器）中，然后对每个桶中的元素分别进行排序，最后将各个桶中的元素按顺序合并得到有序的结果。\n\n    桶排序的基本思想是将待排序的元素均匀地分布到若干个桶中，每个桶内部使用一个较快的排序算法（如插入排序、快速排序等）对元素进行排序。具体的步骤如下：\n\n        1. 确定桶的数量和范围：根据待排序元素的分布情况，确定桶的数量，可以是固定的数量，也可以根据元素的范围动态确定。\n        2. 将元素分配到桶中：遍历待排序的元素，根据元素的值将其分配到相应的桶中。\n        3. 对每个桶中的元素进行排序：对每个桶内部的元素使用一个较快的排序算法进行排序，可以选择插入排序、快速排序等。\n        4. 合并桶中的元素：按照桶的顺序，将每个桶中的元素按顺序合并成一个有序的结果数组。\n\n    桶排序的时间复杂度取决于分配到桶中的元素的分布情况，以及每个桶内部排序算法的选择。在最理想的情况下，当元素均匀分布在不同的桶中，并且每个桶内部的排序时间复杂度为O(nlogn)时，桶排序的时间复杂度可以达到O(n)。然而，在某些情况下，如果元素分布不均匀，可能会导致较大的空间复杂度或较长的排序时间。\n\n    桶排序适用于待排序元素分布较均匀的情况，尤其适合外部排序，即待排序元素无法全部加载到内存中。在实践中，可以根据具体应用场景和数据特点选择合适的桶排序算法的实现方式和参数设置。\n\n3. 立方体排序（Cube Sort），也称为三维排序或多关键字排序，是一种用于对具有多个关键字的记录进行排序的算法。它在三维空间中对记录进行排序，每个记录具有三个关键字，分别对应三个维度。\n\n    立方体排序的基本思想是通过多次应用稳定的排序算法，先按照一个维度对记录进行排序，然后按照另一个维度对已排序的记录进行排序，依此类推，直到所有关键字都按照指定顺序排列为止。可以类比为将记录组成一个立方体，按照某个维度逐层进行切割和排序。\n\n    具体步骤如下：\n\n        1. 确定排序顺序：确定按照哪个维度的关键字先进行排序，然后依次确定其他维度的排序顺序。\n        2. 应用稳定的排序算法：按照确定的顺序依次对记录进行稳定的排序，通常使用的排序算法有插入排序、冒泡排序、归并排序等。\n        3. 重复步骤2：对已排序的记录再次按照下一个维度的关键字进行排序，直到所有关键字都按照指定顺序排列。\n\n    立方体排序的时间复杂度取决于所使用的稳定排序算法的复杂度和记录的数量。如果记录的数量为n，每个维度的排序所使用的算法复杂度为O(f(n))，那么立方体排序的总时间复杂度为O(d * f(n))，其中d为关键字的维度。\n\n    立方体排序适用于多关键字排序的情况，特别适合于具有三个或更多关键字的记录的排序。它可以保持记录之间的相对顺序，并根据每个关键字的重要性进行排序。然而，立方体排序在维度较高和记录数量较大时，可能会面临性能和空间上的挑战。在实际应用中，可以根据具体情况选择合适的排序算法和优化策略。\n```\n\n## Reference\n\n1. [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)\n2. [Splay tree](https://en.wikipedia.org/wiki/Splay_tree)\n3. [K-d tree](https://en.wikipedia.org/wiki/K-d_tree)\n4. [ChatGPT](https://chat.openai.com)","slug":"interview/常见数据结构的时间复杂度和空间复杂度","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iz000o1ts10a8ycke3","content":"<p>这是一个经久不衰的题目，不管你是校招新人还是资深大牛，面试过程中都有可能被问到这个问题，这篇文章会梳理一下常见的数据结构和排序算法，以及相关操作的时间复杂度和空间复杂度。</p>\n<span id=\"more\"></span>\n\n<p>这个问题要答出花样的话，只能展示一下你的博闻强记。正常来说讲一下数组、栈、队列、单链表、双链表、哈希表就差不多了，不过有些比较常用的数据结构，比如用在 redis 和 RocksDB里面的跳表，比如数据库里常用来组织数据的 B tree，聊到这些之后下一步也可以引申着聊一聊 redis 和 RocksDB 的源码实现，这部分会在以后的文章聊到。面试说到底是公司和候选人的互相匹配，在面试过程中候选人必须要尽量避免面试官过于发散地提问，这样才能够保证面试过程能够尽可能完整地展示候选人自己的知识积累。</p>\n<p>收敛面试范围有两种方式，一是要在简历上提到的项目必须是自己真实做过的项目（当然有些同学会包装一些自己没有做过的项目，不做评价），必须保证自己对简历上的项目足够熟悉，高级别的同学同时还需要对简历上涉及的项目在业界的同类方案也要有相当深入的了解。第二就是在面试过程中要学会引导面试官向一些特定的点提问，这一点也很重要。大多数人都不是维基百科，面试官发散的提问也是为了找到候选人比较熟悉和擅长的方向来深入挖掘，如果候选人能够自己积极主导这一过程，整个面试过程就能更加顺利。</p>\n<p>好了话不多说，下面就是一些常见的数据结构和排序算法的时间复杂度和空间复杂度。</p>\n<h2 id=\"基本数据结构\"><a href=\"#基本数据结构\" class=\"headerlink\" title=\"基本数据结构\"></a>基本数据结构</h2><table>\n<thead>\n<tr>\n<th align=\"center\">数据结构</th>\n<th align=\"center\">时间复杂度</th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\">空间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\"></td>\n<td align=\"center\">平均</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\">最优</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\">最坏</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">访问</td>\n<td align=\"center\">查找</td>\n<td align=\"center\">插入</td>\n<td align=\"center\">删除</td>\n<td align=\"center\">访问</td>\n<td align=\"center\">查找</td>\n<td align=\"center\">插入</td>\n<td align=\"center\">删除</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\">数组</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">栈</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">队列</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">单链表</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">双链表</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">跳表</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n log(n))</td>\n</tr>\n<tr>\n<td align=\"center\">哈希表</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">二叉查找树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">笛卡尔树</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">B树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">红黑树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">伸展树（Splay tree）</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">自平衡二叉搜索树（AVL tree）</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">K-D树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">学习笔记：</span><br><span class=\"line\"><span class=\"bullet\">1.</span> 笛卡尔树（Cartesian Tree）是一种特殊的二叉树，它具有以下两个性质：</span><br><span class=\"line\"><span class=\"bullet\">    -</span> 二叉搜索树性质：对于笛卡尔树中的每个节点，其左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。因此，笛卡尔树也是一个有效的二叉搜索树。</span><br><span class=\"line\"><span class=\"bullet\">    -</span> 笛卡尔性质：对于笛卡尔树中的每个节点，其根节点在中序遍历中的位置对应于原始数据数组中对应元素的位置。换句话说，笛卡尔树的根节点对应于原始数组中最大（或最小）的元素，根节点的左子树对应于原始数组中根节点左边的部分，右子树对应于原始数组中根节点右边的部分。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    笛卡尔树通常用于解决与序列相关的问题，如最大矩形面积、下一个更大元素等。通过构建笛卡尔树，可以在O(n)的时间复杂度内解决这些问题。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    构建笛卡尔树的常用方法是使用单调栈。具体步骤如下：</span></span><br><span class=\"line\"><span class=\"code\">        1. 从左到右遍历原始数据数组。</span></span><br><span class=\"line\"><span class=\"code\">        2. 对于每个元素，将其作为新节点插入笛卡尔树中。</span></span><br><span class=\"line\"><span class=\"code\">            - 如果当前节点的值大于栈顶节点的值，将当前节点作为栈顶节点的右子节点，并将栈顶节点弹出栈，直到栈为空或当前节点的值小于栈顶节点的值。</span></span><br><span class=\"line\"><span class=\"code\">            - 如果当前节点的值小于栈顶节点的值，将当前节点作为栈顶节点的左子节点。</span></span><br><span class=\"line\"><span class=\"code\">        3. 将所有剩余的节点依次作为栈顶节点的右子节点，并弹出栈中的节点。</span></span><br><span class=\"line\"><span class=\"code\">    最终得到的树即为笛卡尔树。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    笛卡尔树的特性使得它在某些问题上具有高效的解决方案，但并不是所有问题都适合使用笛卡尔树。在实际应用中，需要根据具体问题的特点和要求来选择合适的数据结构和算法。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 伸展树（Splay Tree）是一种自平衡的二叉搜索树，它通过重新组织树的结构来优化频繁访问的节点，使得这些节点更接近根节点，从而提高查找、插入和删除操作的性能。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    伸展树的主要特点是每次对节点的访问（查找、插入、删除）都会将被访问的节点旋转至根节点，这个过程称为&quot;伸展&quot;。通过伸展操作，伸展树会调整树的形状，使得最近被访问的节点移动到树的根部，以期望在之后的操作中更快地访问到这些节点。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    伸展树的伸展操作通过一系列的旋转来改变树的结构。旋转操作包括&quot;左旋&quot;和&quot;右旋&quot;，通过交换节点的位置来调整树的平衡性。伸展树的伸展操作基于&quot;近似二叉树&quot;（Approximate Binary Tree）的思想，通过将节点向上移动，使得频繁访问的节点更靠近根节点，同时保持树的有序性。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    伸展树的优点在于它适应了访问模式的变化，将频繁访问的节点放置在树的上层，从而减少了访问路径的长度，提高了操作的效率。另外，伸展树没有复杂的平衡因子或调整操作，相对于其他平衡二叉搜索树（如AVL树、红黑树），实现起来更加简单。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    然而，伸展树的最坏情况时间复杂度为O(n)，其中n为树中的节点数，因为伸展操作可能导致树的高度线性增长。因此，在某些特定的访问模式下，伸展树的性能可能不如其他平衡二叉搜索树稳定。此外，伸展树的平均性能与操作的访问模式密切相关。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    伸展树在实际应用中常用于缓存、动态搜索和频繁访问的数据结构等场景，但需要根据具体情况评估其适用性，并注意控制树的深度，避免退化为链表。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 自平衡二叉搜索树（Self-Balancing Binary Search Tree）是一种二叉搜索树，在插入和删除操作后可以自动调整树的结构，以保持树的平衡性，从而提供较为稳定的性能。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    二叉搜索树是一种有序的二叉树，其中每个节点的左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。它的主要优点是在具有良好平衡性的情况下，查找、插入和删除等操作的平均时间复杂度为O(log n)，其中n为树中节点的数量。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    然而，普通的二叉搜索树在频繁的插入和删除操作后，可能会出现不平衡的情况，导致树的高度增加，进而降低了性能。为了解决这个问题，自平衡二叉搜索树引入了各种自平衡的算法和数据结构，以在操作后保持树的平衡。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    常见的自平衡二叉搜索树包括：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">    1.</span> AVL树：通过旋转操作来保持树的平衡，确保左子树和右子树的高度差不超过1。</span><br><span class=\"line\"><span class=\"bullet\">    2.</span> 红黑树：使用颜色标记和旋转操作来保持树的平衡，保证树的高度近似平衡，并满足一些附加条件。</span><br><span class=\"line\"><span class=\"bullet\">    3.</span> B树和B+树：多路搜索树，通过调整节点的数量来保持树的平衡，适用于大规模数据存储和检索场景。</span><br><span class=\"line\"><span class=\"bullet\">    4.</span> Splay树：通过伸展操作将访问的节点移动到根节点，实现最近访问的节点更容易访问到，提高访问性能。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    这些自平衡二叉搜索树的具体实现方式和调整策略有所不同，但它们的共同目标是通过动态调整树的结构，使得树的高度保持较小，从而提供较高的性能和效率。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    根据具体应用场景和需求，选择合适的自平衡二叉搜索树可以提供更稳定和高效的数据存储和检索能力。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">4.</span> KD树（K-Dimensional Tree）是一种用于对k维空间中的点集进行分割和组织的数据结构。它是二叉搜索树的一种扩展形式，用于支持高维数据的快速搜索和近邻查找。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    在KD树中，每个节点代表k维空间中的一个点，并根据该点的坐标进行分割。具体来说，树的每一层根据一个维度（坐标轴）选择一个切分超平面，将空间划分为两个子空间。左子树表示切分超平面左侧的子空间，右子树表示切分超平面右侧的子空间。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    构建KD树的过程如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 选择切分维度：从k个维度中选择一个维度作为当前层的切分维度。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 选择切分值：在选定的切分维度上选择一个值作为切分超平面。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 划分子空间：将当前层的点集根据切分超平面分割为左右两个子空间，并将点集中小于等于切分值的点放入左子树，大于切分值的点放入右子树。</span><br><span class=\"line\"><span class=\"bullet\">        4.</span> 递归构建子树：对左右子空间递归执行以上步骤，构建子树。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    构建完成后，KD树可以提供以下常见操作：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        -</span> 搜索：根据给定的查询点，在KD树中进行搜索，找到最近的点或满足某种条件的点。</span><br><span class=\"line\"><span class=\"bullet\">        -</span> 插入：向KD树中插入一个新的点。</span><br><span class=\"line\"><span class=\"bullet\">        -</span> 删除：从KD树中删除一个指定的点。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    KD树在高维数据集中可以高效地进行搜索和近邻查找，因为它可以根据数据在不同维度上的切分进行快速剪枝和定位。然而，在数据维度非常高时，KD树的效率可能会下降，这时可以考虑其他数据结构或使用降维等方法来处理高维数据。</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"排序算法\"><a href=\"#排序算法\" class=\"headerlink\" title=\"排序算法\"></a>排序算法</h2><p>聊完数据结构，基本上都会聊一聊排序算法了，说起来其实挺羞耻的，我只会写个快排，我自己的经验是面试基本不会考这个，考的话最多也只会写个快排。不过技多不压身，多看看总没有坏处。</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">排序算法</th>\n<th align=\"center\">时间复杂度</th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\">空间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">快速排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(log(n))</td>\n</tr>\n<tr>\n<td align=\"center\">归并排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">归并插入排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">堆排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">冒泡排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n^2)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">插入排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n^2)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">选择排序</td>\n<td align=\"center\">$\\Omega$(n^2)</td>\n<td align=\"center\">$\\Theta$(n^2)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">树排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">希尔排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n(log(n))^2)</td>\n<td align=\"center\">O(n(log(n))^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">桶排序</td>\n<td align=\"center\">$\\Omega$(n+k)</td>\n<td align=\"center\">$\\Theta$(n+k)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">基数排序</td>\n<td align=\"center\">$\\Omega$(nk)</td>\n<td align=\"center\">$\\Theta$(nk)</td>\n<td align=\"center\">O(nk)</td>\n<td align=\"center\">O(n+k)</td>\n</tr>\n<tr>\n<td align=\"center\">计数排序</td>\n<td align=\"center\">$\\Omega$(n+k)</td>\n<td align=\"center\">$\\Theta$(n+k)</td>\n<td align=\"center\">O(n+k)</td>\n<td align=\"center\">O(k)</td>\n</tr>\n<tr>\n<td align=\"center\">立方体排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">1.</span> 归并插入排序（Merge Insertion Sort）是一种结合了归并排序和插入排序思想的排序算法。它利用了归并排序在处理大规模数据时的高效性能，同时又利用了插入排序在小规模数据上的优势。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    归并插入排序的基本思想是：对于待排序的数组，首先将数组分割成较小的子数组，然后对每个子数组使用插入排序进行排序，最后再使用归并操作将子数组合并成一个有序的数组。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    具体步骤如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 初始状态下，将待排序数组分割成多个较小的子数组（通常是递归地将数组分成两半）。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 对每个子数组应用插入排序算法进行排序。当子数组的长度小于等于一定阈值时，切换到插入排序算法。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 合并操作：通过不断合并相邻的有序子数组，将子数组合并成一个有序的数组。这一过程类似于归并排序中的合并操作。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    归并插入排序的关键在于确定合适的子数组大小，通常当子数组的长度小于一定阈值时，切换到插入排序算法。因为插入排序对于小规模数据具有较好的性能，而归并排序在大规模数据上具有较好的性能。通过合理划分子数组大小，可以在排序过程中充分利用两种排序算法的优势。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    归并插入排序算法的时间复杂度为O(n log n)，其中n为待排序数组的长度。由于归并排序和插入排序的时间复杂度都是O(n log n)和O(n^2)级别，归并插入排序在实际应用中的性能与具体实现和问题规模有关。它适用于各种数据分布情况下的排序需求，并且在实践中往往能够提供较好的性能和稳定性。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 桶排序（Bucket Sort）是一种排序算法，它将待排序的元素分到不同的桶（或称为容器）中，然后对每个桶中的元素分别进行排序，最后将各个桶中的元素按顺序合并得到有序的结果。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    桶排序的基本思想是将待排序的元素均匀地分布到若干个桶中，每个桶内部使用一个较快的排序算法（如插入排序、快速排序等）对元素进行排序。具体的步骤如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 确定桶的数量和范围：根据待排序元素的分布情况，确定桶的数量，可以是固定的数量，也可以根据元素的范围动态确定。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 将元素分配到桶中：遍历待排序的元素，根据元素的值将其分配到相应的桶中。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 对每个桶中的元素进行排序：对每个桶内部的元素使用一个较快的排序算法进行排序，可以选择插入排序、快速排序等。</span><br><span class=\"line\"><span class=\"bullet\">        4.</span> 合并桶中的元素：按照桶的顺序，将每个桶中的元素按顺序合并成一个有序的结果数组。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    桶排序的时间复杂度取决于分配到桶中的元素的分布情况，以及每个桶内部排序算法的选择。在最理想的情况下，当元素均匀分布在不同的桶中，并且每个桶内部的排序时间复杂度为O(nlogn)时，桶排序的时间复杂度可以达到O(n)。然而，在某些情况下，如果元素分布不均匀，可能会导致较大的空间复杂度或较长的排序时间。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    桶排序适用于待排序元素分布较均匀的情况，尤其适合外部排序，即待排序元素无法全部加载到内存中。在实践中，可以根据具体应用场景和数据特点选择合适的桶排序算法的实现方式和参数设置。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 立方体排序（Cube Sort），也称为三维排序或多关键字排序，是一种用于对具有多个关键字的记录进行排序的算法。它在三维空间中对记录进行排序，每个记录具有三个关键字，分别对应三个维度。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    立方体排序的基本思想是通过多次应用稳定的排序算法，先按照一个维度对记录进行排序，然后按照另一个维度对已排序的记录进行排序，依此类推，直到所有关键字都按照指定顺序排列为止。可以类比为将记录组成一个立方体，按照某个维度逐层进行切割和排序。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    具体步骤如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 确定排序顺序：确定按照哪个维度的关键字先进行排序，然后依次确定其他维度的排序顺序。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 应用稳定的排序算法：按照确定的顺序依次对记录进行稳定的排序，通常使用的排序算法有插入排序、冒泡排序、归并排序等。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 重复步骤2：对已排序的记录再次按照下一个维度的关键字进行排序，直到所有关键字都按照指定顺序排列。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    立方体排序的时间复杂度取决于所使用的稳定排序算法的复杂度和记录的数量。如果记录的数量为n，每个维度的排序所使用的算法复杂度为O(f(n))，那么立方体排序的总时间复杂度为O(d * f(n))，其中d为关键字的维度。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    立方体排序适用于多关键字排序的情况，特别适合于具有三个或更多关键字的记录的排序。它可以保持记录之间的相对顺序，并根据每个关键字的重要性进行排序。然而，立方体排序在维度较高和记录数量较大时，可能会面临性能和空间上的挑战。在实际应用中，可以根据具体情况选择合适的排序算法和优化策略。</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><ol>\n<li><a href=\"https://www.bigocheatsheet.com/\">Big-O Cheat Sheet</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Splay_tree\">Splay tree</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/K-d_tree\">K-d tree</a></li>\n<li><a href=\"https://chat.openai.com/\">ChatGPT</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>这是一个经久不衰的题目，不管你是校招新人还是资深大牛，面试过程中都有可能被问到这个问题，这篇文章会梳理一下常见的数据结构和排序算法，以及相关操作的时间复杂度和空间复杂度。</p>","more":"<p>这个问题要答出花样的话，只能展示一下你的博闻强记。正常来说讲一下数组、栈、队列、单链表、双链表、哈希表就差不多了，不过有些比较常用的数据结构，比如用在 redis 和 RocksDB里面的跳表，比如数据库里常用来组织数据的 B tree，聊到这些之后下一步也可以引申着聊一聊 redis 和 RocksDB 的源码实现，这部分会在以后的文章聊到。面试说到底是公司和候选人的互相匹配，在面试过程中候选人必须要尽量避免面试官过于发散地提问，这样才能够保证面试过程能够尽可能完整地展示候选人自己的知识积累。</p>\n<p>收敛面试范围有两种方式，一是要在简历上提到的项目必须是自己真实做过的项目（当然有些同学会包装一些自己没有做过的项目，不做评价），必须保证自己对简历上的项目足够熟悉，高级别的同学同时还需要对简历上涉及的项目在业界的同类方案也要有相当深入的了解。第二就是在面试过程中要学会引导面试官向一些特定的点提问，这一点也很重要。大多数人都不是维基百科，面试官发散的提问也是为了找到候选人比较熟悉和擅长的方向来深入挖掘，如果候选人能够自己积极主导这一过程，整个面试过程就能更加顺利。</p>\n<p>好了话不多说，下面就是一些常见的数据结构和排序算法的时间复杂度和空间复杂度。</p>\n<h2 id=\"基本数据结构\"><a href=\"#基本数据结构\" class=\"headerlink\" title=\"基本数据结构\"></a>基本数据结构</h2><table>\n<thead>\n<tr>\n<th align=\"center\">数据结构</th>\n<th align=\"center\">时间复杂度</th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\">空间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\"></td>\n<td align=\"center\">平均</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\">最优</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\">最坏</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">访问</td>\n<td align=\"center\">查找</td>\n<td align=\"center\">插入</td>\n<td align=\"center\">删除</td>\n<td align=\"center\">访问</td>\n<td align=\"center\">查找</td>\n<td align=\"center\">插入</td>\n<td align=\"center\">删除</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\">数组</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">栈</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">队列</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">单链表</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">双链表</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(n)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(1)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">跳表</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n log(n))</td>\n</tr>\n<tr>\n<td align=\"center\">哈希表</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">$\\Theta$(1)</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">二叉查找树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">笛卡尔树</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">B树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">红黑树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">伸展树（Splay tree）</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">N&#x2F;A</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">自平衡二叉搜索树（AVL tree）</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">K-D树</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">$\\Theta$(log(n))</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">学习笔记：</span><br><span class=\"line\"><span class=\"bullet\">1.</span> 笛卡尔树（Cartesian Tree）是一种特殊的二叉树，它具有以下两个性质：</span><br><span class=\"line\"><span class=\"bullet\">    -</span> 二叉搜索树性质：对于笛卡尔树中的每个节点，其左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。因此，笛卡尔树也是一个有效的二叉搜索树。</span><br><span class=\"line\"><span class=\"bullet\">    -</span> 笛卡尔性质：对于笛卡尔树中的每个节点，其根节点在中序遍历中的位置对应于原始数据数组中对应元素的位置。换句话说，笛卡尔树的根节点对应于原始数组中最大（或最小）的元素，根节点的左子树对应于原始数组中根节点左边的部分，右子树对应于原始数组中根节点右边的部分。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    笛卡尔树通常用于解决与序列相关的问题，如最大矩形面积、下一个更大元素等。通过构建笛卡尔树，可以在O(n)的时间复杂度内解决这些问题。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    构建笛卡尔树的常用方法是使用单调栈。具体步骤如下：</span></span><br><span class=\"line\"><span class=\"code\">        1. 从左到右遍历原始数据数组。</span></span><br><span class=\"line\"><span class=\"code\">        2. 对于每个元素，将其作为新节点插入笛卡尔树中。</span></span><br><span class=\"line\"><span class=\"code\">            - 如果当前节点的值大于栈顶节点的值，将当前节点作为栈顶节点的右子节点，并将栈顶节点弹出栈，直到栈为空或当前节点的值小于栈顶节点的值。</span></span><br><span class=\"line\"><span class=\"code\">            - 如果当前节点的值小于栈顶节点的值，将当前节点作为栈顶节点的左子节点。</span></span><br><span class=\"line\"><span class=\"code\">        3. 将所有剩余的节点依次作为栈顶节点的右子节点，并弹出栈中的节点。</span></span><br><span class=\"line\"><span class=\"code\">    最终得到的树即为笛卡尔树。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    笛卡尔树的特性使得它在某些问题上具有高效的解决方案，但并不是所有问题都适合使用笛卡尔树。在实际应用中，需要根据具体问题的特点和要求来选择合适的数据结构和算法。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 伸展树（Splay Tree）是一种自平衡的二叉搜索树，它通过重新组织树的结构来优化频繁访问的节点，使得这些节点更接近根节点，从而提高查找、插入和删除操作的性能。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    伸展树的主要特点是每次对节点的访问（查找、插入、删除）都会将被访问的节点旋转至根节点，这个过程称为&quot;伸展&quot;。通过伸展操作，伸展树会调整树的形状，使得最近被访问的节点移动到树的根部，以期望在之后的操作中更快地访问到这些节点。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    伸展树的伸展操作通过一系列的旋转来改变树的结构。旋转操作包括&quot;左旋&quot;和&quot;右旋&quot;，通过交换节点的位置来调整树的平衡性。伸展树的伸展操作基于&quot;近似二叉树&quot;（Approximate Binary Tree）的思想，通过将节点向上移动，使得频繁访问的节点更靠近根节点，同时保持树的有序性。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    伸展树的优点在于它适应了访问模式的变化，将频繁访问的节点放置在树的上层，从而减少了访问路径的长度，提高了操作的效率。另外，伸展树没有复杂的平衡因子或调整操作，相对于其他平衡二叉搜索树（如AVL树、红黑树），实现起来更加简单。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    然而，伸展树的最坏情况时间复杂度为O(n)，其中n为树中的节点数，因为伸展操作可能导致树的高度线性增长。因此，在某些特定的访问模式下，伸展树的性能可能不如其他平衡二叉搜索树稳定。此外，伸展树的平均性能与操作的访问模式密切相关。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    伸展树在实际应用中常用于缓存、动态搜索和频繁访问的数据结构等场景，但需要根据具体情况评估其适用性，并注意控制树的深度，避免退化为链表。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 自平衡二叉搜索树（Self-Balancing Binary Search Tree）是一种二叉搜索树，在插入和删除操作后可以自动调整树的结构，以保持树的平衡性，从而提供较为稳定的性能。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    二叉搜索树是一种有序的二叉树，其中每个节点的左子树中的所有节点的值都小于该节点的值，右子树中的所有节点的值都大于该节点的值。它的主要优点是在具有良好平衡性的情况下，查找、插入和删除等操作的平均时间复杂度为O(log n)，其中n为树中节点的数量。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    然而，普通的二叉搜索树在频繁的插入和删除操作后，可能会出现不平衡的情况，导致树的高度增加，进而降低了性能。为了解决这个问题，自平衡二叉搜索树引入了各种自平衡的算法和数据结构，以在操作后保持树的平衡。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    常见的自平衡二叉搜索树包括：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">    1.</span> AVL树：通过旋转操作来保持树的平衡，确保左子树和右子树的高度差不超过1。</span><br><span class=\"line\"><span class=\"bullet\">    2.</span> 红黑树：使用颜色标记和旋转操作来保持树的平衡，保证树的高度近似平衡，并满足一些附加条件。</span><br><span class=\"line\"><span class=\"bullet\">    3.</span> B树和B+树：多路搜索树，通过调整节点的数量来保持树的平衡，适用于大规模数据存储和检索场景。</span><br><span class=\"line\"><span class=\"bullet\">    4.</span> Splay树：通过伸展操作将访问的节点移动到根节点，实现最近访问的节点更容易访问到，提高访问性能。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    这些自平衡二叉搜索树的具体实现方式和调整策略有所不同，但它们的共同目标是通过动态调整树的结构，使得树的高度保持较小，从而提供较高的性能和效率。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    根据具体应用场景和需求，选择合适的自平衡二叉搜索树可以提供更稳定和高效的数据存储和检索能力。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">4.</span> KD树（K-Dimensional Tree）是一种用于对k维空间中的点集进行分割和组织的数据结构。它是二叉搜索树的一种扩展形式，用于支持高维数据的快速搜索和近邻查找。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    在KD树中，每个节点代表k维空间中的一个点，并根据该点的坐标进行分割。具体来说，树的每一层根据一个维度（坐标轴）选择一个切分超平面，将空间划分为两个子空间。左子树表示切分超平面左侧的子空间，右子树表示切分超平面右侧的子空间。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    构建KD树的过程如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 选择切分维度：从k个维度中选择一个维度作为当前层的切分维度。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 选择切分值：在选定的切分维度上选择一个值作为切分超平面。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 划分子空间：将当前层的点集根据切分超平面分割为左右两个子空间，并将点集中小于等于切分值的点放入左子树，大于切分值的点放入右子树。</span><br><span class=\"line\"><span class=\"bullet\">        4.</span> 递归构建子树：对左右子空间递归执行以上步骤，构建子树。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    构建完成后，KD树可以提供以下常见操作：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        -</span> 搜索：根据给定的查询点，在KD树中进行搜索，找到最近的点或满足某种条件的点。</span><br><span class=\"line\"><span class=\"bullet\">        -</span> 插入：向KD树中插入一个新的点。</span><br><span class=\"line\"><span class=\"bullet\">        -</span> 删除：从KD树中删除一个指定的点。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    KD树在高维数据集中可以高效地进行搜索和近邻查找，因为它可以根据数据在不同维度上的切分进行快速剪枝和定位。然而，在数据维度非常高时，KD树的效率可能会下降，这时可以考虑其他数据结构或使用降维等方法来处理高维数据。</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"排序算法\"><a href=\"#排序算法\" class=\"headerlink\" title=\"排序算法\"></a>排序算法</h2><p>聊完数据结构，基本上都会聊一聊排序算法了，说起来其实挺羞耻的，我只会写个快排，我自己的经验是面试基本不会考这个，考的话最多也只会写个快排。不过技多不压身，多看看总没有坏处。</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">排序算法</th>\n<th align=\"center\">时间复杂度</th>\n<th align=\"center\"></th>\n<th align=\"center\"></th>\n<th align=\"center\">空间复杂度</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">快速排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(log(n))</td>\n</tr>\n<tr>\n<td align=\"center\">归并排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">归并插入排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">堆排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">冒泡排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n^2)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">插入排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n^2)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">选择排序</td>\n<td align=\"center\">$\\Omega$(n^2)</td>\n<td align=\"center\">$\\Theta$(n^2)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">树排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">希尔排序</td>\n<td align=\"center\">$\\Omega$(n log(n))</td>\n<td align=\"center\">$\\Theta$(n(log(n))^2)</td>\n<td align=\"center\">O(n(log(n))^2)</td>\n<td align=\"center\">O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">桶排序</td>\n<td align=\"center\">$\\Omega$(n+k)</td>\n<td align=\"center\">$\\Theta$(n+k)</td>\n<td align=\"center\">O(n^2)</td>\n<td align=\"center\">O(n)</td>\n</tr>\n<tr>\n<td align=\"center\">基数排序</td>\n<td align=\"center\">$\\Omega$(nk)</td>\n<td align=\"center\">$\\Theta$(nk)</td>\n<td align=\"center\">O(nk)</td>\n<td align=\"center\">O(n+k)</td>\n</tr>\n<tr>\n<td align=\"center\">计数排序</td>\n<td align=\"center\">$\\Omega$(n+k)</td>\n<td align=\"center\">$\\Theta$(n+k)</td>\n<td align=\"center\">O(n+k)</td>\n<td align=\"center\">O(k)</td>\n</tr>\n<tr>\n<td align=\"center\">立方体排序</td>\n<td align=\"center\">$\\Omega$(n)</td>\n<td align=\"center\">$\\Theta$(n log(n))</td>\n<td align=\"center\">O(n log(n))</td>\n<td align=\"center\">O(n)</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">1.</span> 归并插入排序（Merge Insertion Sort）是一种结合了归并排序和插入排序思想的排序算法。它利用了归并排序在处理大规模数据时的高效性能，同时又利用了插入排序在小规模数据上的优势。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    归并插入排序的基本思想是：对于待排序的数组，首先将数组分割成较小的子数组，然后对每个子数组使用插入排序进行排序，最后再使用归并操作将子数组合并成一个有序的数组。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    具体步骤如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 初始状态下，将待排序数组分割成多个较小的子数组（通常是递归地将数组分成两半）。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 对每个子数组应用插入排序算法进行排序。当子数组的长度小于等于一定阈值时，切换到插入排序算法。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 合并操作：通过不断合并相邻的有序子数组，将子数组合并成一个有序的数组。这一过程类似于归并排序中的合并操作。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    归并插入排序的关键在于确定合适的子数组大小，通常当子数组的长度小于一定阈值时，切换到插入排序算法。因为插入排序对于小规模数据具有较好的性能，而归并排序在大规模数据上具有较好的性能。通过合理划分子数组大小，可以在排序过程中充分利用两种排序算法的优势。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    归并插入排序算法的时间复杂度为O(n log n)，其中n为待排序数组的长度。由于归并排序和插入排序的时间复杂度都是O(n log n)和O(n^2)级别，归并插入排序在实际应用中的性能与具体实现和问题规模有关。它适用于各种数据分布情况下的排序需求，并且在实践中往往能够提供较好的性能和稳定性。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 桶排序（Bucket Sort）是一种排序算法，它将待排序的元素分到不同的桶（或称为容器）中，然后对每个桶中的元素分别进行排序，最后将各个桶中的元素按顺序合并得到有序的结果。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    桶排序的基本思想是将待排序的元素均匀地分布到若干个桶中，每个桶内部使用一个较快的排序算法（如插入排序、快速排序等）对元素进行排序。具体的步骤如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 确定桶的数量和范围：根据待排序元素的分布情况，确定桶的数量，可以是固定的数量，也可以根据元素的范围动态确定。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 将元素分配到桶中：遍历待排序的元素，根据元素的值将其分配到相应的桶中。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 对每个桶中的元素进行排序：对每个桶内部的元素使用一个较快的排序算法进行排序，可以选择插入排序、快速排序等。</span><br><span class=\"line\"><span class=\"bullet\">        4.</span> 合并桶中的元素：按照桶的顺序，将每个桶中的元素按顺序合并成一个有序的结果数组。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    桶排序的时间复杂度取决于分配到桶中的元素的分布情况，以及每个桶内部排序算法的选择。在最理想的情况下，当元素均匀分布在不同的桶中，并且每个桶内部的排序时间复杂度为O(nlogn)时，桶排序的时间复杂度可以达到O(n)。然而，在某些情况下，如果元素分布不均匀，可能会导致较大的空间复杂度或较长的排序时间。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    桶排序适用于待排序元素分布较均匀的情况，尤其适合外部排序，即待排序元素无法全部加载到内存中。在实践中，可以根据具体应用场景和数据特点选择合适的桶排序算法的实现方式和参数设置。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 立方体排序（Cube Sort），也称为三维排序或多关键字排序，是一种用于对具有多个关键字的记录进行排序的算法。它在三维空间中对记录进行排序，每个记录具有三个关键字，分别对应三个维度。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    立方体排序的基本思想是通过多次应用稳定的排序算法，先按照一个维度对记录进行排序，然后按照另一个维度对已排序的记录进行排序，依此类推，直到所有关键字都按照指定顺序排列为止。可以类比为将记录组成一个立方体，按照某个维度逐层进行切割和排序。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    具体步骤如下：</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"bullet\">        1.</span> 确定排序顺序：确定按照哪个维度的关键字先进行排序，然后依次确定其他维度的排序顺序。</span><br><span class=\"line\"><span class=\"bullet\">        2.</span> 应用稳定的排序算法：按照确定的顺序依次对记录进行稳定的排序，通常使用的排序算法有插入排序、冒泡排序、归并排序等。</span><br><span class=\"line\"><span class=\"bullet\">        3.</span> 重复步骤2：对已排序的记录再次按照下一个维度的关键字进行排序，直到所有关键字都按照指定顺序排列。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    立方体排序的时间复杂度取决于所使用的稳定排序算法的复杂度和记录的数量。如果记录的数量为n，每个维度的排序所使用的算法复杂度为O(f(n))，那么立方体排序的总时间复杂度为O(d * f(n))，其中d为关键字的维度。</span></span><br><span class=\"line\"><span class=\"code\"></span></span><br><span class=\"line\"><span class=\"code\">    立方体排序适用于多关键字排序的情况，特别适合于具有三个或更多关键字的记录的排序。它可以保持记录之间的相对顺序，并根据每个关键字的重要性进行排序。然而，立方体排序在维度较高和记录数量较大时，可能会面临性能和空间上的挑战。在实际应用中，可以根据具体情况选择合适的排序算法和优化策略。</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><ol>\n<li><a href=\"https://www.bigocheatsheet.com/\">Big-O Cheat Sheet</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Splay_tree\">Splay tree</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/K-d_tree\">K-d tree</a></li>\n<li><a href=\"https://chat.openai.com/\">ChatGPT</a></li>\n</ol>"},{"title":"设计一个数据库连接池","_content":"\n我被问到这个问题的频率真的很高，可能是因为我的简历里面 有一个连接池相关的项目，所以很多面试官都会问我这个问题。\n\n<!-- more -->\n\n连接池其实是一种非常常见的技术，如果大家做过一些线上服务，多少都会知道连接池复用的重要性。下面是 ChatGPT 的解释，关于我们为什么需要连接池。\n\n连接池（Connection Pool）是为了提高数据库连接的利用效率而设计的一种技术。在许多应用程序中，与数据库进行通信时，需要频繁地获取和释放数据库连接。这个过程涉及到网络通信、身份验证和资源分配等操作，耗费时间和系统资源。\n\n连接池的作用是在应用程序启动时预先创建一定数量的数据库连接，并将它们保存在连接池中。应用程序需要与数据库通信时，从连接池中获取一个可用的连接，并在使用完毕后将连接返回给连接池，而不是每次都重新创建和释放连接。这样可以避免频繁地创建和销毁连接的开销，提高连接的重复利用率。\n\n当涉及到创建和释放数据库连接时，主要的开销包括以下几个方面：\n\n1. 网络通信开销：建立数据库连接涉及到与数据库服务器之间的网络通信。在创建连接时，需要建立底层的网络连接，包括建立TCP连接、进行握手和身份验证等操作。这些网络通信的开销包括往返延迟时间、数据传输时间等，尤其在远程数据库服务器的情况下，网络通信开销可能较大。\n\n2. 身份验证开销：在建立连接时，通常需要进行身份验证以确保访问数据库的权限。这涉及到验证用户凭据、检查权限等操作，这些验证过程可能需要访问数据库的系统表或其他认证机制，从而增加了额外的开销。\n\n3. 资源分配开销：每个数据库连接都需要分配一定的系统资源，包括内存、文件描述符或其他操作系统资源。创建连接时，需要为每个连接分配足够的资源以满足其操作的需求。在连接释放时，需要释放这些资源，包括内存的释放和系统资源的回收，这涉及到系统调用和内核操作，从而产生一定的开销。\n\n4. 连接池管理开销：连接池本身也需要管理连接的生命周期和状态。这包括连接的创建、分配、回收和销毁等操作。连接池需要维护连接的可用性、闲置超时时间、连接的有效性检测等功能，这些管理操作也会带来一定的开销。\n\n以上是创建和释放数据库连接可能涉及的一些主要开销。这些开销在每次创建和释放连接时都会发生，而连接池的作用是通过预先创建一定数量的连接，并重复利用这些连接，避免了频繁创建和销毁连接所带来的开销。通过连接池，应用程序可以从连接池中获取已经建立的连接，避免了每次连接都需要进行网络通信、身份验证和资源分配等操作，从而提高了性能和效率。\n\n以下是使用连接池的一些好处：\n\n1. 提高性能：连接池避免了每次与数据库建立连接和断开连接的开销，减少了网络通信、身份验证和资源分配等的时间消耗，从而提高了应用程序的响应速度和整体性能。\n\n2. 节省资源：连接池能够合理管理和控制数据库连接的数量，避免了无限制地创建连接，节省了系统资源（如内存、文件描述符等）的消耗。\n\n[Note] 这种 case 下，如果连接不被管理，那么很容易出现单个 process handle 数量过多或者占用 port 过多的情况，严重情况下会耗尽整个系统的 port 资源。\n\n3. 平滑扩展：连接池可以动态调整连接的数量，根据应用程序的负载情况和数据库的处理能力进行合理分配，从而实现对数据库连接的平滑扩展和负载均衡。\n\n4. 连接管理：连接池可以提供连接的管理功能，包括连接的闲置超时时间、心跳检测、连接的有效性验证等，确保连接的可用性和稳定性。\n\n5. 流量管理：在多节点环境下，连接池可以提供连接的流量管理功能，确保连接的可用性和稳定性，尽可能将流量均匀地分发到各个节点。\n\n总而言之，连接池通过预先创建和管理数据库连接，以及重复利用连接，提高了应用程序与数据库之间的效率和性能，减少了系统资源的消耗。它是常见的数据库优化技术之一，在高并发和大数据量的场景下尤为重要。\n\n\n\n下面简单介绍一个连接池的实现，一般来说，在面试过程中，首先肯定要定义一下基本的接口, 其实最主要的方法就两个 getConnection 和 returnConnection，考虑到可能需要利用额外的线程去创建和清理连接，还可以加上 produceConnectionTask 和 scanConnectionTask。与此同时，考虑到监控的需求，我们还可以加上几个方法来读取连接池的状态信息，比如连接的数量、创建的数量、返回的数量等。\n\n```cpp\n/* \n* ConnectionPool.h\n*/\n#ifndef CONNECTION_POOL_H\n#define CONNECTION_POOL_H\n\n#include <iostream>\n#include <memory>\n#include <mutex>\n#include <queue>\n#include <mysqlx/xdevapi.h>\n#include <chrono>\n#include <condition_variable>\n#include <atomic>\n\nclass ConnectionPool {\npublic:\n    ConnectionPool(const std::string& host, const std::string& user, const std::string& password, const std::string& schema, int min_size, int max_size, int timeout_sec);\n\n    ~ConnectionPool();\n\n    std::shared_ptr<mysqlx::Session*> getConnection();\n\n    void returnConnection(std::shared_ptr<mysqlx::Session*> connection);\n\n    int getNumConnectionsAcquired() const;\n\n    int getNumConnectionsReturned() const;\n\n    int getNumConnectionsCreated() const;\n\n    int getNumConnectionsDestroyed() const;\n\n    int getNumActiveConnections() const;\n\nprivate:\n    const std::string host_;\n    const std::string user_;\n    const std::string password_;\n    const std::string schema_;\n    const int min_size_;\n    const int max_size_;\n    const int timeout_sec_;\n    std::atomic_int num_connections_{0};\n    std::atomic_int num_connections_acquired_{0};\n    std::atomic_int num_connections_returned_{0};\n    std::atomic_int num_connections_created_{0};\n    std::atomic_int num_connections_destroyed_{0};\n    std::atomic_int num_active_connections_{0};\n    std::queue<std::shared_ptr<mysqlx::Session*>> connections_;\n    std::mutex mutex_;\n    std::condition_variable cv_;\n\n    mysqlx::Session* createConnection();\n\n    void destroyConnection(mysqlx::Session* connection);\n\n    void produceConnectionTask();\n\n    void scanConnectionTask();\n};\n\n#endif // CONNECTION_POOL_H\n\n```\n\n下面是具体的实现。\n\n```cpp\n/*\n* ConnectionPool.cpp\n*/\n#include \"connection_pool.h\"\n\nConnectionPool::ConnectionPool(const std::string& host, const std::string& user, const std::string& password, const std::string& schema, int min_size, int max_size, int timeout_sec)\n    : host_(host), user_(user), password_(password), schema_(schema), min_size_(min_size), max_size_(max_size), timeout_sec_(timeout_sec)\n{\n    for (int i = 0; i < min_size_; ++i) {\n        mysqlx::Session* connection = createConnection();\n        connections_.push(std::make_shared<mysqlx::Session*>(connection));\n        num_connections_.fetch_add(1);\n        num_connections_created_.fetch_add(1);\n    }\n\n    std::thread producer_thread(&ConnectionPool::produceConnectionTask, this);\n    std::thread scanner_thread(&ConnectionPool::scanConnectionTask, this);\n\n    producer_thread.detach();\n    scanner_thread.detach();\n}\n\nConnectionPool::~ConnectionPool()\n{\n    {\n        std::unique_lock<std::mutex> lock(mutex_);\n        while (!connections_.empty()) {\n            mysqlx::Session* connection = *(connections_.front().get());\n            connections_.pop();\n            destroyConnection(connection);\n        }\n    }\n\n    num_connections_.store(0);\n    num_connections_acquired_.store(0);\n    num_connections_returned_.store(0);\n    num_connections_created_.store(0);\n    num_connections_destroyed_.store(0);\n    num_active_connections_.store(0);\n}\n\nstd::shared_ptr<mysqlx::Session> ConnectionPool::getConnection(int timeout_ms)\n{\n    std::unique_lock<std::mutex> lock(mutex_);\n    if (cv_.wait_for(lock, std::chrono::milliseconds(timeout_ms), [this]() { return !connections_.empty(); })) {\n        std::shared_ptr<mysqlx::Session*> connection_ptr = connections_.front();\n        connections_.pop();\n        num_connections_acquired_++;\n        num_active_connections_++;\n        return std::shared_ptr<mysqlx::Session>(*(connection_ptr.get()), [this](mysqlx::Session* connection) {\n            returnConnection(std::make_shared<mysqlx::Session*>(connection));\n        });\n    } else {\n        return nullptr;\n    }\n}\n\nvoid ConnectionPool::returnConnection(std::shared_ptr<mysqlx::Session*> connection)\n{\n    std::unique_lock<std::mutex> lock(mutex_);\n    connections_.push(connection);\n    num_connections_returned_.fetch_add(1);\n    num_active_connections_.fetch_sub(1);\n    cv_.notify_one();\n}\n\nint ConnectionPool::getNumConnectionsAcquired() const\n{\n    return num_connections_acquired_.load();\n}\n\nint ConnectionPool::getNumConnectionsReturned() const\n{\n    return num_connections_returned_.load();\n}\n\nint ConnectionPool::getNumConnectionsCreated() const\n{\n    return num_connections_created_.load();\n}\n\nint ConnectionPool::getNumConnectionsDestroyed() const\n{\n    return num_connections_destroyed_.load();\n}\n\nint ConnectionPool::getNumActiveConnections() const\n{\n    return num_active_connections_.load();\n}\n\nmysqlx::Session* ConnectionPool::createConnection()\n{\n    mysqlx::Session* connection = new mysqlx::Session(host_, 33060, user_, password_, schema_);\n    num_connections_created_.fetch_add(1);\n    return connection;\n}\n\nvoid ConnectionPool::destroyConnection(mysqlx::Session* connection)\n{\n    connection->close();\n    delete connection;\n    num_connections_destroyed_.fetch_add(1);\n}\n\nvoid ConnectionPool::produceConnectionTask()\n{\n    while (true) {\n        std::unique_lock<std::mutex> lock(mutex_);\n        if (num_connections_.load() < max_size_) {\n            mysqlx::Session* connection = createConnection();\n            connections_.push(std::make_shared<mysqlx::Session*>(connection));\n            num_connections_.fetch_add(1);\n        }\n        lock.unlock();\n        std::this_thread::sleep_for(std::chrono::seconds(timeout_sec_));\n    }\n}\n\nvoid ConnectionPool::scanConnectionTask()\n{\n    while (true) {\n        std::unique_lock<std::mutex> lock(mutex_);\n        while (!connections_.empty()) {\n            mysqlx::Session* connection = *(connections_.front().get());\n            connections_.pop();\n            lock.unlock();\n            // Check if the connection is still alive\n            try {\n                mysqlx::Result result = connection->execute(\"SELECT 1\");\n            } catch (const mysqlx::Error& e) {\n                destroyConnection(connection);\n                num_connections_.fetch_sub(1);\n                continue;\n            }\n            connections_.push(std::make_shared<mysqlx::Session*>(connection));\n        }\n        lock.unlock();\n        std::this_thread::sleep_for(std::chrono::seconds(timeout_sec_));\n    }\n}\n```\n","source":"_posts/interview/数据库连接池设计.md","raw":"---\ntitle: 设计一个数据库连接池\ntags:\n    - 面试\n---\n\n我被问到这个问题的频率真的很高，可能是因为我的简历里面 有一个连接池相关的项目，所以很多面试官都会问我这个问题。\n\n<!-- more -->\n\n连接池其实是一种非常常见的技术，如果大家做过一些线上服务，多少都会知道连接池复用的重要性。下面是 ChatGPT 的解释，关于我们为什么需要连接池。\n\n连接池（Connection Pool）是为了提高数据库连接的利用效率而设计的一种技术。在许多应用程序中，与数据库进行通信时，需要频繁地获取和释放数据库连接。这个过程涉及到网络通信、身份验证和资源分配等操作，耗费时间和系统资源。\n\n连接池的作用是在应用程序启动时预先创建一定数量的数据库连接，并将它们保存在连接池中。应用程序需要与数据库通信时，从连接池中获取一个可用的连接，并在使用完毕后将连接返回给连接池，而不是每次都重新创建和释放连接。这样可以避免频繁地创建和销毁连接的开销，提高连接的重复利用率。\n\n当涉及到创建和释放数据库连接时，主要的开销包括以下几个方面：\n\n1. 网络通信开销：建立数据库连接涉及到与数据库服务器之间的网络通信。在创建连接时，需要建立底层的网络连接，包括建立TCP连接、进行握手和身份验证等操作。这些网络通信的开销包括往返延迟时间、数据传输时间等，尤其在远程数据库服务器的情况下，网络通信开销可能较大。\n\n2. 身份验证开销：在建立连接时，通常需要进行身份验证以确保访问数据库的权限。这涉及到验证用户凭据、检查权限等操作，这些验证过程可能需要访问数据库的系统表或其他认证机制，从而增加了额外的开销。\n\n3. 资源分配开销：每个数据库连接都需要分配一定的系统资源，包括内存、文件描述符或其他操作系统资源。创建连接时，需要为每个连接分配足够的资源以满足其操作的需求。在连接释放时，需要释放这些资源，包括内存的释放和系统资源的回收，这涉及到系统调用和内核操作，从而产生一定的开销。\n\n4. 连接池管理开销：连接池本身也需要管理连接的生命周期和状态。这包括连接的创建、分配、回收和销毁等操作。连接池需要维护连接的可用性、闲置超时时间、连接的有效性检测等功能，这些管理操作也会带来一定的开销。\n\n以上是创建和释放数据库连接可能涉及的一些主要开销。这些开销在每次创建和释放连接时都会发生，而连接池的作用是通过预先创建一定数量的连接，并重复利用这些连接，避免了频繁创建和销毁连接所带来的开销。通过连接池，应用程序可以从连接池中获取已经建立的连接，避免了每次连接都需要进行网络通信、身份验证和资源分配等操作，从而提高了性能和效率。\n\n以下是使用连接池的一些好处：\n\n1. 提高性能：连接池避免了每次与数据库建立连接和断开连接的开销，减少了网络通信、身份验证和资源分配等的时间消耗，从而提高了应用程序的响应速度和整体性能。\n\n2. 节省资源：连接池能够合理管理和控制数据库连接的数量，避免了无限制地创建连接，节省了系统资源（如内存、文件描述符等）的消耗。\n\n[Note] 这种 case 下，如果连接不被管理，那么很容易出现单个 process handle 数量过多或者占用 port 过多的情况，严重情况下会耗尽整个系统的 port 资源。\n\n3. 平滑扩展：连接池可以动态调整连接的数量，根据应用程序的负载情况和数据库的处理能力进行合理分配，从而实现对数据库连接的平滑扩展和负载均衡。\n\n4. 连接管理：连接池可以提供连接的管理功能，包括连接的闲置超时时间、心跳检测、连接的有效性验证等，确保连接的可用性和稳定性。\n\n5. 流量管理：在多节点环境下，连接池可以提供连接的流量管理功能，确保连接的可用性和稳定性，尽可能将流量均匀地分发到各个节点。\n\n总而言之，连接池通过预先创建和管理数据库连接，以及重复利用连接，提高了应用程序与数据库之间的效率和性能，减少了系统资源的消耗。它是常见的数据库优化技术之一，在高并发和大数据量的场景下尤为重要。\n\n\n\n下面简单介绍一个连接池的实现，一般来说，在面试过程中，首先肯定要定义一下基本的接口, 其实最主要的方法就两个 getConnection 和 returnConnection，考虑到可能需要利用额外的线程去创建和清理连接，还可以加上 produceConnectionTask 和 scanConnectionTask。与此同时，考虑到监控的需求，我们还可以加上几个方法来读取连接池的状态信息，比如连接的数量、创建的数量、返回的数量等。\n\n```cpp\n/* \n* ConnectionPool.h\n*/\n#ifndef CONNECTION_POOL_H\n#define CONNECTION_POOL_H\n\n#include <iostream>\n#include <memory>\n#include <mutex>\n#include <queue>\n#include <mysqlx/xdevapi.h>\n#include <chrono>\n#include <condition_variable>\n#include <atomic>\n\nclass ConnectionPool {\npublic:\n    ConnectionPool(const std::string& host, const std::string& user, const std::string& password, const std::string& schema, int min_size, int max_size, int timeout_sec);\n\n    ~ConnectionPool();\n\n    std::shared_ptr<mysqlx::Session*> getConnection();\n\n    void returnConnection(std::shared_ptr<mysqlx::Session*> connection);\n\n    int getNumConnectionsAcquired() const;\n\n    int getNumConnectionsReturned() const;\n\n    int getNumConnectionsCreated() const;\n\n    int getNumConnectionsDestroyed() const;\n\n    int getNumActiveConnections() const;\n\nprivate:\n    const std::string host_;\n    const std::string user_;\n    const std::string password_;\n    const std::string schema_;\n    const int min_size_;\n    const int max_size_;\n    const int timeout_sec_;\n    std::atomic_int num_connections_{0};\n    std::atomic_int num_connections_acquired_{0};\n    std::atomic_int num_connections_returned_{0};\n    std::atomic_int num_connections_created_{0};\n    std::atomic_int num_connections_destroyed_{0};\n    std::atomic_int num_active_connections_{0};\n    std::queue<std::shared_ptr<mysqlx::Session*>> connections_;\n    std::mutex mutex_;\n    std::condition_variable cv_;\n\n    mysqlx::Session* createConnection();\n\n    void destroyConnection(mysqlx::Session* connection);\n\n    void produceConnectionTask();\n\n    void scanConnectionTask();\n};\n\n#endif // CONNECTION_POOL_H\n\n```\n\n下面是具体的实现。\n\n```cpp\n/*\n* ConnectionPool.cpp\n*/\n#include \"connection_pool.h\"\n\nConnectionPool::ConnectionPool(const std::string& host, const std::string& user, const std::string& password, const std::string& schema, int min_size, int max_size, int timeout_sec)\n    : host_(host), user_(user), password_(password), schema_(schema), min_size_(min_size), max_size_(max_size), timeout_sec_(timeout_sec)\n{\n    for (int i = 0; i < min_size_; ++i) {\n        mysqlx::Session* connection = createConnection();\n        connections_.push(std::make_shared<mysqlx::Session*>(connection));\n        num_connections_.fetch_add(1);\n        num_connections_created_.fetch_add(1);\n    }\n\n    std::thread producer_thread(&ConnectionPool::produceConnectionTask, this);\n    std::thread scanner_thread(&ConnectionPool::scanConnectionTask, this);\n\n    producer_thread.detach();\n    scanner_thread.detach();\n}\n\nConnectionPool::~ConnectionPool()\n{\n    {\n        std::unique_lock<std::mutex> lock(mutex_);\n        while (!connections_.empty()) {\n            mysqlx::Session* connection = *(connections_.front().get());\n            connections_.pop();\n            destroyConnection(connection);\n        }\n    }\n\n    num_connections_.store(0);\n    num_connections_acquired_.store(0);\n    num_connections_returned_.store(0);\n    num_connections_created_.store(0);\n    num_connections_destroyed_.store(0);\n    num_active_connections_.store(0);\n}\n\nstd::shared_ptr<mysqlx::Session> ConnectionPool::getConnection(int timeout_ms)\n{\n    std::unique_lock<std::mutex> lock(mutex_);\n    if (cv_.wait_for(lock, std::chrono::milliseconds(timeout_ms), [this]() { return !connections_.empty(); })) {\n        std::shared_ptr<mysqlx::Session*> connection_ptr = connections_.front();\n        connections_.pop();\n        num_connections_acquired_++;\n        num_active_connections_++;\n        return std::shared_ptr<mysqlx::Session>(*(connection_ptr.get()), [this](mysqlx::Session* connection) {\n            returnConnection(std::make_shared<mysqlx::Session*>(connection));\n        });\n    } else {\n        return nullptr;\n    }\n}\n\nvoid ConnectionPool::returnConnection(std::shared_ptr<mysqlx::Session*> connection)\n{\n    std::unique_lock<std::mutex> lock(mutex_);\n    connections_.push(connection);\n    num_connections_returned_.fetch_add(1);\n    num_active_connections_.fetch_sub(1);\n    cv_.notify_one();\n}\n\nint ConnectionPool::getNumConnectionsAcquired() const\n{\n    return num_connections_acquired_.load();\n}\n\nint ConnectionPool::getNumConnectionsReturned() const\n{\n    return num_connections_returned_.load();\n}\n\nint ConnectionPool::getNumConnectionsCreated() const\n{\n    return num_connections_created_.load();\n}\n\nint ConnectionPool::getNumConnectionsDestroyed() const\n{\n    return num_connections_destroyed_.load();\n}\n\nint ConnectionPool::getNumActiveConnections() const\n{\n    return num_active_connections_.load();\n}\n\nmysqlx::Session* ConnectionPool::createConnection()\n{\n    mysqlx::Session* connection = new mysqlx::Session(host_, 33060, user_, password_, schema_);\n    num_connections_created_.fetch_add(1);\n    return connection;\n}\n\nvoid ConnectionPool::destroyConnection(mysqlx::Session* connection)\n{\n    connection->close();\n    delete connection;\n    num_connections_destroyed_.fetch_add(1);\n}\n\nvoid ConnectionPool::produceConnectionTask()\n{\n    while (true) {\n        std::unique_lock<std::mutex> lock(mutex_);\n        if (num_connections_.load() < max_size_) {\n            mysqlx::Session* connection = createConnection();\n            connections_.push(std::make_shared<mysqlx::Session*>(connection));\n            num_connections_.fetch_add(1);\n        }\n        lock.unlock();\n        std::this_thread::sleep_for(std::chrono::seconds(timeout_sec_));\n    }\n}\n\nvoid ConnectionPool::scanConnectionTask()\n{\n    while (true) {\n        std::unique_lock<std::mutex> lock(mutex_);\n        while (!connections_.empty()) {\n            mysqlx::Session* connection = *(connections_.front().get());\n            connections_.pop();\n            lock.unlock();\n            // Check if the connection is still alive\n            try {\n                mysqlx::Result result = connection->execute(\"SELECT 1\");\n            } catch (const mysqlx::Error& e) {\n                destroyConnection(connection);\n                num_connections_.fetch_sub(1);\n                continue;\n            }\n            connections_.push(std::make_shared<mysqlx::Session*>(connection));\n        }\n        lock.unlock();\n        std::this_thread::sleep_for(std::chrono::seconds(timeout_sec_));\n    }\n}\n```\n","slug":"interview/数据库连接池设计","published":1,"date":"2023-07-30T06:11:37.245Z","updated":"2023-07-30T06:11:37.246Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iz000q1ts1h5p49vlb","content":"<p>我被问到这个问题的频率真的很高，可能是因为我的简历里面 有一个连接池相关的项目，所以很多面试官都会问我这个问题。</p>\n<span id=\"more\"></span>\n\n<p>连接池其实是一种非常常见的技术，如果大家做过一些线上服务，多少都会知道连接池复用的重要性。下面是 ChatGPT 的解释，关于我们为什么需要连接池。</p>\n<p>连接池（Connection Pool）是为了提高数据库连接的利用效率而设计的一种技术。在许多应用程序中，与数据库进行通信时，需要频繁地获取和释放数据库连接。这个过程涉及到网络通信、身份验证和资源分配等操作，耗费时间和系统资源。</p>\n<p>连接池的作用是在应用程序启动时预先创建一定数量的数据库连接，并将它们保存在连接池中。应用程序需要与数据库通信时，从连接池中获取一个可用的连接，并在使用完毕后将连接返回给连接池，而不是每次都重新创建和释放连接。这样可以避免频繁地创建和销毁连接的开销，提高连接的重复利用率。</p>\n<p>当涉及到创建和释放数据库连接时，主要的开销包括以下几个方面：</p>\n<ol>\n<li><p>网络通信开销：建立数据库连接涉及到与数据库服务器之间的网络通信。在创建连接时，需要建立底层的网络连接，包括建立TCP连接、进行握手和身份验证等操作。这些网络通信的开销包括往返延迟时间、数据传输时间等，尤其在远程数据库服务器的情况下，网络通信开销可能较大。</p>\n</li>\n<li><p>身份验证开销：在建立连接时，通常需要进行身份验证以确保访问数据库的权限。这涉及到验证用户凭据、检查权限等操作，这些验证过程可能需要访问数据库的系统表或其他认证机制，从而增加了额外的开销。</p>\n</li>\n<li><p>资源分配开销：每个数据库连接都需要分配一定的系统资源，包括内存、文件描述符或其他操作系统资源。创建连接时，需要为每个连接分配足够的资源以满足其操作的需求。在连接释放时，需要释放这些资源，包括内存的释放和系统资源的回收，这涉及到系统调用和内核操作，从而产生一定的开销。</p>\n</li>\n<li><p>连接池管理开销：连接池本身也需要管理连接的生命周期和状态。这包括连接的创建、分配、回收和销毁等操作。连接池需要维护连接的可用性、闲置超时时间、连接的有效性检测等功能，这些管理操作也会带来一定的开销。</p>\n</li>\n</ol>\n<p>以上是创建和释放数据库连接可能涉及的一些主要开销。这些开销在每次创建和释放连接时都会发生，而连接池的作用是通过预先创建一定数量的连接，并重复利用这些连接，避免了频繁创建和销毁连接所带来的开销。通过连接池，应用程序可以从连接池中获取已经建立的连接，避免了每次连接都需要进行网络通信、身份验证和资源分配等操作，从而提高了性能和效率。</p>\n<p>以下是使用连接池的一些好处：</p>\n<ol>\n<li><p>提高性能：连接池避免了每次与数据库建立连接和断开连接的开销，减少了网络通信、身份验证和资源分配等的时间消耗，从而提高了应用程序的响应速度和整体性能。</p>\n</li>\n<li><p>节省资源：连接池能够合理管理和控制数据库连接的数量，避免了无限制地创建连接，节省了系统资源（如内存、文件描述符等）的消耗。</p>\n</li>\n</ol>\n<p>[Note] 这种 case 下，如果连接不被管理，那么很容易出现单个 process handle 数量过多或者占用 port 过多的情况，严重情况下会耗尽整个系统的 port 资源。</p>\n<ol start=\"3\">\n<li><p>平滑扩展：连接池可以动态调整连接的数量，根据应用程序的负载情况和数据库的处理能力进行合理分配，从而实现对数据库连接的平滑扩展和负载均衡。</p>\n</li>\n<li><p>连接管理：连接池可以提供连接的管理功能，包括连接的闲置超时时间、心跳检测、连接的有效性验证等，确保连接的可用性和稳定性。</p>\n</li>\n<li><p>流量管理：在多节点环境下，连接池可以提供连接的流量管理功能，确保连接的可用性和稳定性，尽可能将流量均匀地分发到各个节点。</p>\n</li>\n</ol>\n<p>总而言之，连接池通过预先创建和管理数据库连接，以及重复利用连接，提高了应用程序与数据库之间的效率和性能，减少了系统资源的消耗。它是常见的数据库优化技术之一，在高并发和大数据量的场景下尤为重要。</p>\n<p>下面简单介绍一个连接池的实现，一般来说，在面试过程中，首先肯定要定义一下基本的接口, 其实最主要的方法就两个 getConnection 和 returnConnection，考虑到可能需要利用额外的线程去创建和清理连接，还可以加上 produceConnectionTask 和 scanConnectionTask。与此同时，考虑到监控的需求，我们还可以加上几个方法来读取连接池的状态信息，比如连接的数量、创建的数量、返回的数量等。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\">* ConnectionPool.h</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">ifndef</span> CONNECTION_POOL_H</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CONNECTION_POOL_H</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;memory&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;mutex&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;queue&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;mysqlx/xdevapi.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;chrono&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;atomic&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ConnectionPool</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">ConnectionPool</span>(<span class=\"type\">const</span> std::string&amp; host, <span class=\"type\">const</span> std::string&amp; user, <span class=\"type\">const</span> std::string&amp; password, <span class=\"type\">const</span> std::string&amp; schema, <span class=\"type\">int</span> min_size, <span class=\"type\">int</span> max_size, <span class=\"type\">int</span> timeout_sec);</span><br><span class=\"line\"></span><br><span class=\"line\">    ~<span class=\"built_in\">ConnectionPool</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">std::shared_ptr&lt;mysqlx::Session*&gt; <span class=\"title\">getConnection</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">returnConnection</span><span class=\"params\">(std::shared_ptr&lt;mysqlx::Session*&gt; connection)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsAcquired</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsReturned</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsCreated</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsDestroyed</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumActiveConnections</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string host_;</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string user_;</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string password_;</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string schema_;</span><br><span class=\"line\">    <span class=\"type\">const</span> <span class=\"type\">int</span> min_size_;</span><br><span class=\"line\">    <span class=\"type\">const</span> <span class=\"type\">int</span> max_size_;</span><br><span class=\"line\">    <span class=\"type\">const</span> <span class=\"type\">int</span> timeout_sec_;</span><br><span class=\"line\">    std::atomic_int num_connections_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_acquired_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_returned_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_created_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_destroyed_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_active_connections_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::queue&lt;std::shared_ptr&lt;mysqlx::Session*&gt;&gt; connections_;</span><br><span class=\"line\">    std::mutex mutex_;</span><br><span class=\"line\">    std::condition_variable cv_;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">mysqlx::Session* <span class=\"title\">createConnection</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">destroyConnection</span><span class=\"params\">(mysqlx::Session* connection)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">produceConnectionTask</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">scanConnectionTask</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">endif</span> <span class=\"comment\">// CONNECTION_POOL_H</span></span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>下面是具体的实现。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">* ConnectionPool.cpp</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&quot;connection_pool.h&quot;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">ConnectionPool::<span class=\"built_in\">ConnectionPool</span>(<span class=\"type\">const</span> std::string&amp; host, <span class=\"type\">const</span> std::string&amp; user, <span class=\"type\">const</span> std::string&amp; password, <span class=\"type\">const</span> std::string&amp; schema, <span class=\"type\">int</span> min_size, <span class=\"type\">int</span> max_size, <span class=\"type\">int</span> timeout_sec)</span><br><span class=\"line\">    : <span class=\"built_in\">host_</span>(host), <span class=\"built_in\">user_</span>(user), <span class=\"built_in\">password_</span>(password), <span class=\"built_in\">schema_</span>(schema), <span class=\"built_in\">min_size_</span>(min_size), <span class=\"built_in\">max_size_</span>(max_size), <span class=\"built_in\">timeout_sec_</span>(timeout_sec)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; min_size_; ++i) &#123;</span><br><span class=\"line\">        mysqlx::Session* connection = <span class=\"built_in\">createConnection</span>();</span><br><span class=\"line\">        connections_.<span class=\"built_in\">push</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">        num_connections_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        num_connections_created_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">std::thread <span class=\"title\">producer_thread</span><span class=\"params\">(&amp;ConnectionPool::produceConnectionTask, <span class=\"keyword\">this</span>)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">std::thread <span class=\"title\">scanner_thread</span><span class=\"params\">(&amp;ConnectionPool::scanConnectionTask, <span class=\"keyword\">this</span>)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    producer_thread.<span class=\"built_in\">detach</span>();</span><br><span class=\"line\">    scanner_thread.<span class=\"built_in\">detach</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">ConnectionPool::~<span class=\"built_in\">ConnectionPool</span>()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (!connections_.<span class=\"built_in\">empty</span>()) &#123;</span><br><span class=\"line\">            mysqlx::Session* connection = *(connections_.<span class=\"built_in\">front</span>().<span class=\"built_in\">get</span>());</span><br><span class=\"line\">            connections_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            <span class=\"built_in\">destroyConnection</span>(connection);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    num_connections_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_acquired_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_returned_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_created_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_destroyed_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_active_connections_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">std::shared_ptr&lt;mysqlx::Session&gt; <span class=\"title\">ConnectionPool::getConnection</span><span class=\"params\">(<span class=\"type\">int</span> timeout_ms)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (cv_.<span class=\"built_in\">wait_for</span>(lock, std::chrono::<span class=\"built_in\">milliseconds</span>(timeout_ms), [<span class=\"keyword\">this</span>]() &#123; <span class=\"keyword\">return</span> !connections_.<span class=\"built_in\">empty</span>(); &#125;)) &#123;</span><br><span class=\"line\">        std::shared_ptr&lt;mysqlx::Session*&gt; connection_ptr = connections_.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        connections_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">        num_connections_acquired_++;</span><br><span class=\"line\">        num_active_connections_++;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> std::<span class=\"built_in\">shared_ptr</span>&lt;mysqlx::Session&gt;(*(connection_ptr.<span class=\"built_in\">get</span>()), [<span class=\"keyword\">this</span>](mysqlx::Session* connection) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">returnConnection</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::returnConnection</span><span class=\"params\">(std::shared_ptr&lt;mysqlx::Session*&gt; connection)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">    connections_.<span class=\"built_in\">push</span>(connection);</span><br><span class=\"line\">    num_connections_returned_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    num_active_connections_.<span class=\"built_in\">fetch_sub</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    cv_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsAcquired</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_acquired_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsReturned</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_returned_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsCreated</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_created_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsDestroyed</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_destroyed_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumActiveConnections</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_active_connections_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">mysqlx::Session* <span class=\"title\">ConnectionPool::createConnection</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    mysqlx::Session* connection = <span class=\"keyword\">new</span> mysqlx::<span class=\"built_in\">Session</span>(host_, <span class=\"number\">33060</span>, user_, password_, schema_);</span><br><span class=\"line\">    num_connections_created_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> connection;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::destroyConnection</span><span class=\"params\">(mysqlx::Session* connection)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    connection-&gt;<span class=\"built_in\">close</span>();</span><br><span class=\"line\">    <span class=\"keyword\">delete</span> connection;</span><br><span class=\"line\">    num_connections_destroyed_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::produceConnectionTask</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (num_connections_.<span class=\"built_in\">load</span>() &lt; max_size_) &#123;</span><br><span class=\"line\">            mysqlx::Session* connection = <span class=\"built_in\">createConnection</span>();</span><br><span class=\"line\">            connections_.<span class=\"built_in\">push</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">            num_connections_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        std::this_thread::<span class=\"built_in\">sleep_for</span>(std::chrono::<span class=\"built_in\">seconds</span>(timeout_sec_));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::scanConnectionTask</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (!connections_.<span class=\"built_in\">empty</span>()) &#123;</span><br><span class=\"line\">            mysqlx::Session* connection = *(connections_.<span class=\"built_in\">front</span>().<span class=\"built_in\">get</span>());</span><br><span class=\"line\">            connections_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">            <span class=\"comment\">// Check if the connection is still alive</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                mysqlx::Result result = connection-&gt;<span class=\"built_in\">execute</span>(<span class=\"string\">&quot;SELECT 1&quot;</span>);</span><br><span class=\"line\">            &#125; <span class=\"built_in\">catch</span> (<span class=\"type\">const</span> mysqlx::Error&amp; e) &#123;</span><br><span class=\"line\">                <span class=\"built_in\">destroyConnection</span>(connection);</span><br><span class=\"line\">                num_connections_.<span class=\"built_in\">fetch_sub</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">                <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            connections_.<span class=\"built_in\">push</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        std::this_thread::<span class=\"built_in\">sleep_for</span>(std::chrono::<span class=\"built_in\">seconds</span>(timeout_sec_));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>我被问到这个问题的频率真的很高，可能是因为我的简历里面 有一个连接池相关的项目，所以很多面试官都会问我这个问题。</p>","more":"<p>连接池其实是一种非常常见的技术，如果大家做过一些线上服务，多少都会知道连接池复用的重要性。下面是 ChatGPT 的解释，关于我们为什么需要连接池。</p>\n<p>连接池（Connection Pool）是为了提高数据库连接的利用效率而设计的一种技术。在许多应用程序中，与数据库进行通信时，需要频繁地获取和释放数据库连接。这个过程涉及到网络通信、身份验证和资源分配等操作，耗费时间和系统资源。</p>\n<p>连接池的作用是在应用程序启动时预先创建一定数量的数据库连接，并将它们保存在连接池中。应用程序需要与数据库通信时，从连接池中获取一个可用的连接，并在使用完毕后将连接返回给连接池，而不是每次都重新创建和释放连接。这样可以避免频繁地创建和销毁连接的开销，提高连接的重复利用率。</p>\n<p>当涉及到创建和释放数据库连接时，主要的开销包括以下几个方面：</p>\n<ol>\n<li><p>网络通信开销：建立数据库连接涉及到与数据库服务器之间的网络通信。在创建连接时，需要建立底层的网络连接，包括建立TCP连接、进行握手和身份验证等操作。这些网络通信的开销包括往返延迟时间、数据传输时间等，尤其在远程数据库服务器的情况下，网络通信开销可能较大。</p>\n</li>\n<li><p>身份验证开销：在建立连接时，通常需要进行身份验证以确保访问数据库的权限。这涉及到验证用户凭据、检查权限等操作，这些验证过程可能需要访问数据库的系统表或其他认证机制，从而增加了额外的开销。</p>\n</li>\n<li><p>资源分配开销：每个数据库连接都需要分配一定的系统资源，包括内存、文件描述符或其他操作系统资源。创建连接时，需要为每个连接分配足够的资源以满足其操作的需求。在连接释放时，需要释放这些资源，包括内存的释放和系统资源的回收，这涉及到系统调用和内核操作，从而产生一定的开销。</p>\n</li>\n<li><p>连接池管理开销：连接池本身也需要管理连接的生命周期和状态。这包括连接的创建、分配、回收和销毁等操作。连接池需要维护连接的可用性、闲置超时时间、连接的有效性检测等功能，这些管理操作也会带来一定的开销。</p>\n</li>\n</ol>\n<p>以上是创建和释放数据库连接可能涉及的一些主要开销。这些开销在每次创建和释放连接时都会发生，而连接池的作用是通过预先创建一定数量的连接，并重复利用这些连接，避免了频繁创建和销毁连接所带来的开销。通过连接池，应用程序可以从连接池中获取已经建立的连接，避免了每次连接都需要进行网络通信、身份验证和资源分配等操作，从而提高了性能和效率。</p>\n<p>以下是使用连接池的一些好处：</p>\n<ol>\n<li><p>提高性能：连接池避免了每次与数据库建立连接和断开连接的开销，减少了网络通信、身份验证和资源分配等的时间消耗，从而提高了应用程序的响应速度和整体性能。</p>\n</li>\n<li><p>节省资源：连接池能够合理管理和控制数据库连接的数量，避免了无限制地创建连接，节省了系统资源（如内存、文件描述符等）的消耗。</p>\n</li>\n</ol>\n<p>[Note] 这种 case 下，如果连接不被管理，那么很容易出现单个 process handle 数量过多或者占用 port 过多的情况，严重情况下会耗尽整个系统的 port 资源。</p>\n<ol start=\"3\">\n<li><p>平滑扩展：连接池可以动态调整连接的数量，根据应用程序的负载情况和数据库的处理能力进行合理分配，从而实现对数据库连接的平滑扩展和负载均衡。</p>\n</li>\n<li><p>连接管理：连接池可以提供连接的管理功能，包括连接的闲置超时时间、心跳检测、连接的有效性验证等，确保连接的可用性和稳定性。</p>\n</li>\n<li><p>流量管理：在多节点环境下，连接池可以提供连接的流量管理功能，确保连接的可用性和稳定性，尽可能将流量均匀地分发到各个节点。</p>\n</li>\n</ol>\n<p>总而言之，连接池通过预先创建和管理数据库连接，以及重复利用连接，提高了应用程序与数据库之间的效率和性能，减少了系统资源的消耗。它是常见的数据库优化技术之一，在高并发和大数据量的场景下尤为重要。</p>\n<p>下面简单介绍一个连接池的实现，一般来说，在面试过程中，首先肯定要定义一下基本的接口, 其实最主要的方法就两个 getConnection 和 returnConnection，考虑到可能需要利用额外的线程去创建和清理连接，还可以加上 produceConnectionTask 和 scanConnectionTask。与此同时，考虑到监控的需求，我们还可以加上几个方法来读取连接池的状态信息，比如连接的数量、创建的数量、返回的数量等。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\">* ConnectionPool.h</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">ifndef</span> CONNECTION_POOL_H</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CONNECTION_POOL_H</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;memory&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;mutex&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;queue&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;mysqlx/xdevapi.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;chrono&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;atomic&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ConnectionPool</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">ConnectionPool</span>(<span class=\"type\">const</span> std::string&amp; host, <span class=\"type\">const</span> std::string&amp; user, <span class=\"type\">const</span> std::string&amp; password, <span class=\"type\">const</span> std::string&amp; schema, <span class=\"type\">int</span> min_size, <span class=\"type\">int</span> max_size, <span class=\"type\">int</span> timeout_sec);</span><br><span class=\"line\"></span><br><span class=\"line\">    ~<span class=\"built_in\">ConnectionPool</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">std::shared_ptr&lt;mysqlx::Session*&gt; <span class=\"title\">getConnection</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">returnConnection</span><span class=\"params\">(std::shared_ptr&lt;mysqlx::Session*&gt; connection)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsAcquired</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsReturned</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsCreated</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumConnectionsDestroyed</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getNumActiveConnections</span><span class=\"params\">()</span> <span class=\"type\">const</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string host_;</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string user_;</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string password_;</span><br><span class=\"line\">    <span class=\"type\">const</span> std::string schema_;</span><br><span class=\"line\">    <span class=\"type\">const</span> <span class=\"type\">int</span> min_size_;</span><br><span class=\"line\">    <span class=\"type\">const</span> <span class=\"type\">int</span> max_size_;</span><br><span class=\"line\">    <span class=\"type\">const</span> <span class=\"type\">int</span> timeout_sec_;</span><br><span class=\"line\">    std::atomic_int num_connections_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_acquired_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_returned_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_created_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_connections_destroyed_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::atomic_int num_active_connections_&#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    std::queue&lt;std::shared_ptr&lt;mysqlx::Session*&gt;&gt; connections_;</span><br><span class=\"line\">    std::mutex mutex_;</span><br><span class=\"line\">    std::condition_variable cv_;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">mysqlx::Session* <span class=\"title\">createConnection</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">destroyConnection</span><span class=\"params\">(mysqlx::Session* connection)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">produceConnectionTask</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">scanConnectionTask</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">endif</span> <span class=\"comment\">// CONNECTION_POOL_H</span></span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>下面是具体的实现。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">* ConnectionPool.cpp</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&quot;connection_pool.h&quot;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">ConnectionPool::<span class=\"built_in\">ConnectionPool</span>(<span class=\"type\">const</span> std::string&amp; host, <span class=\"type\">const</span> std::string&amp; user, <span class=\"type\">const</span> std::string&amp; password, <span class=\"type\">const</span> std::string&amp; schema, <span class=\"type\">int</span> min_size, <span class=\"type\">int</span> max_size, <span class=\"type\">int</span> timeout_sec)</span><br><span class=\"line\">    : <span class=\"built_in\">host_</span>(host), <span class=\"built_in\">user_</span>(user), <span class=\"built_in\">password_</span>(password), <span class=\"built_in\">schema_</span>(schema), <span class=\"built_in\">min_size_</span>(min_size), <span class=\"built_in\">max_size_</span>(max_size), <span class=\"built_in\">timeout_sec_</span>(timeout_sec)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; min_size_; ++i) &#123;</span><br><span class=\"line\">        mysqlx::Session* connection = <span class=\"built_in\">createConnection</span>();</span><br><span class=\"line\">        connections_.<span class=\"built_in\">push</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">        num_connections_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        num_connections_created_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">std::thread <span class=\"title\">producer_thread</span><span class=\"params\">(&amp;ConnectionPool::produceConnectionTask, <span class=\"keyword\">this</span>)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">std::thread <span class=\"title\">scanner_thread</span><span class=\"params\">(&amp;ConnectionPool::scanConnectionTask, <span class=\"keyword\">this</span>)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    producer_thread.<span class=\"built_in\">detach</span>();</span><br><span class=\"line\">    scanner_thread.<span class=\"built_in\">detach</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">ConnectionPool::~<span class=\"built_in\">ConnectionPool</span>()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (!connections_.<span class=\"built_in\">empty</span>()) &#123;</span><br><span class=\"line\">            mysqlx::Session* connection = *(connections_.<span class=\"built_in\">front</span>().<span class=\"built_in\">get</span>());</span><br><span class=\"line\">            connections_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            <span class=\"built_in\">destroyConnection</span>(connection);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    num_connections_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_acquired_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_returned_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_created_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_connections_destroyed_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">    num_active_connections_.<span class=\"built_in\">store</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">std::shared_ptr&lt;mysqlx::Session&gt; <span class=\"title\">ConnectionPool::getConnection</span><span class=\"params\">(<span class=\"type\">int</span> timeout_ms)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (cv_.<span class=\"built_in\">wait_for</span>(lock, std::chrono::<span class=\"built_in\">milliseconds</span>(timeout_ms), [<span class=\"keyword\">this</span>]() &#123; <span class=\"keyword\">return</span> !connections_.<span class=\"built_in\">empty</span>(); &#125;)) &#123;</span><br><span class=\"line\">        std::shared_ptr&lt;mysqlx::Session*&gt; connection_ptr = connections_.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        connections_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">        num_connections_acquired_++;</span><br><span class=\"line\">        num_active_connections_++;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> std::<span class=\"built_in\">shared_ptr</span>&lt;mysqlx::Session&gt;(*(connection_ptr.<span class=\"built_in\">get</span>()), [<span class=\"keyword\">this</span>](mysqlx::Session* connection) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">returnConnection</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::returnConnection</span><span class=\"params\">(std::shared_ptr&lt;mysqlx::Session*&gt; connection)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">    connections_.<span class=\"built_in\">push</span>(connection);</span><br><span class=\"line\">    num_connections_returned_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    num_active_connections_.<span class=\"built_in\">fetch_sub</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    cv_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsAcquired</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_acquired_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsReturned</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_returned_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsCreated</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_created_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumConnectionsDestroyed</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_connections_destroyed_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">ConnectionPool::getNumActiveConnections</span><span class=\"params\">()</span> <span class=\"type\">const</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> num_active_connections_.<span class=\"built_in\">load</span>();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">mysqlx::Session* <span class=\"title\">ConnectionPool::createConnection</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    mysqlx::Session* connection = <span class=\"keyword\">new</span> mysqlx::<span class=\"built_in\">Session</span>(host_, <span class=\"number\">33060</span>, user_, password_, schema_);</span><br><span class=\"line\">    num_connections_created_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> connection;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::destroyConnection</span><span class=\"params\">(mysqlx::Session* connection)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    connection-&gt;<span class=\"built_in\">close</span>();</span><br><span class=\"line\">    <span class=\"keyword\">delete</span> connection;</span><br><span class=\"line\">    num_connections_destroyed_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::produceConnectionTask</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (num_connections_.<span class=\"built_in\">load</span>() &lt; max_size_) &#123;</span><br><span class=\"line\">            mysqlx::Session* connection = <span class=\"built_in\">createConnection</span>();</span><br><span class=\"line\">            connections_.<span class=\"built_in\">push</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">            num_connections_.<span class=\"built_in\">fetch_add</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        std::this_thread::<span class=\"built_in\">sleep_for</span>(std::chrono::<span class=\"built_in\">seconds</span>(timeout_sec_));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ConnectionPool::scanConnectionTask</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (!connections_.<span class=\"built_in\">empty</span>()) &#123;</span><br><span class=\"line\">            mysqlx::Session* connection = *(connections_.<span class=\"built_in\">front</span>().<span class=\"built_in\">get</span>());</span><br><span class=\"line\">            connections_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">            <span class=\"comment\">// Check if the connection is still alive</span></span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                mysqlx::Result result = connection-&gt;<span class=\"built_in\">execute</span>(<span class=\"string\">&quot;SELECT 1&quot;</span>);</span><br><span class=\"line\">            &#125; <span class=\"built_in\">catch</span> (<span class=\"type\">const</span> mysqlx::Error&amp; e) &#123;</span><br><span class=\"line\">                <span class=\"built_in\">destroyConnection</span>(connection);</span><br><span class=\"line\">                num_connections_.<span class=\"built_in\">fetch_sub</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">                <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            connections_.<span class=\"built_in\">push</span>(std::<span class=\"built_in\">make_shared</span>&lt;mysqlx::Session*&gt;(connection));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        std::this_thread::<span class=\"built_in\">sleep_for</span>(std::chrono::<span class=\"built_in\">seconds</span>(timeout_sec_));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"生产环境中的限流方案 -- 如果让你设计一个请求限流器，你会怎么做？","_content":"\n随着互联网应用的普及和用户数量的增长，系统面临的并发请求量不断增加。在这种情况下，如果没有适当的限制措施，系统很容易受到过多的请求压力，导致性能下降甚至崩溃。因此，限流算法应运而生，它可以根据系统的处理能力和资源情况，合理地限制请求的数量，以保证系统的稳定和可靠性。\n\n<!-- more -->\n\n## 常见的限流算法\n限流算法的基本原理是通过控制请求的速率来限制系统的负载。它可以防止过多的请求同时涌入系统，使系统能够按照自身的处理能力有序地进行工作。常见的限流算法包括漏桶算法和令牌桶算法。\n\n### 令牌桶算法（Token Bucket Algorithm）\n\n算法原理：令牌桶算法通过维护一个令牌桶来控制请求的速率。令牌桶以固定的速率往桶中放入令牌（代表请求），桶的大小表示令牌的最大数量。当请求到达时，需要从令牌桶中获取一个令牌，如果桶中没有可用令牌，则请求被拒绝。如果有可用令牌，则取走一个令牌，表示请求被接受。\n工作流程：令牌桶算法使用一个计时器以固定的速率向桶中添加令牌。当请求到达时，首先检查桶中是否有令牌可用。如果有令牌可用，则取走一个令牌，并处理该请求；如果没有令牌可用，则请求被拒绝。无论请求是否被接受，都会消耗一个令牌。\n优点：令牌桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它还可以适应不同的请求速率和峰值流量。\n缺点：在处理大量的突发性请求时，令牌桶可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。\n\n### 漏桶算法（Leaky Bucket Algorithm）\n\n算法原理：漏桶算法以固定的速率从一个漏桶中漏水。当请求到达时，如果桶还有空闲容量，则请求被接受并放入桶中；否则，请求被拒绝。桶中的容量代表系统可以处理的请求数量。如果请求被接受，漏桶以固定的速率漏水，释放出桶中的一个请求，这样就为下一个请求腾出空间。\n工作流程：漏桶算法使用一个计时器以固定的速率漏水。当请求到达时，首先检查桶中是否有空闲容量。如果有空闲容量，则将请求放入桶中，并开始漏水。如果没有空闲容量，则请求被拒绝。无论请求是否被接受，都会按照固定速率漏水释放请求。\n优点：漏桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它可以防止系统被大量请求压垮，提供了一定的请求处理能力保护机制。\n缺点：在处理突发性请求时，漏桶的容量可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。\n\n### 计数器算法（Counter Algorithm）\n\n算法原理：计数器算法简单地统计在指定时间窗口内到达的请求数量，并与预设的阈值进行比较。如果请求数超过阈值，则请求被拒绝。该算法维护一个计数器，每当有请求到达时，计数器加1，并记录请求的时间戳。过了时间窗口后，计数器清零。\n工作流程：计数器算法使用一个计时器来跟踪时间窗口。每当请求到达时，计数器加1，并检查计数器的值是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。\n优点：实现简单，对于控制请求速率较为精确。可以根据业务需求灵活地调整时间窗口的大小和阈值。\n缺点：对于突发性请求的处理能力较差，容易出现请求被拒绝或阻塞的情况。\n\n### 滑动窗口算法（Sliding Window Algorithm）\n\n算法原理：滑动窗口算法将时间划分为固定大小的窗口，每个窗口内维护请求的计数器。随着时间的推移，旧的窗口被移除，新的窗口被添加。通过统计窗口内的请求数量，并与设定的阈值进行比较，可以实现限流的目的。\n工作流程：滑动窗口算法维护一个固定大小的窗口队列，其中每个窗口记录了在该时间窗口内到达的请求数量。当请求到达时，首先根据当前时间确定所属的窗口，然后将请求计数器加1，并检查窗口队列中的总请求数是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。\n优点：对于控制请求速率较为精确，能够平滑地处理突发性请求。可以根据业务需求灵活地调整窗口大小和阈值。\n缺点：算法的实现相对复杂一些，需要维护时间窗口队列，对于高并发场景可能会增加一定的计算和存储开销。\n\n## 生产环境中的限流方案\n\n生产环境中的限流往往比上述算法的实现更加灵活，这是因为网络环境中的请求并不是均匀分布的：有的系统流量具有周期性，与用户的工作时间或者娱乐时间密切关联，有的请求具有突发性，往往一瞬间就能耗尽整个系统中的所有资源。如果整体来看请求数量的图表(metrics dashboard / perf counter)，会发现请求的数量时高时低；如果把图表放大到最小的单位，又能看到图中的折线存在一个个小的尖峰，生产环境中的限流必须要考虑到这类情况。\n\n与此同时，在真实的生产环境中，用户的请求往往不是单一的，我们需要基于某些单元来对资源的占用进行限制，例如：在多租户系统中基于租户来对资源进行限制，在微服务系统中基于请求方的id 来对资源进行限制，在数据库（存储平台）基于表（或者数据分片）来对资源进行限制。这些实现往往是十分灵活的。另一方面，如果仅仅以某些单元来限制资源的占用，而忽略了系统整体的资源占用情况，这样也会导致系统整体的不可用。相信真正维护过线上服务的同学都曾遇到过请求把单台机器打爆的情况，在这种情况下，我们甚至无法连接到节点上进行恢复性的操作。一个生产环境的限流方案必须要考虑到这些情况。\n\n下文介绍了一个生产环境中的限流方案，严格来讲是一个基于固定窗口的限流方案，并没有采取听起来更加先进的令牌桶或者漏斗桶的方式，分享出来提供给大家参考。\n\n首先简单介绍一下限流器的使用背景，这个限流器主要用在单机场景，机器上维护了多个数据表，用户的请求流量往往是对单个表进行读取和写入，所以我们以表为单位进行资源的隔离。我们主要关注以下指标：\n\n- CPU 占用量\n- 线程时间（单个请求占用线程的时间）\n- 网络 IO（Bytes per second）\n- 硬盘读写 IO（包括固态盘和机械盘分别的读写 IO）\n\n这些基本的指标都是我们要关注的。我们可以通过对这些指标进行统计来分析我们的系统的整体资源消耗情况。\n\n### 1. 如何衡量资源的使用情况？\n为了降低分配内存的开销，我们直接采用一个循环缓冲区，存储过去一定时间内资源的使用情况。这个环形缓存由一定数量的槽构成，每个槽代表着 10ms 内的资源使用情况。对于机器上每一张表，我们都创建一个这样的环形缓存，同时，我们也为整个机器创建一个同样的循环缓冲区，用来记录整台机器的资源使用情况。循环缓冲区的大小可以按需指定，比如存储 5 分钟左右的数据，我们则需要  5*60*1000/10=3000 个槽。当请求被执行时，执行器会将资源使用情况报告到环形缓冲区中。其中，IO使用情况在请求执行结束之后报告，CPU 使用情况则是以小于槽的长度的时间间隔来定期报告。\n\n```markdown\nNote: 环形缓冲区是一种常用的数据结构，具有以下好处：\n\n- 高效的内存利用：环形缓冲区可以通过固定大小的缓冲区来存储数据。当缓冲区满时，新的数据可以覆盖最旧的数据。这样可以保持缓冲区的大小不变，从而实现高效的内存利用。\n\n- 实时数据处理：环形缓冲区特别适用于实时数据处理场景。由于环形缓冲区可以按照固定的速率接收数据，并且丢弃最旧的数据，因此它可以存储最近的数据，并提供对实时数据的快速访问。\n\n- 简单的实现和高效的操作：环形缓冲区可以使用数组或循环链表等数据结构来实现，这些实现相对简单而且高效。读取和写入数据的操作可以在常数时间内完成，因此环形缓冲区可以快速地处理大量数据。\n\n- 缓解生产者和消费者之间的速度差异：在并发编程中，生产者和消费者之间的速度差异可能导致数据丢失或阻塞。环形缓冲区提供了一个缓冲区，使得生产者和消费者可以以不同的速度进行工作，而不会发生数据丢失或阻塞。\n```\n\n基于环形缓冲区中各个 bucket 的数据，我们可以计算得到许多观测指标，比如平均资源消耗、p50、p99 等。\n\n### 2. 如何限流？\n为了隔离每个表的资源使用，我们对同一台机器上的每个表都构建这样一个环形缓冲区，用来记录该表可以接受请求的资源占用预算。当某个表的资源使用超出预算时，同时整台机器的资源使用超预算时，我们就对打到这个表的请求进行限流。这种操作允许单个表在机器整体资源仍然可用的情况下适当过载。具体实现如下：\n\n对于机器上的每个表和机器本身，我们都维护一个以环形缓冲区为基础的资源窗口。窗口大小以毫秒为单位，维护一个最大值和一个最小值。最大值表示当前窗口的资源预算，每执行一次请求，我们都在这个值上减去当前消耗的资源数量。当这个值变为 0 时，表示这张表（或者这台机器）的资源已经完全耗尽。当请求继续被执行时，这个值可能会变为负数，这种情况我们称之为负债情况。最小值则是表示当前表（或者机器）可以有多少的负债。当一个时间窗口过去时，对应的资源又会增加回来到最大值。\n","source":"_posts/interview/生产环境中的限流方案.md","raw":"---\ntitle: \"生产环境中的限流方案 -- 如果让你设计一个请求限流器，你会怎么做？\"\ntags:\n    - 面试\n---\n\n随着互联网应用的普及和用户数量的增长，系统面临的并发请求量不断增加。在这种情况下，如果没有适当的限制措施，系统很容易受到过多的请求压力，导致性能下降甚至崩溃。因此，限流算法应运而生，它可以根据系统的处理能力和资源情况，合理地限制请求的数量，以保证系统的稳定和可靠性。\n\n<!-- more -->\n\n## 常见的限流算法\n限流算法的基本原理是通过控制请求的速率来限制系统的负载。它可以防止过多的请求同时涌入系统，使系统能够按照自身的处理能力有序地进行工作。常见的限流算法包括漏桶算法和令牌桶算法。\n\n### 令牌桶算法（Token Bucket Algorithm）\n\n算法原理：令牌桶算法通过维护一个令牌桶来控制请求的速率。令牌桶以固定的速率往桶中放入令牌（代表请求），桶的大小表示令牌的最大数量。当请求到达时，需要从令牌桶中获取一个令牌，如果桶中没有可用令牌，则请求被拒绝。如果有可用令牌，则取走一个令牌，表示请求被接受。\n工作流程：令牌桶算法使用一个计时器以固定的速率向桶中添加令牌。当请求到达时，首先检查桶中是否有令牌可用。如果有令牌可用，则取走一个令牌，并处理该请求；如果没有令牌可用，则请求被拒绝。无论请求是否被接受，都会消耗一个令牌。\n优点：令牌桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它还可以适应不同的请求速率和峰值流量。\n缺点：在处理大量的突发性请求时，令牌桶可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。\n\n### 漏桶算法（Leaky Bucket Algorithm）\n\n算法原理：漏桶算法以固定的速率从一个漏桶中漏水。当请求到达时，如果桶还有空闲容量，则请求被接受并放入桶中；否则，请求被拒绝。桶中的容量代表系统可以处理的请求数量。如果请求被接受，漏桶以固定的速率漏水，释放出桶中的一个请求，这样就为下一个请求腾出空间。\n工作流程：漏桶算法使用一个计时器以固定的速率漏水。当请求到达时，首先检查桶中是否有空闲容量。如果有空闲容量，则将请求放入桶中，并开始漏水。如果没有空闲容量，则请求被拒绝。无论请求是否被接受，都会按照固定速率漏水释放请求。\n优点：漏桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它可以防止系统被大量请求压垮，提供了一定的请求处理能力保护机制。\n缺点：在处理突发性请求时，漏桶的容量可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。\n\n### 计数器算法（Counter Algorithm）\n\n算法原理：计数器算法简单地统计在指定时间窗口内到达的请求数量，并与预设的阈值进行比较。如果请求数超过阈值，则请求被拒绝。该算法维护一个计数器，每当有请求到达时，计数器加1，并记录请求的时间戳。过了时间窗口后，计数器清零。\n工作流程：计数器算法使用一个计时器来跟踪时间窗口。每当请求到达时，计数器加1，并检查计数器的值是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。\n优点：实现简单，对于控制请求速率较为精确。可以根据业务需求灵活地调整时间窗口的大小和阈值。\n缺点：对于突发性请求的处理能力较差，容易出现请求被拒绝或阻塞的情况。\n\n### 滑动窗口算法（Sliding Window Algorithm）\n\n算法原理：滑动窗口算法将时间划分为固定大小的窗口，每个窗口内维护请求的计数器。随着时间的推移，旧的窗口被移除，新的窗口被添加。通过统计窗口内的请求数量，并与设定的阈值进行比较，可以实现限流的目的。\n工作流程：滑动窗口算法维护一个固定大小的窗口队列，其中每个窗口记录了在该时间窗口内到达的请求数量。当请求到达时，首先根据当前时间确定所属的窗口，然后将请求计数器加1，并检查窗口队列中的总请求数是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。\n优点：对于控制请求速率较为精确，能够平滑地处理突发性请求。可以根据业务需求灵活地调整窗口大小和阈值。\n缺点：算法的实现相对复杂一些，需要维护时间窗口队列，对于高并发场景可能会增加一定的计算和存储开销。\n\n## 生产环境中的限流方案\n\n生产环境中的限流往往比上述算法的实现更加灵活，这是因为网络环境中的请求并不是均匀分布的：有的系统流量具有周期性，与用户的工作时间或者娱乐时间密切关联，有的请求具有突发性，往往一瞬间就能耗尽整个系统中的所有资源。如果整体来看请求数量的图表(metrics dashboard / perf counter)，会发现请求的数量时高时低；如果把图表放大到最小的单位，又能看到图中的折线存在一个个小的尖峰，生产环境中的限流必须要考虑到这类情况。\n\n与此同时，在真实的生产环境中，用户的请求往往不是单一的，我们需要基于某些单元来对资源的占用进行限制，例如：在多租户系统中基于租户来对资源进行限制，在微服务系统中基于请求方的id 来对资源进行限制，在数据库（存储平台）基于表（或者数据分片）来对资源进行限制。这些实现往往是十分灵活的。另一方面，如果仅仅以某些单元来限制资源的占用，而忽略了系统整体的资源占用情况，这样也会导致系统整体的不可用。相信真正维护过线上服务的同学都曾遇到过请求把单台机器打爆的情况，在这种情况下，我们甚至无法连接到节点上进行恢复性的操作。一个生产环境的限流方案必须要考虑到这些情况。\n\n下文介绍了一个生产环境中的限流方案，严格来讲是一个基于固定窗口的限流方案，并没有采取听起来更加先进的令牌桶或者漏斗桶的方式，分享出来提供给大家参考。\n\n首先简单介绍一下限流器的使用背景，这个限流器主要用在单机场景，机器上维护了多个数据表，用户的请求流量往往是对单个表进行读取和写入，所以我们以表为单位进行资源的隔离。我们主要关注以下指标：\n\n- CPU 占用量\n- 线程时间（单个请求占用线程的时间）\n- 网络 IO（Bytes per second）\n- 硬盘读写 IO（包括固态盘和机械盘分别的读写 IO）\n\n这些基本的指标都是我们要关注的。我们可以通过对这些指标进行统计来分析我们的系统的整体资源消耗情况。\n\n### 1. 如何衡量资源的使用情况？\n为了降低分配内存的开销，我们直接采用一个循环缓冲区，存储过去一定时间内资源的使用情况。这个环形缓存由一定数量的槽构成，每个槽代表着 10ms 内的资源使用情况。对于机器上每一张表，我们都创建一个这样的环形缓存，同时，我们也为整个机器创建一个同样的循环缓冲区，用来记录整台机器的资源使用情况。循环缓冲区的大小可以按需指定，比如存储 5 分钟左右的数据，我们则需要  5*60*1000/10=3000 个槽。当请求被执行时，执行器会将资源使用情况报告到环形缓冲区中。其中，IO使用情况在请求执行结束之后报告，CPU 使用情况则是以小于槽的长度的时间间隔来定期报告。\n\n```markdown\nNote: 环形缓冲区是一种常用的数据结构，具有以下好处：\n\n- 高效的内存利用：环形缓冲区可以通过固定大小的缓冲区来存储数据。当缓冲区满时，新的数据可以覆盖最旧的数据。这样可以保持缓冲区的大小不变，从而实现高效的内存利用。\n\n- 实时数据处理：环形缓冲区特别适用于实时数据处理场景。由于环形缓冲区可以按照固定的速率接收数据，并且丢弃最旧的数据，因此它可以存储最近的数据，并提供对实时数据的快速访问。\n\n- 简单的实现和高效的操作：环形缓冲区可以使用数组或循环链表等数据结构来实现，这些实现相对简单而且高效。读取和写入数据的操作可以在常数时间内完成，因此环形缓冲区可以快速地处理大量数据。\n\n- 缓解生产者和消费者之间的速度差异：在并发编程中，生产者和消费者之间的速度差异可能导致数据丢失或阻塞。环形缓冲区提供了一个缓冲区，使得生产者和消费者可以以不同的速度进行工作，而不会发生数据丢失或阻塞。\n```\n\n基于环形缓冲区中各个 bucket 的数据，我们可以计算得到许多观测指标，比如平均资源消耗、p50、p99 等。\n\n### 2. 如何限流？\n为了隔离每个表的资源使用，我们对同一台机器上的每个表都构建这样一个环形缓冲区，用来记录该表可以接受请求的资源占用预算。当某个表的资源使用超出预算时，同时整台机器的资源使用超预算时，我们就对打到这个表的请求进行限流。这种操作允许单个表在机器整体资源仍然可用的情况下适当过载。具体实现如下：\n\n对于机器上的每个表和机器本身，我们都维护一个以环形缓冲区为基础的资源窗口。窗口大小以毫秒为单位，维护一个最大值和一个最小值。最大值表示当前窗口的资源预算，每执行一次请求，我们都在这个值上减去当前消耗的资源数量。当这个值变为 0 时，表示这张表（或者这台机器）的资源已经完全耗尽。当请求继续被执行时，这个值可能会变为负数，这种情况我们称之为负债情况。最小值则是表示当前表（或者机器）可以有多少的负债。当一个时间窗口过去时，对应的资源又会增加回来到最大值。\n","slug":"interview/生产环境中的限流方案","published":1,"date":"2023-07-30T06:11:37.246Z","updated":"2023-07-30T06:11:37.246Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iz000s1ts18hqeg8o1","content":"<p>随着互联网应用的普及和用户数量的增长，系统面临的并发请求量不断增加。在这种情况下，如果没有适当的限制措施，系统很容易受到过多的请求压力，导致性能下降甚至崩溃。因此，限流算法应运而生，它可以根据系统的处理能力和资源情况，合理地限制请求的数量，以保证系统的稳定和可靠性。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"常见的限流算法\"><a href=\"#常见的限流算法\" class=\"headerlink\" title=\"常见的限流算法\"></a>常见的限流算法</h2><p>限流算法的基本原理是通过控制请求的速率来限制系统的负载。它可以防止过多的请求同时涌入系统，使系统能够按照自身的处理能力有序地进行工作。常见的限流算法包括漏桶算法和令牌桶算法。</p>\n<h3 id=\"令牌桶算法（Token-Bucket-Algorithm）\"><a href=\"#令牌桶算法（Token-Bucket-Algorithm）\" class=\"headerlink\" title=\"令牌桶算法（Token Bucket Algorithm）\"></a>令牌桶算法（Token Bucket Algorithm）</h3><p>算法原理：令牌桶算法通过维护一个令牌桶来控制请求的速率。令牌桶以固定的速率往桶中放入令牌（代表请求），桶的大小表示令牌的最大数量。当请求到达时，需要从令牌桶中获取一个令牌，如果桶中没有可用令牌，则请求被拒绝。如果有可用令牌，则取走一个令牌，表示请求被接受。<br>工作流程：令牌桶算法使用一个计时器以固定的速率向桶中添加令牌。当请求到达时，首先检查桶中是否有令牌可用。如果有令牌可用，则取走一个令牌，并处理该请求；如果没有令牌可用，则请求被拒绝。无论请求是否被接受，都会消耗一个令牌。<br>优点：令牌桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它还可以适应不同的请求速率和峰值流量。<br>缺点：在处理大量的突发性请求时，令牌桶可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。</p>\n<h3 id=\"漏桶算法（Leaky-Bucket-Algorithm）\"><a href=\"#漏桶算法（Leaky-Bucket-Algorithm）\" class=\"headerlink\" title=\"漏桶算法（Leaky Bucket Algorithm）\"></a>漏桶算法（Leaky Bucket Algorithm）</h3><p>算法原理：漏桶算法以固定的速率从一个漏桶中漏水。当请求到达时，如果桶还有空闲容量，则请求被接受并放入桶中；否则，请求被拒绝。桶中的容量代表系统可以处理的请求数量。如果请求被接受，漏桶以固定的速率漏水，释放出桶中的一个请求，这样就为下一个请求腾出空间。<br>工作流程：漏桶算法使用一个计时器以固定的速率漏水。当请求到达时，首先检查桶中是否有空闲容量。如果有空闲容量，则将请求放入桶中，并开始漏水。如果没有空闲容量，则请求被拒绝。无论请求是否被接受，都会按照固定速率漏水释放请求。<br>优点：漏桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它可以防止系统被大量请求压垮，提供了一定的请求处理能力保护机制。<br>缺点：在处理突发性请求时，漏桶的容量可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。</p>\n<h3 id=\"计数器算法（Counter-Algorithm）\"><a href=\"#计数器算法（Counter-Algorithm）\" class=\"headerlink\" title=\"计数器算法（Counter Algorithm）\"></a>计数器算法（Counter Algorithm）</h3><p>算法原理：计数器算法简单地统计在指定时间窗口内到达的请求数量，并与预设的阈值进行比较。如果请求数超过阈值，则请求被拒绝。该算法维护一个计数器，每当有请求到达时，计数器加1，并记录请求的时间戳。过了时间窗口后，计数器清零。<br>工作流程：计数器算法使用一个计时器来跟踪时间窗口。每当请求到达时，计数器加1，并检查计数器的值是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。<br>优点：实现简单，对于控制请求速率较为精确。可以根据业务需求灵活地调整时间窗口的大小和阈值。<br>缺点：对于突发性请求的处理能力较差，容易出现请求被拒绝或阻塞的情况。</p>\n<h3 id=\"滑动窗口算法（Sliding-Window-Algorithm）\"><a href=\"#滑动窗口算法（Sliding-Window-Algorithm）\" class=\"headerlink\" title=\"滑动窗口算法（Sliding Window Algorithm）\"></a>滑动窗口算法（Sliding Window Algorithm）</h3><p>算法原理：滑动窗口算法将时间划分为固定大小的窗口，每个窗口内维护请求的计数器。随着时间的推移，旧的窗口被移除，新的窗口被添加。通过统计窗口内的请求数量，并与设定的阈值进行比较，可以实现限流的目的。<br>工作流程：滑动窗口算法维护一个固定大小的窗口队列，其中每个窗口记录了在该时间窗口内到达的请求数量。当请求到达时，首先根据当前时间确定所属的窗口，然后将请求计数器加1，并检查窗口队列中的总请求数是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。<br>优点：对于控制请求速率较为精确，能够平滑地处理突发性请求。可以根据业务需求灵活地调整窗口大小和阈值。<br>缺点：算法的实现相对复杂一些，需要维护时间窗口队列，对于高并发场景可能会增加一定的计算和存储开销。</p>\n<h2 id=\"生产环境中的限流方案\"><a href=\"#生产环境中的限流方案\" class=\"headerlink\" title=\"生产环境中的限流方案\"></a>生产环境中的限流方案</h2><p>生产环境中的限流往往比上述算法的实现更加灵活，这是因为网络环境中的请求并不是均匀分布的：有的系统流量具有周期性，与用户的工作时间或者娱乐时间密切关联，有的请求具有突发性，往往一瞬间就能耗尽整个系统中的所有资源。如果整体来看请求数量的图表(metrics dashboard &#x2F; perf counter)，会发现请求的数量时高时低；如果把图表放大到最小的单位，又能看到图中的折线存在一个个小的尖峰，生产环境中的限流必须要考虑到这类情况。</p>\n<p>与此同时，在真实的生产环境中，用户的请求往往不是单一的，我们需要基于某些单元来对资源的占用进行限制，例如：在多租户系统中基于租户来对资源进行限制，在微服务系统中基于请求方的id 来对资源进行限制，在数据库（存储平台）基于表（或者数据分片）来对资源进行限制。这些实现往往是十分灵活的。另一方面，如果仅仅以某些单元来限制资源的占用，而忽略了系统整体的资源占用情况，这样也会导致系统整体的不可用。相信真正维护过线上服务的同学都曾遇到过请求把单台机器打爆的情况，在这种情况下，我们甚至无法连接到节点上进行恢复性的操作。一个生产环境的限流方案必须要考虑到这些情况。</p>\n<p>下文介绍了一个生产环境中的限流方案，严格来讲是一个基于固定窗口的限流方案，并没有采取听起来更加先进的令牌桶或者漏斗桶的方式，分享出来提供给大家参考。</p>\n<p>首先简单介绍一下限流器的使用背景，这个限流器主要用在单机场景，机器上维护了多个数据表，用户的请求流量往往是对单个表进行读取和写入，所以我们以表为单位进行资源的隔离。我们主要关注以下指标：</p>\n<ul>\n<li>CPU 占用量</li>\n<li>线程时间（单个请求占用线程的时间）</li>\n<li>网络 IO（Bytes per second）</li>\n<li>硬盘读写 IO（包括固态盘和机械盘分别的读写 IO）</li>\n</ul>\n<p>这些基本的指标都是我们要关注的。我们可以通过对这些指标进行统计来分析我们的系统的整体资源消耗情况。</p>\n<h3 id=\"1-如何衡量资源的使用情况？\"><a href=\"#1-如何衡量资源的使用情况？\" class=\"headerlink\" title=\"1. 如何衡量资源的使用情况？\"></a>1. 如何衡量资源的使用情况？</h3><p>为了降低分配内存的开销，我们直接采用一个循环缓冲区，存储过去一定时间内资源的使用情况。这个环形缓存由一定数量的槽构成，每个槽代表着 10ms 内的资源使用情况。对于机器上每一张表，我们都创建一个这样的环形缓存，同时，我们也为整个机器创建一个同样的循环缓冲区，用来记录整台机器的资源使用情况。循环缓冲区的大小可以按需指定，比如存储 5 分钟左右的数据，我们则需要  5<em>60</em>1000&#x2F;10&#x3D;3000 个槽。当请求被执行时，执行器会将资源使用情况报告到环形缓冲区中。其中，IO使用情况在请求执行结束之后报告，CPU 使用情况则是以小于槽的长度的时间间隔来定期报告。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: 环形缓冲区是一种常用的数据结构，具有以下好处：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 高效的内存利用：环形缓冲区可以通过固定大小的缓冲区来存储数据。当缓冲区满时，新的数据可以覆盖最旧的数据。这样可以保持缓冲区的大小不变，从而实现高效的内存利用。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 实时数据处理：环形缓冲区特别适用于实时数据处理场景。由于环形缓冲区可以按照固定的速率接收数据，并且丢弃最旧的数据，因此它可以存储最近的数据，并提供对实时数据的快速访问。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 简单的实现和高效的操作：环形缓冲区可以使用数组或循环链表等数据结构来实现，这些实现相对简单而且高效。读取和写入数据的操作可以在常数时间内完成，因此环形缓冲区可以快速地处理大量数据。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 缓解生产者和消费者之间的速度差异：在并发编程中，生产者和消费者之间的速度差异可能导致数据丢失或阻塞。环形缓冲区提供了一个缓冲区，使得生产者和消费者可以以不同的速度进行工作，而不会发生数据丢失或阻塞。</span><br></pre></td></tr></table></figure>\n\n<p>基于环形缓冲区中各个 bucket 的数据，我们可以计算得到许多观测指标，比如平均资源消耗、p50、p99 等。</p>\n<h3 id=\"2-如何限流？\"><a href=\"#2-如何限流？\" class=\"headerlink\" title=\"2. 如何限流？\"></a>2. 如何限流？</h3><p>为了隔离每个表的资源使用，我们对同一台机器上的每个表都构建这样一个环形缓冲区，用来记录该表可以接受请求的资源占用预算。当某个表的资源使用超出预算时，同时整台机器的资源使用超预算时，我们就对打到这个表的请求进行限流。这种操作允许单个表在机器整体资源仍然可用的情况下适当过载。具体实现如下：</p>\n<p>对于机器上的每个表和机器本身，我们都维护一个以环形缓冲区为基础的资源窗口。窗口大小以毫秒为单位，维护一个最大值和一个最小值。最大值表示当前窗口的资源预算，每执行一次请求，我们都在这个值上减去当前消耗的资源数量。当这个值变为 0 时，表示这张表（或者这台机器）的资源已经完全耗尽。当请求继续被执行时，这个值可能会变为负数，这种情况我们称之为负债情况。最小值则是表示当前表（或者机器）可以有多少的负债。当一个时间窗口过去时，对应的资源又会增加回来到最大值。</p>\n","site":{"data":{}},"excerpt":"<p>随着互联网应用的普及和用户数量的增长，系统面临的并发请求量不断增加。在这种情况下，如果没有适当的限制措施，系统很容易受到过多的请求压力，导致性能下降甚至崩溃。因此，限流算法应运而生，它可以根据系统的处理能力和资源情况，合理地限制请求的数量，以保证系统的稳定和可靠性。</p>","more":"<h2 id=\"常见的限流算法\"><a href=\"#常见的限流算法\" class=\"headerlink\" title=\"常见的限流算法\"></a>常见的限流算法</h2><p>限流算法的基本原理是通过控制请求的速率来限制系统的负载。它可以防止过多的请求同时涌入系统，使系统能够按照自身的处理能力有序地进行工作。常见的限流算法包括漏桶算法和令牌桶算法。</p>\n<h3 id=\"令牌桶算法（Token-Bucket-Algorithm）\"><a href=\"#令牌桶算法（Token-Bucket-Algorithm）\" class=\"headerlink\" title=\"令牌桶算法（Token Bucket Algorithm）\"></a>令牌桶算法（Token Bucket Algorithm）</h3><p>算法原理：令牌桶算法通过维护一个令牌桶来控制请求的速率。令牌桶以固定的速率往桶中放入令牌（代表请求），桶的大小表示令牌的最大数量。当请求到达时，需要从令牌桶中获取一个令牌，如果桶中没有可用令牌，则请求被拒绝。如果有可用令牌，则取走一个令牌，表示请求被接受。<br>工作流程：令牌桶算法使用一个计时器以固定的速率向桶中添加令牌。当请求到达时，首先检查桶中是否有令牌可用。如果有令牌可用，则取走一个令牌，并处理该请求；如果没有令牌可用，则请求被拒绝。无论请求是否被接受，都会消耗一个令牌。<br>优点：令牌桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它还可以适应不同的请求速率和峰值流量。<br>缺点：在处理大量的突发性请求时，令牌桶可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。</p>\n<h3 id=\"漏桶算法（Leaky-Bucket-Algorithm）\"><a href=\"#漏桶算法（Leaky-Bucket-Algorithm）\" class=\"headerlink\" title=\"漏桶算法（Leaky Bucket Algorithm）\"></a>漏桶算法（Leaky Bucket Algorithm）</h3><p>算法原理：漏桶算法以固定的速率从一个漏桶中漏水。当请求到达时，如果桶还有空闲容量，则请求被接受并放入桶中；否则，请求被拒绝。桶中的容量代表系统可以处理的请求数量。如果请求被接受，漏桶以固定的速率漏水，释放出桶中的一个请求，这样就为下一个请求腾出空间。<br>工作流程：漏桶算法使用一个计时器以固定的速率漏水。当请求到达时，首先检查桶中是否有空闲容量。如果有空闲容量，则将请求放入桶中，并开始漏水。如果没有空闲容量，则请求被拒绝。无论请求是否被接受，都会按照固定速率漏水释放请求。<br>优点：漏桶算法可以平滑地限制请求的速率，对于突发性请求可以有较好的处理能力。它可以防止系统被大量请求压垮，提供了一定的请求处理能力保护机制。<br>缺点：在处理突发性请求时，漏桶的容量可能会迅速耗尽，导致一段时间内无法处理请求。此外，算法的实现可能相对复杂。</p>\n<h3 id=\"计数器算法（Counter-Algorithm）\"><a href=\"#计数器算法（Counter-Algorithm）\" class=\"headerlink\" title=\"计数器算法（Counter Algorithm）\"></a>计数器算法（Counter Algorithm）</h3><p>算法原理：计数器算法简单地统计在指定时间窗口内到达的请求数量，并与预设的阈值进行比较。如果请求数超过阈值，则请求被拒绝。该算法维护一个计数器，每当有请求到达时，计数器加1，并记录请求的时间戳。过了时间窗口后，计数器清零。<br>工作流程：计数器算法使用一个计时器来跟踪时间窗口。每当请求到达时，计数器加1，并检查计数器的值是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。<br>优点：实现简单，对于控制请求速率较为精确。可以根据业务需求灵活地调整时间窗口的大小和阈值。<br>缺点：对于突发性请求的处理能力较差，容易出现请求被拒绝或阻塞的情况。</p>\n<h3 id=\"滑动窗口算法（Sliding-Window-Algorithm）\"><a href=\"#滑动窗口算法（Sliding-Window-Algorithm）\" class=\"headerlink\" title=\"滑动窗口算法（Sliding Window Algorithm）\"></a>滑动窗口算法（Sliding Window Algorithm）</h3><p>算法原理：滑动窗口算法将时间划分为固定大小的窗口，每个窗口内维护请求的计数器。随着时间的推移，旧的窗口被移除，新的窗口被添加。通过统计窗口内的请求数量，并与设定的阈值进行比较，可以实现限流的目的。<br>工作流程：滑动窗口算法维护一个固定大小的窗口队列，其中每个窗口记录了在该时间窗口内到达的请求数量。当请求到达时，首先根据当前时间确定所属的窗口，然后将请求计数器加1，并检查窗口队列中的总请求数是否超过了阈值。如果超过了阈值，则请求被拒绝；否则，请求被接受。<br>优点：对于控制请求速率较为精确，能够平滑地处理突发性请求。可以根据业务需求灵活地调整窗口大小和阈值。<br>缺点：算法的实现相对复杂一些，需要维护时间窗口队列，对于高并发场景可能会增加一定的计算和存储开销。</p>\n<h2 id=\"生产环境中的限流方案\"><a href=\"#生产环境中的限流方案\" class=\"headerlink\" title=\"生产环境中的限流方案\"></a>生产环境中的限流方案</h2><p>生产环境中的限流往往比上述算法的实现更加灵活，这是因为网络环境中的请求并不是均匀分布的：有的系统流量具有周期性，与用户的工作时间或者娱乐时间密切关联，有的请求具有突发性，往往一瞬间就能耗尽整个系统中的所有资源。如果整体来看请求数量的图表(metrics dashboard &#x2F; perf counter)，会发现请求的数量时高时低；如果把图表放大到最小的单位，又能看到图中的折线存在一个个小的尖峰，生产环境中的限流必须要考虑到这类情况。</p>\n<p>与此同时，在真实的生产环境中，用户的请求往往不是单一的，我们需要基于某些单元来对资源的占用进行限制，例如：在多租户系统中基于租户来对资源进行限制，在微服务系统中基于请求方的id 来对资源进行限制，在数据库（存储平台）基于表（或者数据分片）来对资源进行限制。这些实现往往是十分灵活的。另一方面，如果仅仅以某些单元来限制资源的占用，而忽略了系统整体的资源占用情况，这样也会导致系统整体的不可用。相信真正维护过线上服务的同学都曾遇到过请求把单台机器打爆的情况，在这种情况下，我们甚至无法连接到节点上进行恢复性的操作。一个生产环境的限流方案必须要考虑到这些情况。</p>\n<p>下文介绍了一个生产环境中的限流方案，严格来讲是一个基于固定窗口的限流方案，并没有采取听起来更加先进的令牌桶或者漏斗桶的方式，分享出来提供给大家参考。</p>\n<p>首先简单介绍一下限流器的使用背景，这个限流器主要用在单机场景，机器上维护了多个数据表，用户的请求流量往往是对单个表进行读取和写入，所以我们以表为单位进行资源的隔离。我们主要关注以下指标：</p>\n<ul>\n<li>CPU 占用量</li>\n<li>线程时间（单个请求占用线程的时间）</li>\n<li>网络 IO（Bytes per second）</li>\n<li>硬盘读写 IO（包括固态盘和机械盘分别的读写 IO）</li>\n</ul>\n<p>这些基本的指标都是我们要关注的。我们可以通过对这些指标进行统计来分析我们的系统的整体资源消耗情况。</p>\n<h3 id=\"1-如何衡量资源的使用情况？\"><a href=\"#1-如何衡量资源的使用情况？\" class=\"headerlink\" title=\"1. 如何衡量资源的使用情况？\"></a>1. 如何衡量资源的使用情况？</h3><p>为了降低分配内存的开销，我们直接采用一个循环缓冲区，存储过去一定时间内资源的使用情况。这个环形缓存由一定数量的槽构成，每个槽代表着 10ms 内的资源使用情况。对于机器上每一张表，我们都创建一个这样的环形缓存，同时，我们也为整个机器创建一个同样的循环缓冲区，用来记录整台机器的资源使用情况。循环缓冲区的大小可以按需指定，比如存储 5 分钟左右的数据，我们则需要  5<em>60</em>1000&#x2F;10&#x3D;3000 个槽。当请求被执行时，执行器会将资源使用情况报告到环形缓冲区中。其中，IO使用情况在请求执行结束之后报告，CPU 使用情况则是以小于槽的长度的时间间隔来定期报告。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Note: 环形缓冲区是一种常用的数据结构，具有以下好处：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 高效的内存利用：环形缓冲区可以通过固定大小的缓冲区来存储数据。当缓冲区满时，新的数据可以覆盖最旧的数据。这样可以保持缓冲区的大小不变，从而实现高效的内存利用。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 实时数据处理：环形缓冲区特别适用于实时数据处理场景。由于环形缓冲区可以按照固定的速率接收数据，并且丢弃最旧的数据，因此它可以存储最近的数据，并提供对实时数据的快速访问。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 简单的实现和高效的操作：环形缓冲区可以使用数组或循环链表等数据结构来实现，这些实现相对简单而且高效。读取和写入数据的操作可以在常数时间内完成，因此环形缓冲区可以快速地处理大量数据。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">-</span> 缓解生产者和消费者之间的速度差异：在并发编程中，生产者和消费者之间的速度差异可能导致数据丢失或阻塞。环形缓冲区提供了一个缓冲区，使得生产者和消费者可以以不同的速度进行工作，而不会发生数据丢失或阻塞。</span><br></pre></td></tr></table></figure>\n\n<p>基于环形缓冲区中各个 bucket 的数据，我们可以计算得到许多观测指标，比如平均资源消耗、p50、p99 等。</p>\n<h3 id=\"2-如何限流？\"><a href=\"#2-如何限流？\" class=\"headerlink\" title=\"2. 如何限流？\"></a>2. 如何限流？</h3><p>为了隔离每个表的资源使用，我们对同一台机器上的每个表都构建这样一个环形缓冲区，用来记录该表可以接受请求的资源占用预算。当某个表的资源使用超出预算时，同时整台机器的资源使用超预算时，我们就对打到这个表的请求进行限流。这种操作允许单个表在机器整体资源仍然可用的情况下适当过载。具体实现如下：</p>\n<p>对于机器上的每个表和机器本身，我们都维护一个以环形缓冲区为基础的资源窗口。窗口大小以毫秒为单位，维护一个最大值和一个最小值。最大值表示当前窗口的资源预算，每执行一次请求，我们都在这个值上减去当前消耗的资源数量。当这个值变为 0 时，表示这张表（或者这台机器）的资源已经完全耗尽。当请求继续被执行时，这个值可能会变为负数，这种情况我们称之为负债情况。最小值则是表示当前表（或者机器）可以有多少的负债。当一个时间窗口过去时，对应的资源又会增加回来到最大值。</p>"},{"title":"查询优化大揭秘 TiDB的查询优化规则有哪些？","_content":"\n根据源码中的`optRuleList`列表来看，TiDB 的逻辑计划优化规则总共有22种，下面是源码：\n\n<!-- more -->\n\n```go\nvar optRuleList = []logicalOptRule{\n\t&gcSubstituter{},\n\t&columnPruner{},\n\t&resultReorder{},\n\t&buildKeySolver{},\n\t&decorrelateSolver{},\n\t&semiJoinRewriter{},\n\t&aggregationEliminator{},\n\t&skewDistinctAggRewriter{},\n\t&projectionEliminator{},\n\t&maxMinEliminator{},\n\t&ppdSolver{},\n\t&outerJoinEliminator{},\n\t&partitionProcessor{},\n\t&collectPredicateColumnsPoint{},\n\t&aggregationPushDownSolver{},\n\t&deriveTopNFromWindow{},\n\t&predicateSimplification{},\n\t&pushDownTopNOptimizer{},\n\t&syncWaitStatsLoadPoint{},\n\t&joinReOrderSolver{},\n\t&columnPruner{}, // column pruning again at last, note it will mess up the results of buildKeySolver\n\t&pushDownSequenceSolver{},\n}\n```\n\n我们现在来一个一个过一遍这些 rule。\n\n1. gcSubstituter。下面是`optimize`方法的注释：\n\n```go\n// optimize try to replace the expression to indexed virtual generate column in where, group by, order by, and field clause\n// so that we can use the index on expression.\n// For example. select a+1 from t order by a+1, with a virtual generate column c as (a+1) and\n// an index on c. We need to replace a+1 with c so that we can use the index on c.\n// See also https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html\n```\n\n简单来说，这个优化规则是将where、group by、order by或者字段子句中的表达式替换成被索引的虚拟生成列，从而能够使用索引来访问。具体例子可以看注释中的解释，或者mysql 中对[生成列索引优化](https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html)的解释。\n\n2. columnPruner。这个方法直接没有注释了，但是也很好理解，其实就是列裁剪，对于一些用不到的列，优化过程中可以直接去除，避免多余的 IO 占用。\n\n3. resultReorder。 结果重排序，对没有排序的结果插入一个排序操作符，用于对结果进行排序。\n\n```go\n/*\nresultReorder reorder query results.\nNOTE. it's not a common rule for all queries, it's specially implemented for a few customers.\n\nResults of some queries are not ordered, for example.\n\n\tcreate table t (a int); insert into t values (1), (2); select a from t;\n\nIn the case above, the result can be `1 2` or `2 1`, which is not ordered.\nThis rule reorders results by modifying or injecting a Sort operator.\n 1. iterate the plan from the root, and ignore all input-order operators (Sel/Proj/Limit);\n 2. when meeting the first non-input-order operator,\n    2.1. if it's a Sort, update it by appending all output columns into its order-by list,\n    2.2. otherwise, inject a new Sort upon this operator.\n*/\n```\n\n4. buildKeySolver。提取索引信息为 schema 设置对应的 key。这个东西应该是之后会用来决定如何使用索引的，以后看到这个内容可以再回来研究一下。\n\n5. decorrelateSolver。用来将 `apply plan` 转换成 `join plan`。这个应该就是关联子查询去关联，说白了就是讲一些能够转换成 join 操作的子查询重写成 join 的形式，好处是可以减少子查询重复执行次数。详细解释可以见https://docs.pingcap.com/zh/tidb/dev/correlated-subquery-optimization\n\n```markdown\n\"Apply plan\" 是一个数据库查询优化和执行的概念，用于在查询执行过程中使用嵌套循环连接或半连接操作。\n\n在关系数据库中，当执行包含连接操作的查询时，优化器可以选择使用不同的连接算法来获取结果。一种常见的连接算法是嵌套循环连接（Nested Loop Join），它基于嵌套循环的方式逐个比较连接条件并获取匹配的行。\n\n\"Apply plan\" 是一种特殊的嵌套循环连接算法，它在连接操作中使用了子查询或者外部查询的结果。具体来说，\"Apply plan\" 在每次迭代连接的过程中，将外部查询的结果作为输入，并将其应用于嵌套循环连接中的内部查询。这样可以在每次迭代中有效地使用外部查询的结果来过滤和匹配内部查询的行。\n\n\"Apply plan\" 在执行连接操作时具有一些优势，例如：\n\n1. 减少连接操作的数据量：通过在每次迭代中使用外部查询的结果进行过滤，可以减少连接操作涉及的数据量，从而提高查询性能和效率。\n\n2. 优化连接操作的执行顺序：\"Apply plan\" 可以改变连接操作的执行顺序，先执行外部查询，然后在每次迭代中应用内部查询，这样可以根据数据的特点和选择性来优化连接操作的执行计划。\n\n3. 支持相关子查询：\"Apply plan\" 在连接操作中使用了子查询的结果，这样可以支持相关子查询（Correlated Subquery）的语义和语法。\n\n需要注意的是，\"Apply plan\" 并不是适用于所有情况的最佳连接算法。在实际应用中，优化器会根据查询的复杂性、数据分布、索引情况等因素综合考虑，选择最适合的连接算法来执行查询。\n\n--------\n\n\"Join plan\" 是数据库查询优化和执行中的一个概念，用于指代执行连接操作时所采用的计划或策略。\n\n在关系数据库中，\"join\" 是指将两个或多个表基于某个关联条件进行连接操作，以获取符合条件的结果集。在执行连接操作时，优化器需要选择适当的连接算法和连接顺序，以获得最佳的查询性能。\n\n\"Join plan\" 描述了执行连接操作时所采用的具体计划或策略，包括以下方面：\n\n1. 连接算法选择：根据查询条件、表的大小、索引情况等因素，优化器会选择适合的连接算法，例如嵌套循环连接、哈希连接、排序合并连接等。每种连接算法都有其适用的场景和性能特点。\n\n2. 连接顺序决策：当连接操作涉及多个表时，优化器需要确定连接的顺序。连接顺序的选择可以影响查询性能，例如选择连接顺序可以最小化中间结果集的大小，减少连接操作的数据量。\n\n3. 连接类型决策：连接操作可以有不同的连接类型，如内连接、左连接、右连接、全外连接等。\"Join plan\" 包括选择适当的连接类型以满足查询需求。\n\n4. 索引和优化技术：优化器会考虑现有的索引和其他优化技术，以提高连接操作的性能。它可能选择使用索引来加速连接操作，并利用统计信息和查询历史来评估和选择最佳的连接计划。\n\n总之，“Join plan” 是在查询优化过程中确定连接操作的具体计划或策略。优化器通过考虑连接算法、连接顺序、连接类型以及索引和优化技术等因素，选择最佳的连接计划，以实现高效的查询执行。\n```\n\n6. semiJoinRewriter。半连接重写。\n\n```markdown\n\"semiJoin\"（半连接）是数据库查询中的一种操作，用于判断一个表中的数据是否存在于另一个表中。\n\n在半连接操作中，查询优化器会选择一个表作为左表（left table），另一个表作为右表（right table）。然后，它会根据两个表之间的连接条件，筛选出左表中符合条件的行，并检查这些行是否存在于右表中。\n\n半连接的目的是提取左表中满足连接条件的行，而不关心右表的具体数据。它通常用于优化查询性能，减少数据传输和处理的开销。\n\n半连接操作可以有不同的实现方式，其中一种常见的实现方式是使用存在谓词（EXISTS predicate）。该谓词会在连接操作中使用子查询来判断左表的行是否存在于右表中，返回一个布尔值作为结果。\n\n举个例子，假设有两个表 A 和 B，需要判断表 A 中的某些行是否在表 B 中存在。使用半连接操作，可以编写类似下面的查询：\n\n    ```sql\n    SELECT *\n    FROM A\n    WHERE EXISTS (\n    SELECT 1\n    FROM B\n    WHERE A.id = B.id\n    );\n    ```\n\n上述查询中，子查询会根据连接条件 A.id = B.id 来检查表 A 的行是否存在于表 B 中。如果存在匹配的行，则返回结果。\n\n通过使用半连接操作，可以有效地筛选出左表中存在于右表中的行，从而减少数据量和查询的开销，提高查询性能。\n```\n\n7. aggregationEliminator。消除一些无意义的聚合函数，下面是方法的注释，可以参考其中的例子来理解。\n\n```go\n// tryToEliminateAggregation will eliminate aggregation grouped by unique key.\n// e.g. select min(b) from t group by a. If a is a unique key, then this sql is equal to `select b from t group by a`.\n// For count(expr), sum(expr), avg(expr), count(distinct expr, [expr...]) we may need to rewrite the expr. Details are shown below.\n// If we can eliminate agg successful, we return a projection. Else we return a nil pointer.\n```\n\n8. skewDistinctAggRewriter。将group distinct 聚集函数重写成两级聚合。可以参考下面注释中的例子来理解。这种优化是为了优化在group key数据偏移的情况下缓解数据偏移。这个规则会被应用于满足以下条件的 query：\n    1. 至少有一个 group by的语句\n    2. 有且仅有一个 distinct aggregate 函数（仅限于 count、avg 和 sum）\n\n```go\n// skewDistinctAggRewriter will rewrite group distinct aggregate into 2 level aggregates, e.g.:\n//\n//\tselect S_NATIONKEY as s, count(S_SUPPKEY), count(distinct S_NAME) from supplier group by s;\n//\n// will be rewritten to\n//\n//\tselect S_NATIONKEY as s, sum(c), count(S_NAME) from (\n//\t  select S_NATIONKEY, S_NAME, count(S_SUPPKEY) c from supplier group by S_NATIONKEY, S_NAME\n//\t) as T group by s;\n//\n// If the group key is highly skewed and the distinct key has large number of distinct values\n// (a.k.a. high cardinality), the query execution will be slow. This rule may help to ease the\n// skew issue.\n//\n// The rewrite rule only applies to query that satisfies:\n// - The aggregate has at least 1 group by column (the group key can be columns or expressions)\n// - The aggregate has 1 and only 1 distinct aggregate function (limited to count, avg, sum)\n//\n// This rule is disabled by default. Use tidb_opt_skew_distinct_agg to enable the rule.\n```\n\n9. projectionEliminator。消除逻辑计划中多余的投影。\n\n10. maxMinEliminator。消除最大值最小值函数。下面是注释，可以看一下其中的例子：\n\n```go\n// maxMinEliminator tries to eliminate max/min aggregate function.\n// For SQL like `select max(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id desc limit 1 where id is not null) t;`.\n// For SQL like `select min(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id limit 1 where id is not null) t;`.\n// For SQL like `select max(id), min(id) from t;`, we could optimize it to the cartesianJoin result of the two queries above if `id` has an index.\n```\n\n11. ppdSolver。这个名字有意思，其实是`PredicatePushDown`的缩写。 这个是用来执行谓词下推的规则。\n\n```go\n// PredicatePushDown pushes down the predicates in the where/on/having clauses as deeply as possible.\n// It will accept a predicate that is an expression slice, and return the expressions that can't be pushed.\n// Because it might change the root if the having clause exists, we need to return a plan that represents a new root.\n\n谓词下推（Predicate Pushdown）是数据库查询优化的一种技术，它通过将查询条件下推到数据源（如表、索引）级别进行处理，减少数据的读取和处理量，从而提高查询性能。\n\n在传统的查询执行过程中，查询优化器通常会将查询条件应用于获取结果集之后进行筛选。这意味着数据库系统会读取所有的数据记录，并在获取结果集后再应用查询条件进行过滤，导致数据的读取和处理开销较大。\n\n而谓词下推的思想是，在查询过程中尽早地将查询条件下推到数据源级别，即在读取数据之前应用查询条件进行过滤。这样可以减少读取和处理的数据量，提高查询性能。\n\n通过谓词下推，数据库系统可以在数据源级别利用索引、统计信息和其他优化技术来加速查询过程。它可以有效地削减不必要的数据读取和处理，减少中间结果集的大小，并在查询过程中提前过滤掉不符合查询条件的数据。\n\n谓词下推的具体操作可以包括以下方面：\n\n1. 下推过滤条件：将查询条件应用于索引扫描或表扫描的过程中，尽早地过滤掉不满足条件的数据。\n\n2. 下推投影操作：根据查询需要，将字段选择（Projection）操作下推到数据源级别，减少返回结果的列数。\n\n3. 下推连接条件：对连接操作进行优化，将连接条件下推到连接操作的数据源，减少连接的数据量。\n\n谓词下推在数据库查询优化中起着重要的作用，它可以显著提高查询性能，减少数据读取和处理的开销。通过在数据源级别应用查询条件，可以最大程度地减少不必要的数据操作，加速查询过程并降低系统资源的消耗。\n```\n\n12. outerJoinEliminator。消除外连接。主要有以下两个规则：\n    1. 外连接消除：例如左外连接，如果父查询只使用左表的列和右表（内部表）的连接键（唯一键），则可以消除左外连接。\n    2. 使用不考虑重复的聚合函数进行外连接消除：例如左外连接。如果父查询只使用带有 'distinct' 标签的左表列，则可以消除左外连接。\n\n下面是代码中的注释：\n```\n// tryToEliminateOuterJoin will eliminate outer join plan base on the following rules\n//  1. outer join elimination: For example left outer join, if the parent only use the\n//     columns from left table and the join key of right table(the inner table) is a unique\n//     key of the right table. the left outer join can be eliminated.\n//  2. outer join elimination with duplicate agnostic aggregate functions: For example left outer join.\n//     If the parent only use the columns from left table with 'distinct' label. The left outer join can\n//     be eliminated.\n```\n\n13. partitionProcessor。对分区语句进行重写。主要是做固定分区修剪。下面是注释内容：\n\n```go\n// partitionProcessor rewrites the ast for table partition.\n// Used by static partition prune mode.\n/*\n// create table t (id int) partition by range (id)\n//   (partition p1 values less than (10),\n//    partition p2 values less than (20),\n//    partition p3 values less than (30))\n//\n// select * from t is equal to\n// select * from (union all\n//      select * from p1 where id < 10\n//      select * from p2 where id < 20\n//      select * from p3 where id < 30)\n*/\n// partitionProcessor is here because it's easier to prune partition after predicate push down.\n```\n这里提到在谓词下推之后做分区修剪会更加简单。\n\n14. collectPredicateColumnsPoint。这个方法没有一句注释。不过这个方法有几个比较重要的子方法，下面是这几个子方法的注释：(TODO)\n```\n// CollectColumnStatsUsage collects column stats usage from logical plan.\n// predicate indicates whether to collect predicate columns and histNeeded indicates whether to collect histogram-needed columns.\n// The first return value is predicate columns(nil if predicate is false) and the second return value is histogram-needed columns(nil if histNeeded is false).\n\n\n// collectSyncIndices will collect the indices which includes following conditions:\n// 1. the indices contained the any one of histNeededColumns, eg: histNeededColumns contained A,B columns, and idx_a is\n// composed up by A column, then we thought the idx_a should be collected\n// 2. The stats condition of idx_a can't meet IsFullLoad, which means its stats was evicted previously\n```\n\n15. aggregationPushDownSolver。聚集函数下推，下面是重要方法的注释：\n\n```go\n// tryToPushDownAgg tries to push down an aggregate function into a join path. If all aggFuncs are first row, we won't\n// process it temporarily. If not, We will add additional group by columns and first row functions. We make a new aggregation operator.\n// If the pushed aggregation is grouped by unique key, it's no need to push it down.\n```\n\n16. deriveTopNFromWindow。 从窗口函数中推导 TopN或Limit。按照官方文档中的例子，其实就是通过改写带有窗口函数的语句，减少无意义的排序操作。从下面的例子其实很容易理解这个过程：\n```\n// 改写前\nSELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t) dt WHERE rownumber <= 3\n\n// 改写后\nWITH t_topN AS (SELECT a FROM t1 ORDER BY a LIMIT 3) SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t_topN) dt WHERE rownumber <= 3\n```\n可以看出，进行改写之后，原语句中对全表的 sort 操作被简化成一个 sort + limit 操作，极大地节省了资源。\n\n17. predicateSimplification。谓词简化，其实就是对一些谓词语句进行简化。\n\n18. pushDownTopNOptimizer。这个方法将下推 topN或者 limit操作。 \n\n上述的几个下推方法其实都是类似的思想，讲一些计算操作或者条件判断尽可能下推到距离数据源近的地方，尽早完成数据的过滤操作，从而减少数据传输和计算的开销。\n\n19. syncWaitStatsLoadPoint。同步等待数据加载。\n\n20. joinReOrderSolver。递归采集 join 组，然后对每个组执行 join 重排序算法。\n\n21. columnPruner。最后再进行一次列裁剪，因为前面的列裁剪可能会被`buildKeySolver`弄乱。\n\n22. pushDownSequenceSolver。递归执行下推序列。\n\n## Reference\n[1] https://docs.pingcap.com/zh/tidb/dev/sql-logical-optimization","source":"_posts/tidb/opt_rule.md","raw":"---\ntitle: \"查询优化大揭秘 TiDB的查询优化规则有哪些？\"\ntags: \"TiDB\"\n---\n\n根据源码中的`optRuleList`列表来看，TiDB 的逻辑计划优化规则总共有22种，下面是源码：\n\n<!-- more -->\n\n```go\nvar optRuleList = []logicalOptRule{\n\t&gcSubstituter{},\n\t&columnPruner{},\n\t&resultReorder{},\n\t&buildKeySolver{},\n\t&decorrelateSolver{},\n\t&semiJoinRewriter{},\n\t&aggregationEliminator{},\n\t&skewDistinctAggRewriter{},\n\t&projectionEliminator{},\n\t&maxMinEliminator{},\n\t&ppdSolver{},\n\t&outerJoinEliminator{},\n\t&partitionProcessor{},\n\t&collectPredicateColumnsPoint{},\n\t&aggregationPushDownSolver{},\n\t&deriveTopNFromWindow{},\n\t&predicateSimplification{},\n\t&pushDownTopNOptimizer{},\n\t&syncWaitStatsLoadPoint{},\n\t&joinReOrderSolver{},\n\t&columnPruner{}, // column pruning again at last, note it will mess up the results of buildKeySolver\n\t&pushDownSequenceSolver{},\n}\n```\n\n我们现在来一个一个过一遍这些 rule。\n\n1. gcSubstituter。下面是`optimize`方法的注释：\n\n```go\n// optimize try to replace the expression to indexed virtual generate column in where, group by, order by, and field clause\n// so that we can use the index on expression.\n// For example. select a+1 from t order by a+1, with a virtual generate column c as (a+1) and\n// an index on c. We need to replace a+1 with c so that we can use the index on c.\n// See also https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html\n```\n\n简单来说，这个优化规则是将where、group by、order by或者字段子句中的表达式替换成被索引的虚拟生成列，从而能够使用索引来访问。具体例子可以看注释中的解释，或者mysql 中对[生成列索引优化](https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html)的解释。\n\n2. columnPruner。这个方法直接没有注释了，但是也很好理解，其实就是列裁剪，对于一些用不到的列，优化过程中可以直接去除，避免多余的 IO 占用。\n\n3. resultReorder。 结果重排序，对没有排序的结果插入一个排序操作符，用于对结果进行排序。\n\n```go\n/*\nresultReorder reorder query results.\nNOTE. it's not a common rule for all queries, it's specially implemented for a few customers.\n\nResults of some queries are not ordered, for example.\n\n\tcreate table t (a int); insert into t values (1), (2); select a from t;\n\nIn the case above, the result can be `1 2` or `2 1`, which is not ordered.\nThis rule reorders results by modifying or injecting a Sort operator.\n 1. iterate the plan from the root, and ignore all input-order operators (Sel/Proj/Limit);\n 2. when meeting the first non-input-order operator,\n    2.1. if it's a Sort, update it by appending all output columns into its order-by list,\n    2.2. otherwise, inject a new Sort upon this operator.\n*/\n```\n\n4. buildKeySolver。提取索引信息为 schema 设置对应的 key。这个东西应该是之后会用来决定如何使用索引的，以后看到这个内容可以再回来研究一下。\n\n5. decorrelateSolver。用来将 `apply plan` 转换成 `join plan`。这个应该就是关联子查询去关联，说白了就是讲一些能够转换成 join 操作的子查询重写成 join 的形式，好处是可以减少子查询重复执行次数。详细解释可以见https://docs.pingcap.com/zh/tidb/dev/correlated-subquery-optimization\n\n```markdown\n\"Apply plan\" 是一个数据库查询优化和执行的概念，用于在查询执行过程中使用嵌套循环连接或半连接操作。\n\n在关系数据库中，当执行包含连接操作的查询时，优化器可以选择使用不同的连接算法来获取结果。一种常见的连接算法是嵌套循环连接（Nested Loop Join），它基于嵌套循环的方式逐个比较连接条件并获取匹配的行。\n\n\"Apply plan\" 是一种特殊的嵌套循环连接算法，它在连接操作中使用了子查询或者外部查询的结果。具体来说，\"Apply plan\" 在每次迭代连接的过程中，将外部查询的结果作为输入，并将其应用于嵌套循环连接中的内部查询。这样可以在每次迭代中有效地使用外部查询的结果来过滤和匹配内部查询的行。\n\n\"Apply plan\" 在执行连接操作时具有一些优势，例如：\n\n1. 减少连接操作的数据量：通过在每次迭代中使用外部查询的结果进行过滤，可以减少连接操作涉及的数据量，从而提高查询性能和效率。\n\n2. 优化连接操作的执行顺序：\"Apply plan\" 可以改变连接操作的执行顺序，先执行外部查询，然后在每次迭代中应用内部查询，这样可以根据数据的特点和选择性来优化连接操作的执行计划。\n\n3. 支持相关子查询：\"Apply plan\" 在连接操作中使用了子查询的结果，这样可以支持相关子查询（Correlated Subquery）的语义和语法。\n\n需要注意的是，\"Apply plan\" 并不是适用于所有情况的最佳连接算法。在实际应用中，优化器会根据查询的复杂性、数据分布、索引情况等因素综合考虑，选择最适合的连接算法来执行查询。\n\n--------\n\n\"Join plan\" 是数据库查询优化和执行中的一个概念，用于指代执行连接操作时所采用的计划或策略。\n\n在关系数据库中，\"join\" 是指将两个或多个表基于某个关联条件进行连接操作，以获取符合条件的结果集。在执行连接操作时，优化器需要选择适当的连接算法和连接顺序，以获得最佳的查询性能。\n\n\"Join plan\" 描述了执行连接操作时所采用的具体计划或策略，包括以下方面：\n\n1. 连接算法选择：根据查询条件、表的大小、索引情况等因素，优化器会选择适合的连接算法，例如嵌套循环连接、哈希连接、排序合并连接等。每种连接算法都有其适用的场景和性能特点。\n\n2. 连接顺序决策：当连接操作涉及多个表时，优化器需要确定连接的顺序。连接顺序的选择可以影响查询性能，例如选择连接顺序可以最小化中间结果集的大小，减少连接操作的数据量。\n\n3. 连接类型决策：连接操作可以有不同的连接类型，如内连接、左连接、右连接、全外连接等。\"Join plan\" 包括选择适当的连接类型以满足查询需求。\n\n4. 索引和优化技术：优化器会考虑现有的索引和其他优化技术，以提高连接操作的性能。它可能选择使用索引来加速连接操作，并利用统计信息和查询历史来评估和选择最佳的连接计划。\n\n总之，“Join plan” 是在查询优化过程中确定连接操作的具体计划或策略。优化器通过考虑连接算法、连接顺序、连接类型以及索引和优化技术等因素，选择最佳的连接计划，以实现高效的查询执行。\n```\n\n6. semiJoinRewriter。半连接重写。\n\n```markdown\n\"semiJoin\"（半连接）是数据库查询中的一种操作，用于判断一个表中的数据是否存在于另一个表中。\n\n在半连接操作中，查询优化器会选择一个表作为左表（left table），另一个表作为右表（right table）。然后，它会根据两个表之间的连接条件，筛选出左表中符合条件的行，并检查这些行是否存在于右表中。\n\n半连接的目的是提取左表中满足连接条件的行，而不关心右表的具体数据。它通常用于优化查询性能，减少数据传输和处理的开销。\n\n半连接操作可以有不同的实现方式，其中一种常见的实现方式是使用存在谓词（EXISTS predicate）。该谓词会在连接操作中使用子查询来判断左表的行是否存在于右表中，返回一个布尔值作为结果。\n\n举个例子，假设有两个表 A 和 B，需要判断表 A 中的某些行是否在表 B 中存在。使用半连接操作，可以编写类似下面的查询：\n\n    ```sql\n    SELECT *\n    FROM A\n    WHERE EXISTS (\n    SELECT 1\n    FROM B\n    WHERE A.id = B.id\n    );\n    ```\n\n上述查询中，子查询会根据连接条件 A.id = B.id 来检查表 A 的行是否存在于表 B 中。如果存在匹配的行，则返回结果。\n\n通过使用半连接操作，可以有效地筛选出左表中存在于右表中的行，从而减少数据量和查询的开销，提高查询性能。\n```\n\n7. aggregationEliminator。消除一些无意义的聚合函数，下面是方法的注释，可以参考其中的例子来理解。\n\n```go\n// tryToEliminateAggregation will eliminate aggregation grouped by unique key.\n// e.g. select min(b) from t group by a. If a is a unique key, then this sql is equal to `select b from t group by a`.\n// For count(expr), sum(expr), avg(expr), count(distinct expr, [expr...]) we may need to rewrite the expr. Details are shown below.\n// If we can eliminate agg successful, we return a projection. Else we return a nil pointer.\n```\n\n8. skewDistinctAggRewriter。将group distinct 聚集函数重写成两级聚合。可以参考下面注释中的例子来理解。这种优化是为了优化在group key数据偏移的情况下缓解数据偏移。这个规则会被应用于满足以下条件的 query：\n    1. 至少有一个 group by的语句\n    2. 有且仅有一个 distinct aggregate 函数（仅限于 count、avg 和 sum）\n\n```go\n// skewDistinctAggRewriter will rewrite group distinct aggregate into 2 level aggregates, e.g.:\n//\n//\tselect S_NATIONKEY as s, count(S_SUPPKEY), count(distinct S_NAME) from supplier group by s;\n//\n// will be rewritten to\n//\n//\tselect S_NATIONKEY as s, sum(c), count(S_NAME) from (\n//\t  select S_NATIONKEY, S_NAME, count(S_SUPPKEY) c from supplier group by S_NATIONKEY, S_NAME\n//\t) as T group by s;\n//\n// If the group key is highly skewed and the distinct key has large number of distinct values\n// (a.k.a. high cardinality), the query execution will be slow. This rule may help to ease the\n// skew issue.\n//\n// The rewrite rule only applies to query that satisfies:\n// - The aggregate has at least 1 group by column (the group key can be columns or expressions)\n// - The aggregate has 1 and only 1 distinct aggregate function (limited to count, avg, sum)\n//\n// This rule is disabled by default. Use tidb_opt_skew_distinct_agg to enable the rule.\n```\n\n9. projectionEliminator。消除逻辑计划中多余的投影。\n\n10. maxMinEliminator。消除最大值最小值函数。下面是注释，可以看一下其中的例子：\n\n```go\n// maxMinEliminator tries to eliminate max/min aggregate function.\n// For SQL like `select max(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id desc limit 1 where id is not null) t;`.\n// For SQL like `select min(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id limit 1 where id is not null) t;`.\n// For SQL like `select max(id), min(id) from t;`, we could optimize it to the cartesianJoin result of the two queries above if `id` has an index.\n```\n\n11. ppdSolver。这个名字有意思，其实是`PredicatePushDown`的缩写。 这个是用来执行谓词下推的规则。\n\n```go\n// PredicatePushDown pushes down the predicates in the where/on/having clauses as deeply as possible.\n// It will accept a predicate that is an expression slice, and return the expressions that can't be pushed.\n// Because it might change the root if the having clause exists, we need to return a plan that represents a new root.\n\n谓词下推（Predicate Pushdown）是数据库查询优化的一种技术，它通过将查询条件下推到数据源（如表、索引）级别进行处理，减少数据的读取和处理量，从而提高查询性能。\n\n在传统的查询执行过程中，查询优化器通常会将查询条件应用于获取结果集之后进行筛选。这意味着数据库系统会读取所有的数据记录，并在获取结果集后再应用查询条件进行过滤，导致数据的读取和处理开销较大。\n\n而谓词下推的思想是，在查询过程中尽早地将查询条件下推到数据源级别，即在读取数据之前应用查询条件进行过滤。这样可以减少读取和处理的数据量，提高查询性能。\n\n通过谓词下推，数据库系统可以在数据源级别利用索引、统计信息和其他优化技术来加速查询过程。它可以有效地削减不必要的数据读取和处理，减少中间结果集的大小，并在查询过程中提前过滤掉不符合查询条件的数据。\n\n谓词下推的具体操作可以包括以下方面：\n\n1. 下推过滤条件：将查询条件应用于索引扫描或表扫描的过程中，尽早地过滤掉不满足条件的数据。\n\n2. 下推投影操作：根据查询需要，将字段选择（Projection）操作下推到数据源级别，减少返回结果的列数。\n\n3. 下推连接条件：对连接操作进行优化，将连接条件下推到连接操作的数据源，减少连接的数据量。\n\n谓词下推在数据库查询优化中起着重要的作用，它可以显著提高查询性能，减少数据读取和处理的开销。通过在数据源级别应用查询条件，可以最大程度地减少不必要的数据操作，加速查询过程并降低系统资源的消耗。\n```\n\n12. outerJoinEliminator。消除外连接。主要有以下两个规则：\n    1. 外连接消除：例如左外连接，如果父查询只使用左表的列和右表（内部表）的连接键（唯一键），则可以消除左外连接。\n    2. 使用不考虑重复的聚合函数进行外连接消除：例如左外连接。如果父查询只使用带有 'distinct' 标签的左表列，则可以消除左外连接。\n\n下面是代码中的注释：\n```\n// tryToEliminateOuterJoin will eliminate outer join plan base on the following rules\n//  1. outer join elimination: For example left outer join, if the parent only use the\n//     columns from left table and the join key of right table(the inner table) is a unique\n//     key of the right table. the left outer join can be eliminated.\n//  2. outer join elimination with duplicate agnostic aggregate functions: For example left outer join.\n//     If the parent only use the columns from left table with 'distinct' label. The left outer join can\n//     be eliminated.\n```\n\n13. partitionProcessor。对分区语句进行重写。主要是做固定分区修剪。下面是注释内容：\n\n```go\n// partitionProcessor rewrites the ast for table partition.\n// Used by static partition prune mode.\n/*\n// create table t (id int) partition by range (id)\n//   (partition p1 values less than (10),\n//    partition p2 values less than (20),\n//    partition p3 values less than (30))\n//\n// select * from t is equal to\n// select * from (union all\n//      select * from p1 where id < 10\n//      select * from p2 where id < 20\n//      select * from p3 where id < 30)\n*/\n// partitionProcessor is here because it's easier to prune partition after predicate push down.\n```\n这里提到在谓词下推之后做分区修剪会更加简单。\n\n14. collectPredicateColumnsPoint。这个方法没有一句注释。不过这个方法有几个比较重要的子方法，下面是这几个子方法的注释：(TODO)\n```\n// CollectColumnStatsUsage collects column stats usage from logical plan.\n// predicate indicates whether to collect predicate columns and histNeeded indicates whether to collect histogram-needed columns.\n// The first return value is predicate columns(nil if predicate is false) and the second return value is histogram-needed columns(nil if histNeeded is false).\n\n\n// collectSyncIndices will collect the indices which includes following conditions:\n// 1. the indices contained the any one of histNeededColumns, eg: histNeededColumns contained A,B columns, and idx_a is\n// composed up by A column, then we thought the idx_a should be collected\n// 2. The stats condition of idx_a can't meet IsFullLoad, which means its stats was evicted previously\n```\n\n15. aggregationPushDownSolver。聚集函数下推，下面是重要方法的注释：\n\n```go\n// tryToPushDownAgg tries to push down an aggregate function into a join path. If all aggFuncs are first row, we won't\n// process it temporarily. If not, We will add additional group by columns and first row functions. We make a new aggregation operator.\n// If the pushed aggregation is grouped by unique key, it's no need to push it down.\n```\n\n16. deriveTopNFromWindow。 从窗口函数中推导 TopN或Limit。按照官方文档中的例子，其实就是通过改写带有窗口函数的语句，减少无意义的排序操作。从下面的例子其实很容易理解这个过程：\n```\n// 改写前\nSELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t) dt WHERE rownumber <= 3\n\n// 改写后\nWITH t_topN AS (SELECT a FROM t1 ORDER BY a LIMIT 3) SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t_topN) dt WHERE rownumber <= 3\n```\n可以看出，进行改写之后，原语句中对全表的 sort 操作被简化成一个 sort + limit 操作，极大地节省了资源。\n\n17. predicateSimplification。谓词简化，其实就是对一些谓词语句进行简化。\n\n18. pushDownTopNOptimizer。这个方法将下推 topN或者 limit操作。 \n\n上述的几个下推方法其实都是类似的思想，讲一些计算操作或者条件判断尽可能下推到距离数据源近的地方，尽早完成数据的过滤操作，从而减少数据传输和计算的开销。\n\n19. syncWaitStatsLoadPoint。同步等待数据加载。\n\n20. joinReOrderSolver。递归采集 join 组，然后对每个组执行 join 重排序算法。\n\n21. columnPruner。最后再进行一次列裁剪，因为前面的列裁剪可能会被`buildKeySolver`弄乱。\n\n22. pushDownSequenceSolver。递归执行下推序列。\n\n## Reference\n[1] https://docs.pingcap.com/zh/tidb/dev/sql-logical-optimization","slug":"tidb/opt_rule","published":1,"date":"2023-07-30T06:11:37.246Z","updated":"2023-07-30T06:11:37.247Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6iz000t1ts17qy22tco","content":"<p>根据源码中的<code>optRuleList</code>列表来看，TiDB 的逻辑计划优化规则总共有22种，下面是源码：</p>\n<span id=\"more\"></span>\n\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> optRuleList = []logicalOptRule&#123;</span><br><span class=\"line\">\t&amp;gcSubstituter&#123;&#125;,</span><br><span class=\"line\">\t&amp;columnPruner&#123;&#125;,</span><br><span class=\"line\">\t&amp;resultReorder&#123;&#125;,</span><br><span class=\"line\">\t&amp;buildKeySolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;decorrelateSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;semiJoinRewriter&#123;&#125;,</span><br><span class=\"line\">\t&amp;aggregationEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;skewDistinctAggRewriter&#123;&#125;,</span><br><span class=\"line\">\t&amp;projectionEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;maxMinEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;ppdSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;outerJoinEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;partitionProcessor&#123;&#125;,</span><br><span class=\"line\">\t&amp;collectPredicateColumnsPoint&#123;&#125;,</span><br><span class=\"line\">\t&amp;aggregationPushDownSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;deriveTopNFromWindow&#123;&#125;,</span><br><span class=\"line\">\t&amp;predicateSimplification&#123;&#125;,</span><br><span class=\"line\">\t&amp;pushDownTopNOptimizer&#123;&#125;,</span><br><span class=\"line\">\t&amp;syncWaitStatsLoadPoint&#123;&#125;,</span><br><span class=\"line\">\t&amp;joinReOrderSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;columnPruner&#123;&#125;, <span class=\"comment\">// column pruning again at last, note it will mess up the results of buildKeySolver</span></span><br><span class=\"line\">\t&amp;pushDownSequenceSolver&#123;&#125;,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们现在来一个一个过一遍这些 rule。</p>\n<ol>\n<li>gcSubstituter。下面是<code>optimize</code>方法的注释：</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// optimize try to replace the expression to indexed virtual generate column in where, group by, order by, and field clause</span></span><br><span class=\"line\"><span class=\"comment\">// so that we can use the index on expression.</span></span><br><span class=\"line\"><span class=\"comment\">// For example. select a+1 from t order by a+1, with a virtual generate column c as (a+1) and</span></span><br><span class=\"line\"><span class=\"comment\">// an index on c. We need to replace a+1 with c so that we can use the index on c.</span></span><br><span class=\"line\"><span class=\"comment\">// See also https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html</span></span><br></pre></td></tr></table></figure>\n\n<p>简单来说，这个优化规则是将where、group by、order by或者字段子句中的表达式替换成被索引的虚拟生成列，从而能够使用索引来访问。具体例子可以看注释中的解释，或者mysql 中对<a href=\"https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html\">生成列索引优化</a>的解释。</p>\n<ol start=\"2\">\n<li><p>columnPruner。这个方法直接没有注释了，但是也很好理解，其实就是列裁剪，对于一些用不到的列，优化过程中可以直接去除，避免多余的 IO 占用。</p>\n</li>\n<li><p>resultReorder。 结果重排序，对没有排序的结果插入一个排序操作符，用于对结果进行排序。</p>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">resultReorder reorder query results.</span></span><br><span class=\"line\"><span class=\"comment\">NOTE. it&#x27;s not a common rule for all queries, it&#x27;s specially implemented for a few customers.</span></span><br><span class=\"line\"><span class=\"comment\"></span></span><br><span class=\"line\"><span class=\"comment\">Results of some queries are not ordered, for example.</span></span><br><span class=\"line\"><span class=\"comment\"></span></span><br><span class=\"line\"><span class=\"comment\">\tcreate table t (a int); insert into t values (1), (2); select a from t;</span></span><br><span class=\"line\"><span class=\"comment\"></span></span><br><span class=\"line\"><span class=\"comment\">In the case above, the result can be `1 2` or `2 1`, which is not ordered.</span></span><br><span class=\"line\"><span class=\"comment\">This rule reorders results by modifying or injecting a Sort operator.</span></span><br><span class=\"line\"><span class=\"comment\"> 1. iterate the plan from the root, and ignore all input-order operators (Sel/Proj/Limit);</span></span><br><span class=\"line\"><span class=\"comment\"> 2. when meeting the first non-input-order operator,</span></span><br><span class=\"line\"><span class=\"comment\">    2.1. if it&#x27;s a Sort, update it by appending all output columns into its order-by list,</span></span><br><span class=\"line\"><span class=\"comment\">    2.2. otherwise, inject a new Sort upon this operator.</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li><p>buildKeySolver。提取索引信息为 schema 设置对应的 key。这个东西应该是之后会用来决定如何使用索引的，以后看到这个内容可以再回来研究一下。</p>\n</li>\n<li><p>decorrelateSolver。用来将 <code>apply plan</code> 转换成 <code>join plan</code>。这个应该就是关联子查询去关联，说白了就是讲一些能够转换成 join 操作的子查询重写成 join 的形式，好处是可以减少子查询重复执行次数。详细解释可以见<a href=\"https://docs.pingcap.com/zh/tidb/dev/correlated-subquery-optimization\">https://docs.pingcap.com/zh/tidb/dev/correlated-subquery-optimization</a></p>\n</li>\n</ol>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;Apply plan&quot; 是一个数据库查询优化和执行的概念，用于在查询执行过程中使用嵌套循环连接或半连接操作。</span><br><span class=\"line\"></span><br><span class=\"line\">在关系数据库中，当执行包含连接操作的查询时，优化器可以选择使用不同的连接算法来获取结果。一种常见的连接算法是嵌套循环连接（Nested Loop Join），它基于嵌套循环的方式逐个比较连接条件并获取匹配的行。</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Apply plan&quot; 是一种特殊的嵌套循环连接算法，它在连接操作中使用了子查询或者外部查询的结果。具体来说，&quot;Apply plan&quot; 在每次迭代连接的过程中，将外部查询的结果作为输入，并将其应用于嵌套循环连接中的内部查询。这样可以在每次迭代中有效地使用外部查询的结果来过滤和匹配内部查询的行。</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Apply plan&quot; 在执行连接操作时具有一些优势，例如：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 减少连接操作的数据量：通过在每次迭代中使用外部查询的结果进行过滤，可以减少连接操作涉及的数据量，从而提高查询性能和效率。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 优化连接操作的执行顺序：&quot;Apply plan&quot; 可以改变连接操作的执行顺序，先执行外部查询，然后在每次迭代中应用内部查询，这样可以根据数据的特点和选择性来优化连接操作的执行计划。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 支持相关子查询：&quot;Apply plan&quot; 在连接操作中使用了子查询的结果，这样可以支持相关子查询（Correlated Subquery）的语义和语法。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，&quot;Apply plan&quot; 并不是适用于所有情况的最佳连接算法。在实际应用中，优化器会根据查询的复杂性、数据分布、索引情况等因素综合考虑，选择最适合的连接算法来执行查询。</span><br><span class=\"line\"></span><br><span class=\"line\">--------</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Join plan&quot; 是数据库查询优化和执行中的一个概念，用于指代执行连接操作时所采用的计划或策略。</span><br><span class=\"line\"></span><br><span class=\"line\">在关系数据库中，&quot;join&quot; 是指将两个或多个表基于某个关联条件进行连接操作，以获取符合条件的结果集。在执行连接操作时，优化器需要选择适当的连接算法和连接顺序，以获得最佳的查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Join plan&quot; 描述了执行连接操作时所采用的具体计划或策略，包括以下方面：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 连接算法选择：根据查询条件、表的大小、索引情况等因素，优化器会选择适合的连接算法，例如嵌套循环连接、哈希连接、排序合并连接等。每种连接算法都有其适用的场景和性能特点。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 连接顺序决策：当连接操作涉及多个表时，优化器需要确定连接的顺序。连接顺序的选择可以影响查询性能，例如选择连接顺序可以最小化中间结果集的大小，减少连接操作的数据量。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 连接类型决策：连接操作可以有不同的连接类型，如内连接、左连接、右连接、全外连接等。&quot;Join plan&quot; 包括选择适当的连接类型以满足查询需求。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">4.</span> 索引和优化技术：优化器会考虑现有的索引和其他优化技术，以提高连接操作的性能。它可能选择使用索引来加速连接操作，并利用统计信息和查询历史来评估和选择最佳的连接计划。</span><br><span class=\"line\"></span><br><span class=\"line\">总之，“Join plan” 是在查询优化过程中确定连接操作的具体计划或策略。优化器通过考虑连接算法、连接顺序、连接类型以及索引和优化技术等因素，选择最佳的连接计划，以实现高效的查询执行。</span><br></pre></td></tr></table></figure>\n\n<ol start=\"6\">\n<li>semiJoinRewriter。半连接重写。</li>\n</ol>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;semiJoin&quot;（半连接）是数据库查询中的一种操作，用于判断一个表中的数据是否存在于另一个表中。</span><br><span class=\"line\"></span><br><span class=\"line\">在半连接操作中，查询优化器会选择一个表作为左表（left table），另一个表作为右表（right table）。然后，它会根据两个表之间的连接条件，筛选出左表中符合条件的行，并检查这些行是否存在于右表中。</span><br><span class=\"line\"></span><br><span class=\"line\">半连接的目的是提取左表中满足连接条件的行，而不关心右表的具体数据。它通常用于优化查询性能，减少数据传输和处理的开销。</span><br><span class=\"line\"></span><br><span class=\"line\">半连接操作可以有不同的实现方式，其中一种常见的实现方式是使用存在谓词（EXISTS predicate）。该谓词会在连接操作中使用子查询来判断左表的行是否存在于右表中，返回一个布尔值作为结果。</span><br><span class=\"line\"></span><br><span class=\"line\">举个例子，假设有两个表 A 和 B，需要判断表 A 中的某些行是否在表 B 中存在。使用半连接操作，可以编写类似下面的查询：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    ```sql</span></span><br><span class=\"line\"><span class=\"code\">    SELECT *</span></span><br><span class=\"line\"><span class=\"code\">    FROM A</span></span><br><span class=\"line\"><span class=\"code\">    WHERE EXISTS (</span></span><br><span class=\"line\"><span class=\"code\">    SELECT 1</span></span><br><span class=\"line\"><span class=\"code\">    FROM B</span></span><br><span class=\"line\"><span class=\"code\">    WHERE A.id = B.id</span></span><br><span class=\"line\"><span class=\"code\">    );</span></span><br></pre></td></tr></table></figure>\n\n<p>上述查询中，子查询会根据连接条件 A.id &#x3D; B.id 来检查表 A 的行是否存在于表 B 中。如果存在匹配的行，则返回结果。</p>\n<p>通过使用半连接操作，可以有效地筛选出左表中存在于右表中的行，从而减少数据量和查询的开销，提高查询性能。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">7. aggregationEliminator。消除一些无意义的聚合函数，下面是方法的注释，可以参考其中的例子来理解。</span><br><span class=\"line\"></span><br><span class=\"line\">```go</span><br><span class=\"line\">// tryToEliminateAggregation will eliminate aggregation grouped by unique key.</span><br><span class=\"line\">// e.g. select min(b) from t group by a. If a is a unique key, then this sql is equal to `select b from t group by a`.</span><br><span class=\"line\">// For count(expr), sum(expr), avg(expr), count(distinct expr, [expr...]) we may need to rewrite the expr. Details are shown below.</span><br><span class=\"line\">// If we can eliminate agg successful, we return a projection. Else we return a nil pointer.</span><br></pre></td></tr></table></figure>\n\n<ol start=\"8\">\n<li>skewDistinctAggRewriter。将group distinct 聚集函数重写成两级聚合。可以参考下面注释中的例子来理解。这种优化是为了优化在group key数据偏移的情况下缓解数据偏移。这个规则会被应用于满足以下条件的 query：<ol>\n<li>至少有一个 group by的语句</li>\n<li>有且仅有一个 distinct aggregate 函数（仅限于 count、avg 和 sum）</li>\n</ol>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// skewDistinctAggRewriter will rewrite group distinct aggregate into 2 level aggregates, e.g.:</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">//\tselect S_NATIONKEY as s, count(S_SUPPKEY), count(distinct S_NAME) from supplier group by s;</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// will be rewritten to</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">//\tselect S_NATIONKEY as s, sum(c), count(S_NAME) from (</span></span><br><span class=\"line\"><span class=\"comment\">//\t  select S_NATIONKEY, S_NAME, count(S_SUPPKEY) c from supplier group by S_NATIONKEY, S_NAME</span></span><br><span class=\"line\"><span class=\"comment\">//\t) as T group by s;</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// If the group key is highly skewed and the distinct key has large number of distinct values</span></span><br><span class=\"line\"><span class=\"comment\">// (a.k.a. high cardinality), the query execution will be slow. This rule may help to ease the</span></span><br><span class=\"line\"><span class=\"comment\">// skew issue.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The rewrite rule only applies to query that satisfies:</span></span><br><span class=\"line\"><span class=\"comment\">// - The aggregate has at least 1 group by column (the group key can be columns or expressions)</span></span><br><span class=\"line\"><span class=\"comment\">// - The aggregate has 1 and only 1 distinct aggregate function (limited to count, avg, sum)</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// This rule is disabled by default. Use tidb_opt_skew_distinct_agg to enable the rule.</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"9\">\n<li><p>projectionEliminator。消除逻辑计划中多余的投影。</p>\n</li>\n<li><p>maxMinEliminator。消除最大值最小值函数。下面是注释，可以看一下其中的例子：</p>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// maxMinEliminator tries to eliminate max/min aggregate function.</span></span><br><span class=\"line\"><span class=\"comment\">// For SQL like `select max(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id desc limit 1 where id is not null) t;`.</span></span><br><span class=\"line\"><span class=\"comment\">// For SQL like `select min(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id limit 1 where id is not null) t;`.</span></span><br><span class=\"line\"><span class=\"comment\">// For SQL like `select max(id), min(id) from t;`, we could optimize it to the cartesianJoin result of the two queries above if `id` has an index.</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"11\">\n<li>ppdSolver。这个名字有意思，其实是<code>PredicatePushDown</code>的缩写。 这个是用来执行谓词下推的规则。</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// PredicatePushDown pushes down the predicates in the where/on/having clauses as deeply as possible.</span></span><br><span class=\"line\"><span class=\"comment\">// It will accept a predicate that is an expression slice, and return the expressions that can&#x27;t be pushed.</span></span><br><span class=\"line\"><span class=\"comment\">// Because it might change the root if the having clause exists, we need to return a plan that represents a new root.</span></span><br><span class=\"line\"></span><br><span class=\"line\">谓词下推（Predicate Pushdown）是数据库查询优化的一种技术，它通过将查询条件下推到数据源（如表、索引）级别进行处理，减少数据的读取和处理量，从而提高查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">在传统的查询执行过程中，查询优化器通常会将查询条件应用于获取结果集之后进行筛选。这意味着数据库系统会读取所有的数据记录，并在获取结果集后再应用查询条件进行过滤，导致数据的读取和处理开销较大。</span><br><span class=\"line\"></span><br><span class=\"line\">而谓词下推的思想是，在查询过程中尽早地将查询条件下推到数据源级别，即在读取数据之前应用查询条件进行过滤。这样可以减少读取和处理的数据量，提高查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">通过谓词下推，数据库系统可以在数据源级别利用索引、统计信息和其他优化技术来加速查询过程。它可以有效地削减不必要的数据读取和处理，减少中间结果集的大小，并在查询过程中提前过滤掉不符合查询条件的数据。</span><br><span class=\"line\"></span><br><span class=\"line\">谓词下推的具体操作可以包括以下方面：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">1.</span> 下推过滤条件：将查询条件应用于索引扫描或表扫描的过程中，尽早地过滤掉不满足条件的数据。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">2.</span> 下推投影操作：根据查询需要，将字段选择（Projection）操作下推到数据源级别，减少返回结果的列数。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">3.</span> 下推连接条件：对连接操作进行优化，将连接条件下推到连接操作的数据源，减少连接的数据量。</span><br><span class=\"line\"></span><br><span class=\"line\">谓词下推在数据库查询优化中起着重要的作用，它可以显著提高查询性能，减少数据读取和处理的开销。通过在数据源级别应用查询条件，可以最大程度地减少不必要的数据操作，加速查询过程并降低系统资源的消耗。</span><br></pre></td></tr></table></figure>\n\n<ol start=\"12\">\n<li>outerJoinEliminator。消除外连接。主要有以下两个规则：<ol>\n<li>外连接消除：例如左外连接，如果父查询只使用左表的列和右表（内部表）的连接键（唯一键），则可以消除左外连接。</li>\n<li>使用不考虑重复的聚合函数进行外连接消除：例如左外连接。如果父查询只使用带有 ‘distinct’ 标签的左表列，则可以消除左外连接。</li>\n</ol>\n</li>\n</ol>\n<p>下面是代码中的注释：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// tryToEliminateOuterJoin will eliminate outer join plan base on the following rules</span><br><span class=\"line\">//  1. outer join elimination: For example left outer join, if the parent only use the</span><br><span class=\"line\">//     columns from left table and the join key of right table(the inner table) is a unique</span><br><span class=\"line\">//     key of the right table. the left outer join can be eliminated.</span><br><span class=\"line\">//  2. outer join elimination with duplicate agnostic aggregate functions: For example left outer join.</span><br><span class=\"line\">//     If the parent only use the columns from left table with &#x27;distinct&#x27; label. The left outer join can</span><br><span class=\"line\">//     be eliminated.</span><br></pre></td></tr></table></figure>\n\n<ol start=\"13\">\n<li>partitionProcessor。对分区语句进行重写。主要是做固定分区修剪。下面是注释内容：</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// partitionProcessor rewrites the ast for table partition.</span></span><br><span class=\"line\"><span class=\"comment\">// Used by static partition prune mode.</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">// create table t (id int) partition by range (id)</span></span><br><span class=\"line\"><span class=\"comment\">//   (partition p1 values less than (10),</span></span><br><span class=\"line\"><span class=\"comment\">//    partition p2 values less than (20),</span></span><br><span class=\"line\"><span class=\"comment\">//    partition p3 values less than (30))</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// select * from t is equal to</span></span><br><span class=\"line\"><span class=\"comment\">// select * from (union all</span></span><br><span class=\"line\"><span class=\"comment\">//      select * from p1 where id &lt; 10</span></span><br><span class=\"line\"><span class=\"comment\">//      select * from p2 where id &lt; 20</span></span><br><span class=\"line\"><span class=\"comment\">//      select * from p3 where id &lt; 30)</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"comment\">// partitionProcessor is here because it&#x27;s easier to prune partition after predicate push down.</span></span><br></pre></td></tr></table></figure>\n<p>这里提到在谓词下推之后做分区修剪会更加简单。</p>\n<ol start=\"14\">\n<li><p>collectPredicateColumnsPoint。这个方法没有一句注释。不过这个方法有几个比较重要的子方法，下面是这几个子方法的注释：(TODO)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// CollectColumnStatsUsage collects column stats usage from logical plan.</span><br><span class=\"line\">// predicate indicates whether to collect predicate columns and histNeeded indicates whether to collect histogram-needed columns.</span><br><span class=\"line\">// The first return value is predicate columns(nil if predicate is false) and the second return value is histogram-needed columns(nil if histNeeded is false).</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// collectSyncIndices will collect the indices which includes following conditions:</span><br><span class=\"line\">// 1. the indices contained the any one of histNeededColumns, eg: histNeededColumns contained A,B columns, and idx_a is</span><br><span class=\"line\">// composed up by A column, then we thought the idx_a should be collected</span><br><span class=\"line\">// 2. The stats condition of idx_a can&#x27;t meet IsFullLoad, which means its stats was evicted previously</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>aggregationPushDownSolver。聚集函数下推，下面是重要方法的注释：</p>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// tryToPushDownAgg tries to push down an aggregate function into a join path. If all aggFuncs are first row, we won&#x27;t</span></span><br><span class=\"line\"><span class=\"comment\">// process it temporarily. If not, We will add additional group by columns and first row functions. We make a new aggregation operator.</span></span><br><span class=\"line\"><span class=\"comment\">// If the pushed aggregation is grouped by unique key, it&#x27;s no need to push it down.</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"16\">\n<li><p>deriveTopNFromWindow。 从窗口函数中推导 TopN或Limit。按照官方文档中的例子，其实就是通过改写带有窗口函数的语句，减少无意义的排序操作。从下面的例子其实很容易理解这个过程：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 改写前</span><br><span class=\"line\">SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t) dt WHERE rownumber &lt;= 3</span><br><span class=\"line\"></span><br><span class=\"line\">// 改写后</span><br><span class=\"line\">WITH t_topN AS (SELECT a FROM t1 ORDER BY a LIMIT 3) SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t_topN) dt WHERE rownumber &lt;= 3</span><br></pre></td></tr></table></figure>\n<p>可以看出，进行改写之后，原语句中对全表的 sort 操作被简化成一个 sort + limit 操作，极大地节省了资源。</p>\n</li>\n<li><p>predicateSimplification。谓词简化，其实就是对一些谓词语句进行简化。</p>\n</li>\n<li><p>pushDownTopNOptimizer。这个方法将下推 topN或者 limit操作。</p>\n</li>\n</ol>\n<p>上述的几个下推方法其实都是类似的思想，讲一些计算操作或者条件判断尽可能下推到距离数据源近的地方，尽早完成数据的过滤操作，从而减少数据传输和计算的开销。</p>\n<ol start=\"19\">\n<li><p>syncWaitStatsLoadPoint。同步等待数据加载。</p>\n</li>\n<li><p>joinReOrderSolver。递归采集 join 组，然后对每个组执行 join 重排序算法。</p>\n</li>\n<li><p>columnPruner。最后再进行一次列裁剪，因为前面的列裁剪可能会被<code>buildKeySolver</code>弄乱。</p>\n</li>\n<li><p>pushDownSequenceSolver。递归执行下推序列。</p>\n</li>\n</ol>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] <a href=\"https://docs.pingcap.com/zh/tidb/dev/sql-logical-optimization\">https://docs.pingcap.com/zh/tidb/dev/sql-logical-optimization</a></p>\n","site":{"data":{}},"excerpt":"<p>根据源码中的<code>optRuleList</code>列表来看，TiDB 的逻辑计划优化规则总共有22种，下面是源码：</p>","more":"<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> optRuleList = []logicalOptRule&#123;</span><br><span class=\"line\">\t&amp;gcSubstituter&#123;&#125;,</span><br><span class=\"line\">\t&amp;columnPruner&#123;&#125;,</span><br><span class=\"line\">\t&amp;resultReorder&#123;&#125;,</span><br><span class=\"line\">\t&amp;buildKeySolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;decorrelateSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;semiJoinRewriter&#123;&#125;,</span><br><span class=\"line\">\t&amp;aggregationEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;skewDistinctAggRewriter&#123;&#125;,</span><br><span class=\"line\">\t&amp;projectionEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;maxMinEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;ppdSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;outerJoinEliminator&#123;&#125;,</span><br><span class=\"line\">\t&amp;partitionProcessor&#123;&#125;,</span><br><span class=\"line\">\t&amp;collectPredicateColumnsPoint&#123;&#125;,</span><br><span class=\"line\">\t&amp;aggregationPushDownSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;deriveTopNFromWindow&#123;&#125;,</span><br><span class=\"line\">\t&amp;predicateSimplification&#123;&#125;,</span><br><span class=\"line\">\t&amp;pushDownTopNOptimizer&#123;&#125;,</span><br><span class=\"line\">\t&amp;syncWaitStatsLoadPoint&#123;&#125;,</span><br><span class=\"line\">\t&amp;joinReOrderSolver&#123;&#125;,</span><br><span class=\"line\">\t&amp;columnPruner&#123;&#125;, <span class=\"comment\">// column pruning again at last, note it will mess up the results of buildKeySolver</span></span><br><span class=\"line\">\t&amp;pushDownSequenceSolver&#123;&#125;,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们现在来一个一个过一遍这些 rule。</p>\n<ol>\n<li>gcSubstituter。下面是<code>optimize</code>方法的注释：</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// optimize try to replace the expression to indexed virtual generate column in where, group by, order by, and field clause</span></span><br><span class=\"line\"><span class=\"comment\">// so that we can use the index on expression.</span></span><br><span class=\"line\"><span class=\"comment\">// For example. select a+1 from t order by a+1, with a virtual generate column c as (a+1) and</span></span><br><span class=\"line\"><span class=\"comment\">// an index on c. We need to replace a+1 with c so that we can use the index on c.</span></span><br><span class=\"line\"><span class=\"comment\">// See also https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html</span></span><br></pre></td></tr></table></figure>\n\n<p>简单来说，这个优化规则是将where、group by、order by或者字段子句中的表达式替换成被索引的虚拟生成列，从而能够使用索引来访问。具体例子可以看注释中的解释，或者mysql 中对<a href=\"https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html\">生成列索引优化</a>的解释。</p>\n<ol start=\"2\">\n<li><p>columnPruner。这个方法直接没有注释了，但是也很好理解，其实就是列裁剪，对于一些用不到的列，优化过程中可以直接去除，避免多余的 IO 占用。</p>\n</li>\n<li><p>resultReorder。 结果重排序，对没有排序的结果插入一个排序操作符，用于对结果进行排序。</p>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">resultReorder reorder query results.</span></span><br><span class=\"line\"><span class=\"comment\">NOTE. it&#x27;s not a common rule for all queries, it&#x27;s specially implemented for a few customers.</span></span><br><span class=\"line\"><span class=\"comment\"></span></span><br><span class=\"line\"><span class=\"comment\">Results of some queries are not ordered, for example.</span></span><br><span class=\"line\"><span class=\"comment\"></span></span><br><span class=\"line\"><span class=\"comment\">\tcreate table t (a int); insert into t values (1), (2); select a from t;</span></span><br><span class=\"line\"><span class=\"comment\"></span></span><br><span class=\"line\"><span class=\"comment\">In the case above, the result can be `1 2` or `2 1`, which is not ordered.</span></span><br><span class=\"line\"><span class=\"comment\">This rule reorders results by modifying or injecting a Sort operator.</span></span><br><span class=\"line\"><span class=\"comment\"> 1. iterate the plan from the root, and ignore all input-order operators (Sel/Proj/Limit);</span></span><br><span class=\"line\"><span class=\"comment\"> 2. when meeting the first non-input-order operator,</span></span><br><span class=\"line\"><span class=\"comment\">    2.1. if it&#x27;s a Sort, update it by appending all output columns into its order-by list,</span></span><br><span class=\"line\"><span class=\"comment\">    2.2. otherwise, inject a new Sort upon this operator.</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li><p>buildKeySolver。提取索引信息为 schema 设置对应的 key。这个东西应该是之后会用来决定如何使用索引的，以后看到这个内容可以再回来研究一下。</p>\n</li>\n<li><p>decorrelateSolver。用来将 <code>apply plan</code> 转换成 <code>join plan</code>。这个应该就是关联子查询去关联，说白了就是讲一些能够转换成 join 操作的子查询重写成 join 的形式，好处是可以减少子查询重复执行次数。详细解释可以见<a href=\"https://docs.pingcap.com/zh/tidb/dev/correlated-subquery-optimization\">https://docs.pingcap.com/zh/tidb/dev/correlated-subquery-optimization</a></p>\n</li>\n</ol>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;Apply plan&quot; 是一个数据库查询优化和执行的概念，用于在查询执行过程中使用嵌套循环连接或半连接操作。</span><br><span class=\"line\"></span><br><span class=\"line\">在关系数据库中，当执行包含连接操作的查询时，优化器可以选择使用不同的连接算法来获取结果。一种常见的连接算法是嵌套循环连接（Nested Loop Join），它基于嵌套循环的方式逐个比较连接条件并获取匹配的行。</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Apply plan&quot; 是一种特殊的嵌套循环连接算法，它在连接操作中使用了子查询或者外部查询的结果。具体来说，&quot;Apply plan&quot; 在每次迭代连接的过程中，将外部查询的结果作为输入，并将其应用于嵌套循环连接中的内部查询。这样可以在每次迭代中有效地使用外部查询的结果来过滤和匹配内部查询的行。</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Apply plan&quot; 在执行连接操作时具有一些优势，例如：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 减少连接操作的数据量：通过在每次迭代中使用外部查询的结果进行过滤，可以减少连接操作涉及的数据量，从而提高查询性能和效率。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 优化连接操作的执行顺序：&quot;Apply plan&quot; 可以改变连接操作的执行顺序，先执行外部查询，然后在每次迭代中应用内部查询，这样可以根据数据的特点和选择性来优化连接操作的执行计划。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 支持相关子查询：&quot;Apply plan&quot; 在连接操作中使用了子查询的结果，这样可以支持相关子查询（Correlated Subquery）的语义和语法。</span><br><span class=\"line\"></span><br><span class=\"line\">需要注意的是，&quot;Apply plan&quot; 并不是适用于所有情况的最佳连接算法。在实际应用中，优化器会根据查询的复杂性、数据分布、索引情况等因素综合考虑，选择最适合的连接算法来执行查询。</span><br><span class=\"line\"></span><br><span class=\"line\">--------</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Join plan&quot; 是数据库查询优化和执行中的一个概念，用于指代执行连接操作时所采用的计划或策略。</span><br><span class=\"line\"></span><br><span class=\"line\">在关系数据库中，&quot;join&quot; 是指将两个或多个表基于某个关联条件进行连接操作，以获取符合条件的结果集。在执行连接操作时，优化器需要选择适当的连接算法和连接顺序，以获得最佳的查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;Join plan&quot; 描述了执行连接操作时所采用的具体计划或策略，包括以下方面：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">1.</span> 连接算法选择：根据查询条件、表的大小、索引情况等因素，优化器会选择适合的连接算法，例如嵌套循环连接、哈希连接、排序合并连接等。每种连接算法都有其适用的场景和性能特点。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">2.</span> 连接顺序决策：当连接操作涉及多个表时，优化器需要确定连接的顺序。连接顺序的选择可以影响查询性能，例如选择连接顺序可以最小化中间结果集的大小，减少连接操作的数据量。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">3.</span> 连接类型决策：连接操作可以有不同的连接类型，如内连接、左连接、右连接、全外连接等。&quot;Join plan&quot; 包括选择适当的连接类型以满足查询需求。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">4.</span> 索引和优化技术：优化器会考虑现有的索引和其他优化技术，以提高连接操作的性能。它可能选择使用索引来加速连接操作，并利用统计信息和查询历史来评估和选择最佳的连接计划。</span><br><span class=\"line\"></span><br><span class=\"line\">总之，“Join plan” 是在查询优化过程中确定连接操作的具体计划或策略。优化器通过考虑连接算法、连接顺序、连接类型以及索引和优化技术等因素，选择最佳的连接计划，以实现高效的查询执行。</span><br></pre></td></tr></table></figure>\n\n<ol start=\"6\">\n<li>semiJoinRewriter。半连接重写。</li>\n</ol>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;semiJoin&quot;（半连接）是数据库查询中的一种操作，用于判断一个表中的数据是否存在于另一个表中。</span><br><span class=\"line\"></span><br><span class=\"line\">在半连接操作中，查询优化器会选择一个表作为左表（left table），另一个表作为右表（right table）。然后，它会根据两个表之间的连接条件，筛选出左表中符合条件的行，并检查这些行是否存在于右表中。</span><br><span class=\"line\"></span><br><span class=\"line\">半连接的目的是提取左表中满足连接条件的行，而不关心右表的具体数据。它通常用于优化查询性能，减少数据传输和处理的开销。</span><br><span class=\"line\"></span><br><span class=\"line\">半连接操作可以有不同的实现方式，其中一种常见的实现方式是使用存在谓词（EXISTS predicate）。该谓词会在连接操作中使用子查询来判断左表的行是否存在于右表中，返回一个布尔值作为结果。</span><br><span class=\"line\"></span><br><span class=\"line\">举个例子，假设有两个表 A 和 B，需要判断表 A 中的某些行是否在表 B 中存在。使用半连接操作，可以编写类似下面的查询：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"code\">    ```sql</span></span><br><span class=\"line\"><span class=\"code\">    SELECT *</span></span><br><span class=\"line\"><span class=\"code\">    FROM A</span></span><br><span class=\"line\"><span class=\"code\">    WHERE EXISTS (</span></span><br><span class=\"line\"><span class=\"code\">    SELECT 1</span></span><br><span class=\"line\"><span class=\"code\">    FROM B</span></span><br><span class=\"line\"><span class=\"code\">    WHERE A.id = B.id</span></span><br><span class=\"line\"><span class=\"code\">    );</span></span><br></pre></td></tr></table></figure>\n\n<p>上述查询中，子查询会根据连接条件 A.id &#x3D; B.id 来检查表 A 的行是否存在于表 B 中。如果存在匹配的行，则返回结果。</p>\n<p>通过使用半连接操作，可以有效地筛选出左表中存在于右表中的行，从而减少数据量和查询的开销，提高查询性能。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">7. aggregationEliminator。消除一些无意义的聚合函数，下面是方法的注释，可以参考其中的例子来理解。</span><br><span class=\"line\"></span><br><span class=\"line\">```go</span><br><span class=\"line\">// tryToEliminateAggregation will eliminate aggregation grouped by unique key.</span><br><span class=\"line\">// e.g. select min(b) from t group by a. If a is a unique key, then this sql is equal to `select b from t group by a`.</span><br><span class=\"line\">// For count(expr), sum(expr), avg(expr), count(distinct expr, [expr...]) we may need to rewrite the expr. Details are shown below.</span><br><span class=\"line\">// If we can eliminate agg successful, we return a projection. Else we return a nil pointer.</span><br></pre></td></tr></table></figure>\n\n<ol start=\"8\">\n<li>skewDistinctAggRewriter。将group distinct 聚集函数重写成两级聚合。可以参考下面注释中的例子来理解。这种优化是为了优化在group key数据偏移的情况下缓解数据偏移。这个规则会被应用于满足以下条件的 query：<ol>\n<li>至少有一个 group by的语句</li>\n<li>有且仅有一个 distinct aggregate 函数（仅限于 count、avg 和 sum）</li>\n</ol>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// skewDistinctAggRewriter will rewrite group distinct aggregate into 2 level aggregates, e.g.:</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">//\tselect S_NATIONKEY as s, count(S_SUPPKEY), count(distinct S_NAME) from supplier group by s;</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// will be rewritten to</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">//\tselect S_NATIONKEY as s, sum(c), count(S_NAME) from (</span></span><br><span class=\"line\"><span class=\"comment\">//\t  select S_NATIONKEY, S_NAME, count(S_SUPPKEY) c from supplier group by S_NATIONKEY, S_NAME</span></span><br><span class=\"line\"><span class=\"comment\">//\t) as T group by s;</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// If the group key is highly skewed and the distinct key has large number of distinct values</span></span><br><span class=\"line\"><span class=\"comment\">// (a.k.a. high cardinality), the query execution will be slow. This rule may help to ease the</span></span><br><span class=\"line\"><span class=\"comment\">// skew issue.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The rewrite rule only applies to query that satisfies:</span></span><br><span class=\"line\"><span class=\"comment\">// - The aggregate has at least 1 group by column (the group key can be columns or expressions)</span></span><br><span class=\"line\"><span class=\"comment\">// - The aggregate has 1 and only 1 distinct aggregate function (limited to count, avg, sum)</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// This rule is disabled by default. Use tidb_opt_skew_distinct_agg to enable the rule.</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"9\">\n<li><p>projectionEliminator。消除逻辑计划中多余的投影。</p>\n</li>\n<li><p>maxMinEliminator。消除最大值最小值函数。下面是注释，可以看一下其中的例子：</p>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// maxMinEliminator tries to eliminate max/min aggregate function.</span></span><br><span class=\"line\"><span class=\"comment\">// For SQL like `select max(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id desc limit 1 where id is not null) t;`.</span></span><br><span class=\"line\"><span class=\"comment\">// For SQL like `select min(id) from t;`, we could optimize it to `select max(id) from (select id from t order by id limit 1 where id is not null) t;`.</span></span><br><span class=\"line\"><span class=\"comment\">// For SQL like `select max(id), min(id) from t;`, we could optimize it to the cartesianJoin result of the two queries above if `id` has an index.</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"11\">\n<li>ppdSolver。这个名字有意思，其实是<code>PredicatePushDown</code>的缩写。 这个是用来执行谓词下推的规则。</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// PredicatePushDown pushes down the predicates in the where/on/having clauses as deeply as possible.</span></span><br><span class=\"line\"><span class=\"comment\">// It will accept a predicate that is an expression slice, and return the expressions that can&#x27;t be pushed.</span></span><br><span class=\"line\"><span class=\"comment\">// Because it might change the root if the having clause exists, we need to return a plan that represents a new root.</span></span><br><span class=\"line\"></span><br><span class=\"line\">谓词下推（Predicate Pushdown）是数据库查询优化的一种技术，它通过将查询条件下推到数据源（如表、索引）级别进行处理，减少数据的读取和处理量，从而提高查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">在传统的查询执行过程中，查询优化器通常会将查询条件应用于获取结果集之后进行筛选。这意味着数据库系统会读取所有的数据记录，并在获取结果集后再应用查询条件进行过滤，导致数据的读取和处理开销较大。</span><br><span class=\"line\"></span><br><span class=\"line\">而谓词下推的思想是，在查询过程中尽早地将查询条件下推到数据源级别，即在读取数据之前应用查询条件进行过滤。这样可以减少读取和处理的数据量，提高查询性能。</span><br><span class=\"line\"></span><br><span class=\"line\">通过谓词下推，数据库系统可以在数据源级别利用索引、统计信息和其他优化技术来加速查询过程。它可以有效地削减不必要的数据读取和处理，减少中间结果集的大小，并在查询过程中提前过滤掉不符合查询条件的数据。</span><br><span class=\"line\"></span><br><span class=\"line\">谓词下推的具体操作可以包括以下方面：</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">1.</span> 下推过滤条件：将查询条件应用于索引扫描或表扫描的过程中，尽早地过滤掉不满足条件的数据。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">2.</span> 下推投影操作：根据查询需要，将字段选择（Projection）操作下推到数据源级别，减少返回结果的列数。</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"number\">3.</span> 下推连接条件：对连接操作进行优化，将连接条件下推到连接操作的数据源，减少连接的数据量。</span><br><span class=\"line\"></span><br><span class=\"line\">谓词下推在数据库查询优化中起着重要的作用，它可以显著提高查询性能，减少数据读取和处理的开销。通过在数据源级别应用查询条件，可以最大程度地减少不必要的数据操作，加速查询过程并降低系统资源的消耗。</span><br></pre></td></tr></table></figure>\n\n<ol start=\"12\">\n<li>outerJoinEliminator。消除外连接。主要有以下两个规则：<ol>\n<li>外连接消除：例如左外连接，如果父查询只使用左表的列和右表（内部表）的连接键（唯一键），则可以消除左外连接。</li>\n<li>使用不考虑重复的聚合函数进行外连接消除：例如左外连接。如果父查询只使用带有 ‘distinct’ 标签的左表列，则可以消除左外连接。</li>\n</ol>\n</li>\n</ol>\n<p>下面是代码中的注释：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// tryToEliminateOuterJoin will eliminate outer join plan base on the following rules</span><br><span class=\"line\">//  1. outer join elimination: For example left outer join, if the parent only use the</span><br><span class=\"line\">//     columns from left table and the join key of right table(the inner table) is a unique</span><br><span class=\"line\">//     key of the right table. the left outer join can be eliminated.</span><br><span class=\"line\">//  2. outer join elimination with duplicate agnostic aggregate functions: For example left outer join.</span><br><span class=\"line\">//     If the parent only use the columns from left table with &#x27;distinct&#x27; label. The left outer join can</span><br><span class=\"line\">//     be eliminated.</span><br></pre></td></tr></table></figure>\n\n<ol start=\"13\">\n<li>partitionProcessor。对分区语句进行重写。主要是做固定分区修剪。下面是注释内容：</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// partitionProcessor rewrites the ast for table partition.</span></span><br><span class=\"line\"><span class=\"comment\">// Used by static partition prune mode.</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">// create table t (id int) partition by range (id)</span></span><br><span class=\"line\"><span class=\"comment\">//   (partition p1 values less than (10),</span></span><br><span class=\"line\"><span class=\"comment\">//    partition p2 values less than (20),</span></span><br><span class=\"line\"><span class=\"comment\">//    partition p3 values less than (30))</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// select * from t is equal to</span></span><br><span class=\"line\"><span class=\"comment\">// select * from (union all</span></span><br><span class=\"line\"><span class=\"comment\">//      select * from p1 where id &lt; 10</span></span><br><span class=\"line\"><span class=\"comment\">//      select * from p2 where id &lt; 20</span></span><br><span class=\"line\"><span class=\"comment\">//      select * from p3 where id &lt; 30)</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"comment\">// partitionProcessor is here because it&#x27;s easier to prune partition after predicate push down.</span></span><br></pre></td></tr></table></figure>\n<p>这里提到在谓词下推之后做分区修剪会更加简单。</p>\n<ol start=\"14\">\n<li><p>collectPredicateColumnsPoint。这个方法没有一句注释。不过这个方法有几个比较重要的子方法，下面是这几个子方法的注释：(TODO)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// CollectColumnStatsUsage collects column stats usage from logical plan.</span><br><span class=\"line\">// predicate indicates whether to collect predicate columns and histNeeded indicates whether to collect histogram-needed columns.</span><br><span class=\"line\">// The first return value is predicate columns(nil if predicate is false) and the second return value is histogram-needed columns(nil if histNeeded is false).</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// collectSyncIndices will collect the indices which includes following conditions:</span><br><span class=\"line\">// 1. the indices contained the any one of histNeededColumns, eg: histNeededColumns contained A,B columns, and idx_a is</span><br><span class=\"line\">// composed up by A column, then we thought the idx_a should be collected</span><br><span class=\"line\">// 2. The stats condition of idx_a can&#x27;t meet IsFullLoad, which means its stats was evicted previously</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>aggregationPushDownSolver。聚集函数下推，下面是重要方法的注释：</p>\n</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// tryToPushDownAgg tries to push down an aggregate function into a join path. If all aggFuncs are first row, we won&#x27;t</span></span><br><span class=\"line\"><span class=\"comment\">// process it temporarily. If not, We will add additional group by columns and first row functions. We make a new aggregation operator.</span></span><br><span class=\"line\"><span class=\"comment\">// If the pushed aggregation is grouped by unique key, it&#x27;s no need to push it down.</span></span><br></pre></td></tr></table></figure>\n\n<ol start=\"16\">\n<li><p>deriveTopNFromWindow。 从窗口函数中推导 TopN或Limit。按照官方文档中的例子，其实就是通过改写带有窗口函数的语句，减少无意义的排序操作。从下面的例子其实很容易理解这个过程：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 改写前</span><br><span class=\"line\">SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t) dt WHERE rownumber &lt;= 3</span><br><span class=\"line\"></span><br><span class=\"line\">// 改写后</span><br><span class=\"line\">WITH t_topN AS (SELECT a FROM t1 ORDER BY a LIMIT 3) SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t_topN) dt WHERE rownumber &lt;= 3</span><br></pre></td></tr></table></figure>\n<p>可以看出，进行改写之后，原语句中对全表的 sort 操作被简化成一个 sort + limit 操作，极大地节省了资源。</p>\n</li>\n<li><p>predicateSimplification。谓词简化，其实就是对一些谓词语句进行简化。</p>\n</li>\n<li><p>pushDownTopNOptimizer。这个方法将下推 topN或者 limit操作。</p>\n</li>\n</ol>\n<p>上述的几个下推方法其实都是类似的思想，讲一些计算操作或者条件判断尽可能下推到距离数据源近的地方，尽早完成数据的过滤操作，从而减少数据传输和计算的开销。</p>\n<ol start=\"19\">\n<li><p>syncWaitStatsLoadPoint。同步等待数据加载。</p>\n</li>\n<li><p>joinReOrderSolver。递归采集 join 组，然后对每个组执行 join 重排序算法。</p>\n</li>\n<li><p>columnPruner。最后再进行一次列裁剪，因为前面的列裁剪可能会被<code>buildKeySolver</code>弄乱。</p>\n</li>\n<li><p>pushDownSequenceSolver。递归执行下推序列。</p>\n</li>\n</ol>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] <a href=\"https://docs.pingcap.com/zh/tidb/dev/sql-logical-optimization\">https://docs.pingcap.com/zh/tidb/dev/sql-logical-optimization</a></p>"},{"title":"TiDB 存储接口设计","_content":"\n今天开始一个新的系列，分析 TiDB的源码。TiDB是目前开源做的比较好的一个数据库，目前商用做的也挺好的，项目影响力很大。因为是 Go语言实现的，读起来也没有什么太大的门槛。考虑到之后可能会参考 TiDB 做一些自己的小项目，这个系列应该会陆陆续续把整个项目的代码都分析完。由于行文仓促，我对项目也不是特别熟悉，这个系列难免会有错漏之处，之后回顾这个系列的时候，有些地方我可能会自己打脸，重新写一版本。\n\n<!-- more -->\n\n今天这一篇会简单过一遍 TiDB 如何和TiKV 做交互，主要记录我在读代码过程中看到的一些点。\n\nTiDB 的源码里面有两个模块与存储有关，分别是 store 和 kv。store 部分主要负责，kv 部分主要负责\n\n首先是 store 模块。\n\n在 tidb-server 启动的时候，main 函数中会将 TiKV 的Driver注册到 kvstore 的一个 map 里。`Driver` 接口里面值定义了一个 `Open` 方法，定义在 kv 模块的 kv.go 里，用于返回一个基于当前 store 的 storage 实例。完成注册后，`main` 函数会读取 config 中配置的 keyspaceName，基于此创建一个 storage 实例，用于创建 server。前面注册的 driver 会在此处基于 store path 解析出来，调用 `Open` 方法创建 storage 实例。\n```go\n// tidb-server/main.go\nfunc main() {\n    ...\n    registerStores()\n    ...\n    keyspaceName := keyspace.GetKeyspaceNameBySettings()\n\n    ...\n\tstorage, dom := createStoreAndDomain(keyspaceName)\n\tsvr := createServer(storage, dom)\n}\n```\n\n这里涉及了另外一个内容更多的接口`Storage`。下面是接口的定义，里面的方法相对较多，我们可以简单过一下几个重要的方法。`Begin`用于开启一个全局事务，`GetSnapshot`方法可以计入传入的 version 读取一个快照，`GetClient`用于获取一个存储 client 实例，`GetMPPClient`用于获取一个 mpp client 实例(MPP是一个面试过程中喜欢聊到的话题，我们可以后面单独聊一下这部分)，`Close`用于关闭当前 store，`UUID`、`CurrentVersion`、`Name`、`Describe`等方法可以获取当前存储实例的相关信息，`GetMemCache`用于获取当前存储的 memory manager，`GetMinSafeTS`基于给定的 txnScope 获取当前存储的最小 SafeTS(这个没太懂是干什么的，后面可以再仔细看看),`GetLockWaits`可以获取所有的 lock wait 信息，`GetCodec`获取当前存储的 `codec`。\n\n```go\n// Storage defines the interface for storage.\n// Isolation should be at least SI(SNAPSHOT ISOLATION)\ntype Storage interface {\n\t// Begin a global transaction\n\tBegin(opts ...tikv.TxnOption) (Transaction, error)\n\t// GetSnapshot gets a snapshot that is able to read any data which data is <= ver.\n\t// if ver is MaxVersion or > current max committed version, we will use current version for this snapshot.\n\tGetSnapshot(ver Version) Snapshot\n\t// GetClient gets a client instance.\n\tGetClient() Client\n\t// GetMPPClient gets a mpp client instance.\n\tGetMPPClient() MPPClient\n\t// Close store\n\tClose() error\n\t// UUID return a unique ID which represents a Storage.\n\tUUID() string\n\t// CurrentVersion returns current max committed version with the given txnScope (local or global).\n\tCurrentVersion(txnScope string) (Version, error)\n\t// GetOracle gets a timestamp oracle client.\n\tGetOracle() oracle.Oracle\n\t// SupportDeleteRange gets the storage support delete range or not.\n\tSupportDeleteRange() (supported bool)\n\t// Name gets the name of the storage engine\n\tName() string\n\t// Describe returns of brief introduction of the storage\n\tDescribe() string\n\t// ShowStatus returns the specified status of the storage\n\tShowStatus(ctx context.Context, key string) (interface{}, error)\n\t// GetMemCache return memory manager of the storage.\n\tGetMemCache() MemManager\n\t// GetMinSafeTS return the minimal SafeTS of the storage with given txnScope.\n\tGetMinSafeTS(txnScope string) uint64\n\t// GetLockWaits return all lock wait information\n\tGetLockWaits() ([]*deadlockpb.WaitForEntry, error)\n\t// GetCodec gets the codec of the storage.\n\tGetCodec() tikv.Codec\n}\n```\n\n这些方法具体在哪些地方使用，我们可以在后面继续研究。我们可以简单看一下 TiDB 中 `tikv_driver.go`里对这些接口的实现，整个文件只有 400 多行，读起来也比较简单。\n\n首先可以看下当前 storage 是如何创建的。如前文所述，`main`方法中在完成 driver 注册后，会打开 storage，创建 storage 实例。`TiKVDriver`中的`OpenWithOptions`方法，这个方法里会加载一些关键配置，创建一些必要的组件，比如 placement driver相关的实例，用于连接[集群总控中心](https://cn.pingcap.com/blog/placement-driver)（我也不知道为什么叫这个名字，其实 meta server 之类的名字好像更好理解一些），包括 pdCli 和 pdClient，pdCli 用来直接连接 pd server，pdClient 在 pdCli 的基础上对一些元信息做编解码的工作；比如 叫做 SafePointKV 的etcd实例，这个我暂时没明白是用来做什么的，看注释是说用来做 mock test和 runtime的无缝集成的；还有 RPC client，用来做和 tikv server 的 rpc 管理的。最后会基于上述生成的组件，生成一个 KV store 的实例。这里还有一个比较有意思的是会生成一个 coprStore，应该是用来服务于 [Coprocessor](https://cn.pingcap.com/blog/tikv-source-code-reading-14) 场景，这个东西在很多系统中都有实现，后面可以专门讲一下。完成这一系列工作之后，一个 storage 实例就生成了。\n\n接着来看一下`Begin`方法，这个方法是用于开启一个全局事务，主要靠调用 KVStore 的 `Begin` 方法来实现。在 KVStore 的`Begin`方法中，首先加载传入的 option，然后获取启动事务的 timestamp，并基于这个 timestamp 创建一个 TiKV的快照TiKVSnapshot，然后返回 KVTxn 实例，构建TiKVTxn 后返回。Txn相关的细节在之后的文章可以详细介绍一下。\n\n`tikv_driver.go`里面关于 `storage`接口的实现还有一些其他的方法，我们可以在后面调用到的时候来进一步分析。\n","source":"_posts/tidb/store_interface.md","raw":"---\ntitle: \"TiDB 存储接口设计\"\ntags:\n\t- TiDB\n\t- 数据库\n\t- 源码分析\n---\n\n今天开始一个新的系列，分析 TiDB的源码。TiDB是目前开源做的比较好的一个数据库，目前商用做的也挺好的，项目影响力很大。因为是 Go语言实现的，读起来也没有什么太大的门槛。考虑到之后可能会参考 TiDB 做一些自己的小项目，这个系列应该会陆陆续续把整个项目的代码都分析完。由于行文仓促，我对项目也不是特别熟悉，这个系列难免会有错漏之处，之后回顾这个系列的时候，有些地方我可能会自己打脸，重新写一版本。\n\n<!-- more -->\n\n今天这一篇会简单过一遍 TiDB 如何和TiKV 做交互，主要记录我在读代码过程中看到的一些点。\n\nTiDB 的源码里面有两个模块与存储有关，分别是 store 和 kv。store 部分主要负责，kv 部分主要负责\n\n首先是 store 模块。\n\n在 tidb-server 启动的时候，main 函数中会将 TiKV 的Driver注册到 kvstore 的一个 map 里。`Driver` 接口里面值定义了一个 `Open` 方法，定义在 kv 模块的 kv.go 里，用于返回一个基于当前 store 的 storage 实例。完成注册后，`main` 函数会读取 config 中配置的 keyspaceName，基于此创建一个 storage 实例，用于创建 server。前面注册的 driver 会在此处基于 store path 解析出来，调用 `Open` 方法创建 storage 实例。\n```go\n// tidb-server/main.go\nfunc main() {\n    ...\n    registerStores()\n    ...\n    keyspaceName := keyspace.GetKeyspaceNameBySettings()\n\n    ...\n\tstorage, dom := createStoreAndDomain(keyspaceName)\n\tsvr := createServer(storage, dom)\n}\n```\n\n这里涉及了另外一个内容更多的接口`Storage`。下面是接口的定义，里面的方法相对较多，我们可以简单过一下几个重要的方法。`Begin`用于开启一个全局事务，`GetSnapshot`方法可以计入传入的 version 读取一个快照，`GetClient`用于获取一个存储 client 实例，`GetMPPClient`用于获取一个 mpp client 实例(MPP是一个面试过程中喜欢聊到的话题，我们可以后面单独聊一下这部分)，`Close`用于关闭当前 store，`UUID`、`CurrentVersion`、`Name`、`Describe`等方法可以获取当前存储实例的相关信息，`GetMemCache`用于获取当前存储的 memory manager，`GetMinSafeTS`基于给定的 txnScope 获取当前存储的最小 SafeTS(这个没太懂是干什么的，后面可以再仔细看看),`GetLockWaits`可以获取所有的 lock wait 信息，`GetCodec`获取当前存储的 `codec`。\n\n```go\n// Storage defines the interface for storage.\n// Isolation should be at least SI(SNAPSHOT ISOLATION)\ntype Storage interface {\n\t// Begin a global transaction\n\tBegin(opts ...tikv.TxnOption) (Transaction, error)\n\t// GetSnapshot gets a snapshot that is able to read any data which data is <= ver.\n\t// if ver is MaxVersion or > current max committed version, we will use current version for this snapshot.\n\tGetSnapshot(ver Version) Snapshot\n\t// GetClient gets a client instance.\n\tGetClient() Client\n\t// GetMPPClient gets a mpp client instance.\n\tGetMPPClient() MPPClient\n\t// Close store\n\tClose() error\n\t// UUID return a unique ID which represents a Storage.\n\tUUID() string\n\t// CurrentVersion returns current max committed version with the given txnScope (local or global).\n\tCurrentVersion(txnScope string) (Version, error)\n\t// GetOracle gets a timestamp oracle client.\n\tGetOracle() oracle.Oracle\n\t// SupportDeleteRange gets the storage support delete range or not.\n\tSupportDeleteRange() (supported bool)\n\t// Name gets the name of the storage engine\n\tName() string\n\t// Describe returns of brief introduction of the storage\n\tDescribe() string\n\t// ShowStatus returns the specified status of the storage\n\tShowStatus(ctx context.Context, key string) (interface{}, error)\n\t// GetMemCache return memory manager of the storage.\n\tGetMemCache() MemManager\n\t// GetMinSafeTS return the minimal SafeTS of the storage with given txnScope.\n\tGetMinSafeTS(txnScope string) uint64\n\t// GetLockWaits return all lock wait information\n\tGetLockWaits() ([]*deadlockpb.WaitForEntry, error)\n\t// GetCodec gets the codec of the storage.\n\tGetCodec() tikv.Codec\n}\n```\n\n这些方法具体在哪些地方使用，我们可以在后面继续研究。我们可以简单看一下 TiDB 中 `tikv_driver.go`里对这些接口的实现，整个文件只有 400 多行，读起来也比较简单。\n\n首先可以看下当前 storage 是如何创建的。如前文所述，`main`方法中在完成 driver 注册后，会打开 storage，创建 storage 实例。`TiKVDriver`中的`OpenWithOptions`方法，这个方法里会加载一些关键配置，创建一些必要的组件，比如 placement driver相关的实例，用于连接[集群总控中心](https://cn.pingcap.com/blog/placement-driver)（我也不知道为什么叫这个名字，其实 meta server 之类的名字好像更好理解一些），包括 pdCli 和 pdClient，pdCli 用来直接连接 pd server，pdClient 在 pdCli 的基础上对一些元信息做编解码的工作；比如 叫做 SafePointKV 的etcd实例，这个我暂时没明白是用来做什么的，看注释是说用来做 mock test和 runtime的无缝集成的；还有 RPC client，用来做和 tikv server 的 rpc 管理的。最后会基于上述生成的组件，生成一个 KV store 的实例。这里还有一个比较有意思的是会生成一个 coprStore，应该是用来服务于 [Coprocessor](https://cn.pingcap.com/blog/tikv-source-code-reading-14) 场景，这个东西在很多系统中都有实现，后面可以专门讲一下。完成这一系列工作之后，一个 storage 实例就生成了。\n\n接着来看一下`Begin`方法，这个方法是用于开启一个全局事务，主要靠调用 KVStore 的 `Begin` 方法来实现。在 KVStore 的`Begin`方法中，首先加载传入的 option，然后获取启动事务的 timestamp，并基于这个 timestamp 创建一个 TiKV的快照TiKVSnapshot，然后返回 KVTxn 实例，构建TiKVTxn 后返回。Txn相关的细节在之后的文章可以详细介绍一下。\n\n`tikv_driver.go`里面关于 `storage`接口的实现还有一些其他的方法，我们可以在后面调用到的时候来进一步分析。\n","slug":"tidb/store_interface","published":1,"date":"2023-07-30T06:11:37.247Z","updated":"2023-07-30T06:11:37.247Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6j0000u1ts108tmfiru","content":"<p>今天开始一个新的系列，分析 TiDB的源码。TiDB是目前开源做的比较好的一个数据库，目前商用做的也挺好的，项目影响力很大。因为是 Go语言实现的，读起来也没有什么太大的门槛。考虑到之后可能会参考 TiDB 做一些自己的小项目，这个系列应该会陆陆续续把整个项目的代码都分析完。由于行文仓促，我对项目也不是特别熟悉，这个系列难免会有错漏之处，之后回顾这个系列的时候，有些地方我可能会自己打脸，重新写一版本。</p>\n<span id=\"more\"></span>\n\n<p>今天这一篇会简单过一遍 TiDB 如何和TiKV 做交互，主要记录我在读代码过程中看到的一些点。</p>\n<p>TiDB 的源码里面有两个模块与存储有关，分别是 store 和 kv。store 部分主要负责，kv 部分主要负责</p>\n<p>首先是 store 模块。</p>\n<p>在 tidb-server 启动的时候，main 函数中会将 TiKV 的Driver注册到 kvstore 的一个 map 里。<code>Driver</code> 接口里面值定义了一个 <code>Open</code> 方法，定义在 kv 模块的 kv.go 里，用于返回一个基于当前 store 的 storage 实例。完成注册后，<code>main</code> 函数会读取 config 中配置的 keyspaceName，基于此创建一个 storage 实例，用于创建 server。前面注册的 driver 会在此处基于 store path 解析出来，调用 <code>Open</code> 方法创建 storage 实例。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// tidb-server/main.go</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    registerStores()</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    keyspaceName := keyspace.GetKeyspaceNameBySettings()</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\">\tstorage, dom := createStoreAndDomain(keyspaceName)</span><br><span class=\"line\">\tsvr := createServer(storage, dom)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里涉及了另外一个内容更多的接口<code>Storage</code>。下面是接口的定义，里面的方法相对较多，我们可以简单过一下几个重要的方法。<code>Begin</code>用于开启一个全局事务，<code>GetSnapshot</code>方法可以计入传入的 version 读取一个快照，<code>GetClient</code>用于获取一个存储 client 实例，<code>GetMPPClient</code>用于获取一个 mpp client 实例(MPP是一个面试过程中喜欢聊到的话题，我们可以后面单独聊一下这部分)，<code>Close</code>用于关闭当前 store，<code>UUID</code>、<code>CurrentVersion</code>、<code>Name</code>、<code>Describe</code>等方法可以获取当前存储实例的相关信息，<code>GetMemCache</code>用于获取当前存储的 memory manager，<code>GetMinSafeTS</code>基于给定的 txnScope 获取当前存储的最小 SafeTS(这个没太懂是干什么的，后面可以再仔细看看),<code>GetLockWaits</code>可以获取所有的 lock wait 信息，<code>GetCodec</code>获取当前存储的 <code>codec</code>。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Storage defines the interface for storage.</span></span><br><span class=\"line\"><span class=\"comment\">// Isolation should be at least SI(SNAPSHOT ISOLATION)</span></span><br><span class=\"line\"><span class=\"keyword\">type</span> Storage <span class=\"keyword\">interface</span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// Begin a global transaction</span></span><br><span class=\"line\">\tBegin(opts ...tikv.TxnOption) (Transaction, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetSnapshot gets a snapshot that is able to read any data which data is &lt;= ver.</span></span><br><span class=\"line\">\t<span class=\"comment\">// if ver is MaxVersion or &gt; current max committed version, we will use current version for this snapshot.</span></span><br><span class=\"line\">\tGetSnapshot(ver Version) Snapshot</span><br><span class=\"line\">\t<span class=\"comment\">// GetClient gets a client instance.</span></span><br><span class=\"line\">\tGetClient() Client</span><br><span class=\"line\">\t<span class=\"comment\">// GetMPPClient gets a mpp client instance.</span></span><br><span class=\"line\">\tGetMPPClient() MPPClient</span><br><span class=\"line\">\t<span class=\"comment\">// Close store</span></span><br><span class=\"line\">\tClose() <span class=\"type\">error</span></span><br><span class=\"line\">\t<span class=\"comment\">// UUID return a unique ID which represents a Storage.</span></span><br><span class=\"line\">\tUUID() <span class=\"type\">string</span></span><br><span class=\"line\">\t<span class=\"comment\">// CurrentVersion returns current max committed version with the given txnScope (local or global).</span></span><br><span class=\"line\">\tCurrentVersion(txnScope <span class=\"type\">string</span>) (Version, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetOracle gets a timestamp oracle client.</span></span><br><span class=\"line\">\tGetOracle() oracle.Oracle</span><br><span class=\"line\">\t<span class=\"comment\">// SupportDeleteRange gets the storage support delete range or not.</span></span><br><span class=\"line\">\tSupportDeleteRange() (supported <span class=\"type\">bool</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// Name gets the name of the storage engine</span></span><br><span class=\"line\">\tName() <span class=\"type\">string</span></span><br><span class=\"line\">\t<span class=\"comment\">// Describe returns of brief introduction of the storage</span></span><br><span class=\"line\">\tDescribe() <span class=\"type\">string</span></span><br><span class=\"line\">\t<span class=\"comment\">// ShowStatus returns the specified status of the storage</span></span><br><span class=\"line\">\tShowStatus(ctx context.Context, key <span class=\"type\">string</span>) (<span class=\"keyword\">interface</span>&#123;&#125;, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetMemCache return memory manager of the storage.</span></span><br><span class=\"line\">\tGetMemCache() MemManager</span><br><span class=\"line\">\t<span class=\"comment\">// GetMinSafeTS return the minimal SafeTS of the storage with given txnScope.</span></span><br><span class=\"line\">\tGetMinSafeTS(txnScope <span class=\"type\">string</span>) <span class=\"type\">uint64</span></span><br><span class=\"line\">\t<span class=\"comment\">// GetLockWaits return all lock wait information</span></span><br><span class=\"line\">\tGetLockWaits() ([]*deadlockpb.WaitForEntry, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetCodec gets the codec of the storage.</span></span><br><span class=\"line\">\tGetCodec() tikv.Codec</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这些方法具体在哪些地方使用，我们可以在后面继续研究。我们可以简单看一下 TiDB 中 <code>tikv_driver.go</code>里对这些接口的实现，整个文件只有 400 多行，读起来也比较简单。</p>\n<p>首先可以看下当前 storage 是如何创建的。如前文所述，<code>main</code>方法中在完成 driver 注册后，会打开 storage，创建 storage 实例。<code>TiKVDriver</code>中的<code>OpenWithOptions</code>方法，这个方法里会加载一些关键配置，创建一些必要的组件，比如 placement driver相关的实例，用于连接<a href=\"https://cn.pingcap.com/blog/placement-driver\">集群总控中心</a>（我也不知道为什么叫这个名字，其实 meta server 之类的名字好像更好理解一些），包括 pdCli 和 pdClient，pdCli 用来直接连接 pd server，pdClient 在 pdCli 的基础上对一些元信息做编解码的工作；比如 叫做 SafePointKV 的etcd实例，这个我暂时没明白是用来做什么的，看注释是说用来做 mock test和 runtime的无缝集成的；还有 RPC client，用来做和 tikv server 的 rpc 管理的。最后会基于上述生成的组件，生成一个 KV store 的实例。这里还有一个比较有意思的是会生成一个 coprStore，应该是用来服务于 <a href=\"https://cn.pingcap.com/blog/tikv-source-code-reading-14\">Coprocessor</a> 场景，这个东西在很多系统中都有实现，后面可以专门讲一下。完成这一系列工作之后，一个 storage 实例就生成了。</p>\n<p>接着来看一下<code>Begin</code>方法，这个方法是用于开启一个全局事务，主要靠调用 KVStore 的 <code>Begin</code> 方法来实现。在 KVStore 的<code>Begin</code>方法中，首先加载传入的 option，然后获取启动事务的 timestamp，并基于这个 timestamp 创建一个 TiKV的快照TiKVSnapshot，然后返回 KVTxn 实例，构建TiKVTxn 后返回。Txn相关的细节在之后的文章可以详细介绍一下。</p>\n<p><code>tikv_driver.go</code>里面关于 <code>storage</code>接口的实现还有一些其他的方法，我们可以在后面调用到的时候来进一步分析。</p>\n","site":{"data":{}},"excerpt":"<p>今天开始一个新的系列，分析 TiDB的源码。TiDB是目前开源做的比较好的一个数据库，目前商用做的也挺好的，项目影响力很大。因为是 Go语言实现的，读起来也没有什么太大的门槛。考虑到之后可能会参考 TiDB 做一些自己的小项目，这个系列应该会陆陆续续把整个项目的代码都分析完。由于行文仓促，我对项目也不是特别熟悉，这个系列难免会有错漏之处，之后回顾这个系列的时候，有些地方我可能会自己打脸，重新写一版本。</p>","more":"<p>今天这一篇会简单过一遍 TiDB 如何和TiKV 做交互，主要记录我在读代码过程中看到的一些点。</p>\n<p>TiDB 的源码里面有两个模块与存储有关，分别是 store 和 kv。store 部分主要负责，kv 部分主要负责</p>\n<p>首先是 store 模块。</p>\n<p>在 tidb-server 启动的时候，main 函数中会将 TiKV 的Driver注册到 kvstore 的一个 map 里。<code>Driver</code> 接口里面值定义了一个 <code>Open</code> 方法，定义在 kv 模块的 kv.go 里，用于返回一个基于当前 store 的 storage 实例。完成注册后，<code>main</code> 函数会读取 config 中配置的 keyspaceName，基于此创建一个 storage 实例，用于创建 server。前面注册的 driver 会在此处基于 store path 解析出来，调用 <code>Open</code> 方法创建 storage 实例。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// tidb-server/main.go</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    registerStores()</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    keyspaceName := keyspace.GetKeyspaceNameBySettings()</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\">\tstorage, dom := createStoreAndDomain(keyspaceName)</span><br><span class=\"line\">\tsvr := createServer(storage, dom)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里涉及了另外一个内容更多的接口<code>Storage</code>。下面是接口的定义，里面的方法相对较多，我们可以简单过一下几个重要的方法。<code>Begin</code>用于开启一个全局事务，<code>GetSnapshot</code>方法可以计入传入的 version 读取一个快照，<code>GetClient</code>用于获取一个存储 client 实例，<code>GetMPPClient</code>用于获取一个 mpp client 实例(MPP是一个面试过程中喜欢聊到的话题，我们可以后面单独聊一下这部分)，<code>Close</code>用于关闭当前 store，<code>UUID</code>、<code>CurrentVersion</code>、<code>Name</code>、<code>Describe</code>等方法可以获取当前存储实例的相关信息，<code>GetMemCache</code>用于获取当前存储的 memory manager，<code>GetMinSafeTS</code>基于给定的 txnScope 获取当前存储的最小 SafeTS(这个没太懂是干什么的，后面可以再仔细看看),<code>GetLockWaits</code>可以获取所有的 lock wait 信息，<code>GetCodec</code>获取当前存储的 <code>codec</code>。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Storage defines the interface for storage.</span></span><br><span class=\"line\"><span class=\"comment\">// Isolation should be at least SI(SNAPSHOT ISOLATION)</span></span><br><span class=\"line\"><span class=\"keyword\">type</span> Storage <span class=\"keyword\">interface</span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// Begin a global transaction</span></span><br><span class=\"line\">\tBegin(opts ...tikv.TxnOption) (Transaction, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetSnapshot gets a snapshot that is able to read any data which data is &lt;= ver.</span></span><br><span class=\"line\">\t<span class=\"comment\">// if ver is MaxVersion or &gt; current max committed version, we will use current version for this snapshot.</span></span><br><span class=\"line\">\tGetSnapshot(ver Version) Snapshot</span><br><span class=\"line\">\t<span class=\"comment\">// GetClient gets a client instance.</span></span><br><span class=\"line\">\tGetClient() Client</span><br><span class=\"line\">\t<span class=\"comment\">// GetMPPClient gets a mpp client instance.</span></span><br><span class=\"line\">\tGetMPPClient() MPPClient</span><br><span class=\"line\">\t<span class=\"comment\">// Close store</span></span><br><span class=\"line\">\tClose() <span class=\"type\">error</span></span><br><span class=\"line\">\t<span class=\"comment\">// UUID return a unique ID which represents a Storage.</span></span><br><span class=\"line\">\tUUID() <span class=\"type\">string</span></span><br><span class=\"line\">\t<span class=\"comment\">// CurrentVersion returns current max committed version with the given txnScope (local or global).</span></span><br><span class=\"line\">\tCurrentVersion(txnScope <span class=\"type\">string</span>) (Version, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetOracle gets a timestamp oracle client.</span></span><br><span class=\"line\">\tGetOracle() oracle.Oracle</span><br><span class=\"line\">\t<span class=\"comment\">// SupportDeleteRange gets the storage support delete range or not.</span></span><br><span class=\"line\">\tSupportDeleteRange() (supported <span class=\"type\">bool</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// Name gets the name of the storage engine</span></span><br><span class=\"line\">\tName() <span class=\"type\">string</span></span><br><span class=\"line\">\t<span class=\"comment\">// Describe returns of brief introduction of the storage</span></span><br><span class=\"line\">\tDescribe() <span class=\"type\">string</span></span><br><span class=\"line\">\t<span class=\"comment\">// ShowStatus returns the specified status of the storage</span></span><br><span class=\"line\">\tShowStatus(ctx context.Context, key <span class=\"type\">string</span>) (<span class=\"keyword\">interface</span>&#123;&#125;, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetMemCache return memory manager of the storage.</span></span><br><span class=\"line\">\tGetMemCache() MemManager</span><br><span class=\"line\">\t<span class=\"comment\">// GetMinSafeTS return the minimal SafeTS of the storage with given txnScope.</span></span><br><span class=\"line\">\tGetMinSafeTS(txnScope <span class=\"type\">string</span>) <span class=\"type\">uint64</span></span><br><span class=\"line\">\t<span class=\"comment\">// GetLockWaits return all lock wait information</span></span><br><span class=\"line\">\tGetLockWaits() ([]*deadlockpb.WaitForEntry, <span class=\"type\">error</span>)</span><br><span class=\"line\">\t<span class=\"comment\">// GetCodec gets the codec of the storage.</span></span><br><span class=\"line\">\tGetCodec() tikv.Codec</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这些方法具体在哪些地方使用，我们可以在后面继续研究。我们可以简单看一下 TiDB 中 <code>tikv_driver.go</code>里对这些接口的实现，整个文件只有 400 多行，读起来也比较简单。</p>\n<p>首先可以看下当前 storage 是如何创建的。如前文所述，<code>main</code>方法中在完成 driver 注册后，会打开 storage，创建 storage 实例。<code>TiKVDriver</code>中的<code>OpenWithOptions</code>方法，这个方法里会加载一些关键配置，创建一些必要的组件，比如 placement driver相关的实例，用于连接<a href=\"https://cn.pingcap.com/blog/placement-driver\">集群总控中心</a>（我也不知道为什么叫这个名字，其实 meta server 之类的名字好像更好理解一些），包括 pdCli 和 pdClient，pdCli 用来直接连接 pd server，pdClient 在 pdCli 的基础上对一些元信息做编解码的工作；比如 叫做 SafePointKV 的etcd实例，这个我暂时没明白是用来做什么的，看注释是说用来做 mock test和 runtime的无缝集成的；还有 RPC client，用来做和 tikv server 的 rpc 管理的。最后会基于上述生成的组件，生成一个 KV store 的实例。这里还有一个比较有意思的是会生成一个 coprStore，应该是用来服务于 <a href=\"https://cn.pingcap.com/blog/tikv-source-code-reading-14\">Coprocessor</a> 场景，这个东西在很多系统中都有实现，后面可以专门讲一下。完成这一系列工作之后，一个 storage 实例就生成了。</p>\n<p>接着来看一下<code>Begin</code>方法，这个方法是用于开启一个全局事务，主要靠调用 KVStore 的 <code>Begin</code> 方法来实现。在 KVStore 的<code>Begin</code>方法中，首先加载传入的 option，然后获取启动事务的 timestamp，并基于这个 timestamp 创建一个 TiKV的快照TiKVSnapshot，然后返回 KVTxn 实例，构建TiKVTxn 后返回。Txn相关的细节在之后的文章可以详细介绍一下。</p>\n<p><code>tikv_driver.go</code>里面关于 <code>storage</code>接口的实现还有一些其他的方法，我们可以在后面调用到的时候来进一步分析。</p>"},{"title":"TiDB 查询计划优化，Optimize 是怎么实现的","_content":"\n查询优化器可以说是 DBMS 的灵魂模块了，这篇文章会简单讲一下 TiDB 的查询优化模块，从`planner/optimize.go`的 `Optimize`方法出发，逐步拆解 TiDB 查询优化的整个过程。\n\n<!-- more -->\n\n方法的定义如下,前两个参数是 context，我们先不用管，接着是抽象语法树的`node`，以及用于读取 schema 信息的接口。本方法会返回一个执行计划和`fieldName`的 slice。\n```go\nfunc Optimize(ctx context.Context, sctx sessionctx.Context, node ast.Node, is infoschema.InfoSchema) (core.Plan, types.NameSlice, error)\n```\n\n下面来详细看一下整体的实现思路，这是一个两百多行的超长方法，里面还有一些边边角角的实现，我们尝试来理解一下整个实现过程。\n\n进入方法后，首先会做一些 session variable 的检查，比如`InRestrictedSQL` 比如`isolationReadContainTiFlash`，这些检查与一些具体 feature 有关，我们暂时可以先不用管。\n\n接着来到一个 Optimize 方法`OptimizeExecStmt`, 如果当前 node 是一个 [`EXECUTE Statement`](https://dev.mysql.com/doc/refman/5.7/en/execute.html)，那我们就直接调用`buildLogicalPlan`方法构建逻辑计划，这部分就涉及到 `planner`部分的源码，我们之后再对这里进行分析。在构建完成逻辑计划后，再调用`GetPlanFromSessionPlanCache`来获取一个执行计划，若 session 的 plan cache 中存在对应的 plan，则从 cache 直接返回，否则就调用`generateNewPlan`方法来生成一个新的 plan。\n\n我们来看它是如何生成一个新的 plan 的。首先这里会尝试记录一个 cache miss 的 metric（当然这是很小的一个点，但是 metric 其实是生产环境中诊断系统健康状态的重要工具，我们看代码的过程中同样要学习如何打 metric），然后将读出的 `PreparedAst`进行优化。这样就又回到了 Optimize 方法里面。完成优化生成 plan 后，紧接着会尝试调用`tryCachePointPlan`来判断当前计划是否是一个`point execution plan`，并尝试将其 cache 下来。下面是 `PointGetPlan`的注释：\n\n```go\n// PointGetPlan is a fast plan for simple point get.\n// When we detect that the statement has a unique equal access condition, this plan is used.\n// This plan is much faster to build and to execute because it avoid the optimization and coprocessor cost.\n```\n\n简单来说，`PointGetPlan`就是用于执行存在唯一的 equal 条件的查询语句的查询计划。\n\n紧接着，这里会对当前计划进行判断，确认是否可以讲计划存入 cache，这里有一系列不同类型的物理计划不允许 cache。我们后面可以单独研究一下哪些计划可以放入 cache，哪些不行。判断可以放入 cache 的 plan，这里会生成对应的 key 和 value，然后放入 cache，并将对应的 plan 返回。\n\n接下来到了比较具体的优化部分，首先从 node 中提取出 `tableHints`,并对语句中的所有 hint 进行处理。完成处理后，如果这里是一个 point plan，函数会直接尝试 `PointGetPlan`来执行当前查询。接着获取 `TxnManager`，尝试`AdviseWarmup，这部分会在对 Txn 的分析里涉及到。\n\n这里接着做了一个`useBinding`的检查，我本来不知道这个是什么，后来查了一下之后发现其实就是去为特定语句绑定查询计划，比如指定索引之类的。这种操作能够人为查询过程中使用的索引，确保查询计划按照预期的方式生成。\n\n接下来最重要的`optimize`方法来了，这个方法就是执行整个优化的关键方法了。首先，语法树节点会`Accept`一个基于当前 session 的 context 生成的`hintProcessor`(这个操作我没太明白是在做什么事情，可以后面再看)，接着，我们从`planBuilderPool`里面取出一个 builder，用于生成逻辑计划，比较有意思的是这里对 builder 使用了`sync.Pool` 进行了复用和保存，`builder`在完成初始化后，会被拿来构建逻辑计划，这里用到`buildLogicalPlan`方法，这里会基于对应语句来构建执行计划。构建后逻辑计划后会执行权限检查，接着会做表锁的检查。通过上述检查后，如果当前 plan 不是逻辑计划，则会直接返回；如果是，则尝试使用瀑布计划器进行优化，找到最优的计划，并返回最佳计划。如果没有开启瀑布计划器，则会调用 `DoOptimize`方法进行优化，并返回最终计划。\n\n上面的`optimize`方法有三个方法需要进一步分析，这三个方法应该就是整个查询优化最核心部分的内容了。\n\n1. `buildLogicalPlan`：基于不同的语句类型构建初始的逻辑计划，涉及的语句比较多。以最基本的`SELECT`语句举例，在构建计划之前会做一些准备工作，比如对语句的检查、是否涉及 join 操作、是否有是`SELECT FOR UPDATE`等等，在构建计划时，先会创建一个基于 `FROM`语句的带有 data source 的 plan，这里面涉及到一些view 的检查、partition 的检查，接着会基于`FROM`的不同数据源构建，如果是一个 table，那么就会去找到一些可能可以使用的索引，作为 `IndexHints`等信息放入`DataSource`中，`DataSource`中还会有一些诸如`Column`、`PossibleAccessPath`等信息，并将其作为 planer 返回，返回后会做一些特定的处理，比如`SORT`、`LIMIT`等。里面的操作相对来说比较详细，后面可能会针对某个语句执行的整个生命周期写一篇文章，这样可能更好理解整个过程。\n2. 瀑布优化器的`FindBestPlan`：这个方法的注释非常完整，我们看起来也比较轻松。下面是注释的内容：\n\n```go\n// FindBestPlan is the optimization entrance of the cascades planner. The\n// optimization is composed of 3 phases: preprocessing, exploration and implementation.\n//\n// ------------------------------------------------------------------------------\n// Phase 1: Preprocessing\n// ------------------------------------------------------------------------------\n//\n// The target of this phase is to preprocess the plan tree by some heuristic\n// rules which should always be beneficial, for example Column Pruning.\n//\n// ------------------------------------------------------------------------------\n// Phase 2: Exploration\n// ------------------------------------------------------------------------------\n//\n// The target of this phase is to explore all the logically equivalent\n// expressions by exploring all the equivalent group expressions of each group.\n//\n// At the very beginning, there is only one group expression in a Group. After\n// applying some transformation rules on certain expressions of the Group, all\n// the equivalent expressions are found and stored in the Group. This procedure\n// can be regarded as searching for a weak connected component in a directed\n// graph, where nodes are expressions and directed edges are the transformation\n// rules.\n//\n// ------------------------------------------------------------------------------\n// Phase 3: Implementation\n// ------------------------------------------------------------------------------\n//\n// The target of this phase is to search the best physical plan for a Group\n// which satisfies a certain required physical property.\n//\n// In this phase, we need to enumerate all the applicable implementation rules\n// for each expression in each group under the required physical property. A\n// memo structure is used for a group to reduce the repeated search on the same\n// required physical property.\n```\n\n- 首先是预处理阶段。在这个阶段会对整个计划树做一个预处理，使用一些启发式规则进行优化，比如列裁剪。（我以为这里有很多优化规则，不过看方法只有一个列裁剪。。）\n- 接着是探索阶段。探索阶段会尝试对每一组表达式的所有等效表达式进行探索。在最开始的时候，一个 group 里面只有一组表达式，在执行一些转换规则之后，我们会找到所有的等效表达式并存入 Group 中。这个过程可以被当做在一个有向图里找一个弱连接组件，在这个图里，节点是表达式，边是各种转换规则。\n- 最后一个阶段是实现阶段，目标是找到一个最优的物理计划。这里会在要求的物理属性下对每一组的每一个表达式都遍历所有可用的实现规则。这里会有一个 memo 结构体，用于减少重复的搜索。\n\n3. `DoOptimize`：这个方法是为了将逻辑计划优化成一个物理计划。这里会应用很多的优化规则，优化规则存储在`optRuleList`里面，我们会在下一篇文章里谈到。\n\n```go\n在数据库领域，逻辑计划（Logical Plan）和物理计划（Physical Plan）是查询执行的两个关键阶段。它们表示了查询在执行过程中的不同层次和优化方式。\n\n逻辑计划是描述查询逻辑操作的计划，它不依赖于具体的执行环境和数据存储方式。逻辑计划通常由查询优化器根据用户提交的查询语句生成，它是对查询语句的语义解析和语义优化的结果。逻辑计划描述了查询的逻辑操作流程，包括涉及的表、连接方式、过滤条件、聚合操作等，但不关注具体的执行细节和物理存储结构。\n\n物理计划是根据逻辑计划和执行环境的具体情况生成的计划，它依赖于具体的数据库系统、存储引擎和硬件设备。物理计划是优化器根据逻辑计划和系统统计信息等综合考虑的结果，它将逻辑计划转化为实际的执行操作。物理计划考虑了具体的执行代价、数据访问路径、索引的选择、并行度等因素，以最优的方式执行查询操作。\n\n总结来说，逻辑计划关注查询的逻辑操作流程和语义，独立于具体的执行环境；而物理计划则将逻辑计划转化为可执行的操作，考虑了具体的执行细节和执行代价。逻辑计划是查询优化的一个关键阶段，它对查询进行了抽象和优化；物理计划则是执行阶段的具体操作计划，它考虑了实际的执行环境和资源情况。\n```\n","source":"_posts/tidb/optimize.md","raw":"---\ntitle: TiDB 查询计划优化，Optimize 是怎么实现的\ntags:\n    - TiDB\n    - 数据库\n    - 源码分析\n---\n\n查询优化器可以说是 DBMS 的灵魂模块了，这篇文章会简单讲一下 TiDB 的查询优化模块，从`planner/optimize.go`的 `Optimize`方法出发，逐步拆解 TiDB 查询优化的整个过程。\n\n<!-- more -->\n\n方法的定义如下,前两个参数是 context，我们先不用管，接着是抽象语法树的`node`，以及用于读取 schema 信息的接口。本方法会返回一个执行计划和`fieldName`的 slice。\n```go\nfunc Optimize(ctx context.Context, sctx sessionctx.Context, node ast.Node, is infoschema.InfoSchema) (core.Plan, types.NameSlice, error)\n```\n\n下面来详细看一下整体的实现思路，这是一个两百多行的超长方法，里面还有一些边边角角的实现，我们尝试来理解一下整个实现过程。\n\n进入方法后，首先会做一些 session variable 的检查，比如`InRestrictedSQL` 比如`isolationReadContainTiFlash`，这些检查与一些具体 feature 有关，我们暂时可以先不用管。\n\n接着来到一个 Optimize 方法`OptimizeExecStmt`, 如果当前 node 是一个 [`EXECUTE Statement`](https://dev.mysql.com/doc/refman/5.7/en/execute.html)，那我们就直接调用`buildLogicalPlan`方法构建逻辑计划，这部分就涉及到 `planner`部分的源码，我们之后再对这里进行分析。在构建完成逻辑计划后，再调用`GetPlanFromSessionPlanCache`来获取一个执行计划，若 session 的 plan cache 中存在对应的 plan，则从 cache 直接返回，否则就调用`generateNewPlan`方法来生成一个新的 plan。\n\n我们来看它是如何生成一个新的 plan 的。首先这里会尝试记录一个 cache miss 的 metric（当然这是很小的一个点，但是 metric 其实是生产环境中诊断系统健康状态的重要工具，我们看代码的过程中同样要学习如何打 metric），然后将读出的 `PreparedAst`进行优化。这样就又回到了 Optimize 方法里面。完成优化生成 plan 后，紧接着会尝试调用`tryCachePointPlan`来判断当前计划是否是一个`point execution plan`，并尝试将其 cache 下来。下面是 `PointGetPlan`的注释：\n\n```go\n// PointGetPlan is a fast plan for simple point get.\n// When we detect that the statement has a unique equal access condition, this plan is used.\n// This plan is much faster to build and to execute because it avoid the optimization and coprocessor cost.\n```\n\n简单来说，`PointGetPlan`就是用于执行存在唯一的 equal 条件的查询语句的查询计划。\n\n紧接着，这里会对当前计划进行判断，确认是否可以讲计划存入 cache，这里有一系列不同类型的物理计划不允许 cache。我们后面可以单独研究一下哪些计划可以放入 cache，哪些不行。判断可以放入 cache 的 plan，这里会生成对应的 key 和 value，然后放入 cache，并将对应的 plan 返回。\n\n接下来到了比较具体的优化部分，首先从 node 中提取出 `tableHints`,并对语句中的所有 hint 进行处理。完成处理后，如果这里是一个 point plan，函数会直接尝试 `PointGetPlan`来执行当前查询。接着获取 `TxnManager`，尝试`AdviseWarmup，这部分会在对 Txn 的分析里涉及到。\n\n这里接着做了一个`useBinding`的检查，我本来不知道这个是什么，后来查了一下之后发现其实就是去为特定语句绑定查询计划，比如指定索引之类的。这种操作能够人为查询过程中使用的索引，确保查询计划按照预期的方式生成。\n\n接下来最重要的`optimize`方法来了，这个方法就是执行整个优化的关键方法了。首先，语法树节点会`Accept`一个基于当前 session 的 context 生成的`hintProcessor`(这个操作我没太明白是在做什么事情，可以后面再看)，接着，我们从`planBuilderPool`里面取出一个 builder，用于生成逻辑计划，比较有意思的是这里对 builder 使用了`sync.Pool` 进行了复用和保存，`builder`在完成初始化后，会被拿来构建逻辑计划，这里用到`buildLogicalPlan`方法，这里会基于对应语句来构建执行计划。构建后逻辑计划后会执行权限检查，接着会做表锁的检查。通过上述检查后，如果当前 plan 不是逻辑计划，则会直接返回；如果是，则尝试使用瀑布计划器进行优化，找到最优的计划，并返回最佳计划。如果没有开启瀑布计划器，则会调用 `DoOptimize`方法进行优化，并返回最终计划。\n\n上面的`optimize`方法有三个方法需要进一步分析，这三个方法应该就是整个查询优化最核心部分的内容了。\n\n1. `buildLogicalPlan`：基于不同的语句类型构建初始的逻辑计划，涉及的语句比较多。以最基本的`SELECT`语句举例，在构建计划之前会做一些准备工作，比如对语句的检查、是否涉及 join 操作、是否有是`SELECT FOR UPDATE`等等，在构建计划时，先会创建一个基于 `FROM`语句的带有 data source 的 plan，这里面涉及到一些view 的检查、partition 的检查，接着会基于`FROM`的不同数据源构建，如果是一个 table，那么就会去找到一些可能可以使用的索引，作为 `IndexHints`等信息放入`DataSource`中，`DataSource`中还会有一些诸如`Column`、`PossibleAccessPath`等信息，并将其作为 planer 返回，返回后会做一些特定的处理，比如`SORT`、`LIMIT`等。里面的操作相对来说比较详细，后面可能会针对某个语句执行的整个生命周期写一篇文章，这样可能更好理解整个过程。\n2. 瀑布优化器的`FindBestPlan`：这个方法的注释非常完整，我们看起来也比较轻松。下面是注释的内容：\n\n```go\n// FindBestPlan is the optimization entrance of the cascades planner. The\n// optimization is composed of 3 phases: preprocessing, exploration and implementation.\n//\n// ------------------------------------------------------------------------------\n// Phase 1: Preprocessing\n// ------------------------------------------------------------------------------\n//\n// The target of this phase is to preprocess the plan tree by some heuristic\n// rules which should always be beneficial, for example Column Pruning.\n//\n// ------------------------------------------------------------------------------\n// Phase 2: Exploration\n// ------------------------------------------------------------------------------\n//\n// The target of this phase is to explore all the logically equivalent\n// expressions by exploring all the equivalent group expressions of each group.\n//\n// At the very beginning, there is only one group expression in a Group. After\n// applying some transformation rules on certain expressions of the Group, all\n// the equivalent expressions are found and stored in the Group. This procedure\n// can be regarded as searching for a weak connected component in a directed\n// graph, where nodes are expressions and directed edges are the transformation\n// rules.\n//\n// ------------------------------------------------------------------------------\n// Phase 3: Implementation\n// ------------------------------------------------------------------------------\n//\n// The target of this phase is to search the best physical plan for a Group\n// which satisfies a certain required physical property.\n//\n// In this phase, we need to enumerate all the applicable implementation rules\n// for each expression in each group under the required physical property. A\n// memo structure is used for a group to reduce the repeated search on the same\n// required physical property.\n```\n\n- 首先是预处理阶段。在这个阶段会对整个计划树做一个预处理，使用一些启发式规则进行优化，比如列裁剪。（我以为这里有很多优化规则，不过看方法只有一个列裁剪。。）\n- 接着是探索阶段。探索阶段会尝试对每一组表达式的所有等效表达式进行探索。在最开始的时候，一个 group 里面只有一组表达式，在执行一些转换规则之后，我们会找到所有的等效表达式并存入 Group 中。这个过程可以被当做在一个有向图里找一个弱连接组件，在这个图里，节点是表达式，边是各种转换规则。\n- 最后一个阶段是实现阶段，目标是找到一个最优的物理计划。这里会在要求的物理属性下对每一组的每一个表达式都遍历所有可用的实现规则。这里会有一个 memo 结构体，用于减少重复的搜索。\n\n3. `DoOptimize`：这个方法是为了将逻辑计划优化成一个物理计划。这里会应用很多的优化规则，优化规则存储在`optRuleList`里面，我们会在下一篇文章里谈到。\n\n```go\n在数据库领域，逻辑计划（Logical Plan）和物理计划（Physical Plan）是查询执行的两个关键阶段。它们表示了查询在执行过程中的不同层次和优化方式。\n\n逻辑计划是描述查询逻辑操作的计划，它不依赖于具体的执行环境和数据存储方式。逻辑计划通常由查询优化器根据用户提交的查询语句生成，它是对查询语句的语义解析和语义优化的结果。逻辑计划描述了查询的逻辑操作流程，包括涉及的表、连接方式、过滤条件、聚合操作等，但不关注具体的执行细节和物理存储结构。\n\n物理计划是根据逻辑计划和执行环境的具体情况生成的计划，它依赖于具体的数据库系统、存储引擎和硬件设备。物理计划是优化器根据逻辑计划和系统统计信息等综合考虑的结果，它将逻辑计划转化为实际的执行操作。物理计划考虑了具体的执行代价、数据访问路径、索引的选择、并行度等因素，以最优的方式执行查询操作。\n\n总结来说，逻辑计划关注查询的逻辑操作流程和语义，独立于具体的执行环境；而物理计划则将逻辑计划转化为可执行的操作，考虑了具体的执行细节和执行代价。逻辑计划是查询优化的一个关键阶段，它对查询进行了抽象和优化；物理计划则是执行阶段的具体操作计划，它考虑了实际的执行环境和资源情况。\n```\n","slug":"tidb/optimize","published":1,"date":"2023-07-30T06:11:37.247Z","updated":"2023-07-30T06:11:37.247Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clkp3c6j0000x1ts1gvff2k8r","content":"<p>查询优化器可以说是 DBMS 的灵魂模块了，这篇文章会简单讲一下 TiDB 的查询优化模块，从<code>planner/optimize.go</code>的 <code>Optimize</code>方法出发，逐步拆解 TiDB 查询优化的整个过程。</p>\n<span id=\"more\"></span>\n\n<p>方法的定义如下,前两个参数是 context，我们先不用管，接着是抽象语法树的<code>node</code>，以及用于读取 schema 信息的接口。本方法会返回一个执行计划和<code>fieldName</code>的 slice。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">Optimize</span><span class=\"params\">(ctx context.Context, sctx sessionctx.Context, node ast.Node, is infoschema.InfoSchema)</span></span> (core.Plan, types.NameSlice, <span class=\"type\">error</span>)</span><br></pre></td></tr></table></figure>\n\n<p>下面来详细看一下整体的实现思路，这是一个两百多行的超长方法，里面还有一些边边角角的实现，我们尝试来理解一下整个实现过程。</p>\n<p>进入方法后，首先会做一些 session variable 的检查，比如<code>InRestrictedSQL</code> 比如<code>isolationReadContainTiFlash</code>，这些检查与一些具体 feature 有关，我们暂时可以先不用管。</p>\n<p>接着来到一个 Optimize 方法<code>OptimizeExecStmt</code>, 如果当前 node 是一个 <a href=\"https://dev.mysql.com/doc/refman/5.7/en/execute.html\"><code>EXECUTE Statement</code></a>，那我们就直接调用<code>buildLogicalPlan</code>方法构建逻辑计划，这部分就涉及到 <code>planner</code>部分的源码，我们之后再对这里进行分析。在构建完成逻辑计划后，再调用<code>GetPlanFromSessionPlanCache</code>来获取一个执行计划，若 session 的 plan cache 中存在对应的 plan，则从 cache 直接返回，否则就调用<code>generateNewPlan</code>方法来生成一个新的 plan。</p>\n<p>我们来看它是如何生成一个新的 plan 的。首先这里会尝试记录一个 cache miss 的 metric（当然这是很小的一个点，但是 metric 其实是生产环境中诊断系统健康状态的重要工具，我们看代码的过程中同样要学习如何打 metric），然后将读出的 <code>PreparedAst</code>进行优化。这样就又回到了 Optimize 方法里面。完成优化生成 plan 后，紧接着会尝试调用<code>tryCachePointPlan</code>来判断当前计划是否是一个<code>point execution plan</code>，并尝试将其 cache 下来。下面是 <code>PointGetPlan</code>的注释：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// PointGetPlan is a fast plan for simple point get.</span></span><br><span class=\"line\"><span class=\"comment\">// When we detect that the statement has a unique equal access condition, this plan is used.</span></span><br><span class=\"line\"><span class=\"comment\">// This plan is much faster to build and to execute because it avoid the optimization and coprocessor cost.</span></span><br></pre></td></tr></table></figure>\n\n<p>简单来说，<code>PointGetPlan</code>就是用于执行存在唯一的 equal 条件的查询语句的查询计划。</p>\n<p>紧接着，这里会对当前计划进行判断，确认是否可以讲计划存入 cache，这里有一系列不同类型的物理计划不允许 cache。我们后面可以单独研究一下哪些计划可以放入 cache，哪些不行。判断可以放入 cache 的 plan，这里会生成对应的 key 和 value，然后放入 cache，并将对应的 plan 返回。</p>\n<p>接下来到了比较具体的优化部分，首先从 node 中提取出 <code>tableHints</code>,并对语句中的所有 hint 进行处理。完成处理后，如果这里是一个 point plan，函数会直接尝试 <code>PointGetPlan</code>来执行当前查询。接着获取 <code>TxnManager</code>，尝试&#96;AdviseWarmup，这部分会在对 Txn 的分析里涉及到。</p>\n<p>这里接着做了一个<code>useBinding</code>的检查，我本来不知道这个是什么，后来查了一下之后发现其实就是去为特定语句绑定查询计划，比如指定索引之类的。这种操作能够人为查询过程中使用的索引，确保查询计划按照预期的方式生成。</p>\n<p>接下来最重要的<code>optimize</code>方法来了，这个方法就是执行整个优化的关键方法了。首先，语法树节点会<code>Accept</code>一个基于当前 session 的 context 生成的<code>hintProcessor</code>(这个操作我没太明白是在做什么事情，可以后面再看)，接着，我们从<code>planBuilderPool</code>里面取出一个 builder，用于生成逻辑计划，比较有意思的是这里对 builder 使用了<code>sync.Pool</code> 进行了复用和保存，<code>builder</code>在完成初始化后，会被拿来构建逻辑计划，这里用到<code>buildLogicalPlan</code>方法，这里会基于对应语句来构建执行计划。构建后逻辑计划后会执行权限检查，接着会做表锁的检查。通过上述检查后，如果当前 plan 不是逻辑计划，则会直接返回；如果是，则尝试使用瀑布计划器进行优化，找到最优的计划，并返回最佳计划。如果没有开启瀑布计划器，则会调用 <code>DoOptimize</code>方法进行优化，并返回最终计划。</p>\n<p>上面的<code>optimize</code>方法有三个方法需要进一步分析，这三个方法应该就是整个查询优化最核心部分的内容了。</p>\n<ol>\n<li><code>buildLogicalPlan</code>：基于不同的语句类型构建初始的逻辑计划，涉及的语句比较多。以最基本的<code>SELECT</code>语句举例，在构建计划之前会做一些准备工作，比如对语句的检查、是否涉及 join 操作、是否有是<code>SELECT FOR UPDATE</code>等等，在构建计划时，先会创建一个基于 <code>FROM</code>语句的带有 data source 的 plan，这里面涉及到一些view 的检查、partition 的检查，接着会基于<code>FROM</code>的不同数据源构建，如果是一个 table，那么就会去找到一些可能可以使用的索引，作为 <code>IndexHints</code>等信息放入<code>DataSource</code>中，<code>DataSource</code>中还会有一些诸如<code>Column</code>、<code>PossibleAccessPath</code>等信息，并将其作为 planer 返回，返回后会做一些特定的处理，比如<code>SORT</code>、<code>LIMIT</code>等。里面的操作相对来说比较详细，后面可能会针对某个语句执行的整个生命周期写一篇文章，这样可能更好理解整个过程。</li>\n<li>瀑布优化器的<code>FindBestPlan</code>：这个方法的注释非常完整，我们看起来也比较轻松。下面是注释的内容：</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// FindBestPlan is the optimization entrance of the cascades planner. The</span></span><br><span class=\"line\"><span class=\"comment\">// optimization is composed of 3 phases: preprocessing, exploration and implementation.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">// Phase 1: Preprocessing</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The target of this phase is to preprocess the plan tree by some heuristic</span></span><br><span class=\"line\"><span class=\"comment\">// rules which should always be beneficial, for example Column Pruning.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">// Phase 2: Exploration</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The target of this phase is to explore all the logically equivalent</span></span><br><span class=\"line\"><span class=\"comment\">// expressions by exploring all the equivalent group expressions of each group.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// At the very beginning, there is only one group expression in a Group. After</span></span><br><span class=\"line\"><span class=\"comment\">// applying some transformation rules on certain expressions of the Group, all</span></span><br><span class=\"line\"><span class=\"comment\">// the equivalent expressions are found and stored in the Group. This procedure</span></span><br><span class=\"line\"><span class=\"comment\">// can be regarded as searching for a weak connected component in a directed</span></span><br><span class=\"line\"><span class=\"comment\">// graph, where nodes are expressions and directed edges are the transformation</span></span><br><span class=\"line\"><span class=\"comment\">// rules.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">// Phase 3: Implementation</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The target of this phase is to search the best physical plan for a Group</span></span><br><span class=\"line\"><span class=\"comment\">// which satisfies a certain required physical property.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// In this phase, we need to enumerate all the applicable implementation rules</span></span><br><span class=\"line\"><span class=\"comment\">// for each expression in each group under the required physical property. A</span></span><br><span class=\"line\"><span class=\"comment\">// memo structure is used for a group to reduce the repeated search on the same</span></span><br><span class=\"line\"><span class=\"comment\">// required physical property.</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>首先是预处理阶段。在这个阶段会对整个计划树做一个预处理，使用一些启发式规则进行优化，比如列裁剪。（我以为这里有很多优化规则，不过看方法只有一个列裁剪。。）</li>\n<li>接着是探索阶段。探索阶段会尝试对每一组表达式的所有等效表达式进行探索。在最开始的时候，一个 group 里面只有一组表达式，在执行一些转换规则之后，我们会找到所有的等效表达式并存入 Group 中。这个过程可以被当做在一个有向图里找一个弱连接组件，在这个图里，节点是表达式，边是各种转换规则。</li>\n<li>最后一个阶段是实现阶段，目标是找到一个最优的物理计划。这里会在要求的物理属性下对每一组的每一个表达式都遍历所有可用的实现规则。这里会有一个 memo 结构体，用于减少重复的搜索。</li>\n</ul>\n<ol start=\"3\">\n<li><code>DoOptimize</code>：这个方法是为了将逻辑计划优化成一个物理计划。这里会应用很多的优化规则，优化规则存储在<code>optRuleList</code>里面，我们会在下一篇文章里谈到。</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在数据库领域，逻辑计划（Logical Plan）和物理计划（Physical Plan）是查询执行的两个关键阶段。它们表示了查询在执行过程中的不同层次和优化方式。</span><br><span class=\"line\"></span><br><span class=\"line\">逻辑计划是描述查询逻辑操作的计划，它不依赖于具体的执行环境和数据存储方式。逻辑计划通常由查询优化器根据用户提交的查询语句生成，它是对查询语句的语义解析和语义优化的结果。逻辑计划描述了查询的逻辑操作流程，包括涉及的表、连接方式、过滤条件、聚合操作等，但不关注具体的执行细节和物理存储结构。</span><br><span class=\"line\"></span><br><span class=\"line\">物理计划是根据逻辑计划和执行环境的具体情况生成的计划，它依赖于具体的数据库系统、存储引擎和硬件设备。物理计划是优化器根据逻辑计划和系统统计信息等综合考虑的结果，它将逻辑计划转化为实际的执行操作。物理计划考虑了具体的执行代价、数据访问路径、索引的选择、并行度等因素，以最优的方式执行查询操作。</span><br><span class=\"line\"></span><br><span class=\"line\">总结来说，逻辑计划关注查询的逻辑操作流程和语义，独立于具体的执行环境；而物理计划则将逻辑计划转化为可执行的操作，考虑了具体的执行细节和执行代价。逻辑计划是查询优化的一个关键阶段，它对查询进行了抽象和优化；物理计划则是执行阶段的具体操作计划，它考虑了实际的执行环境和资源情况。</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>查询优化器可以说是 DBMS 的灵魂模块了，这篇文章会简单讲一下 TiDB 的查询优化模块，从<code>planner/optimize.go</code>的 <code>Optimize</code>方法出发，逐步拆解 TiDB 查询优化的整个过程。</p>","more":"<p>方法的定义如下,前两个参数是 context，我们先不用管，接着是抽象语法树的<code>node</code>，以及用于读取 schema 信息的接口。本方法会返回一个执行计划和<code>fieldName</code>的 slice。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">Optimize</span><span class=\"params\">(ctx context.Context, sctx sessionctx.Context, node ast.Node, is infoschema.InfoSchema)</span></span> (core.Plan, types.NameSlice, <span class=\"type\">error</span>)</span><br></pre></td></tr></table></figure>\n\n<p>下面来详细看一下整体的实现思路，这是一个两百多行的超长方法，里面还有一些边边角角的实现，我们尝试来理解一下整个实现过程。</p>\n<p>进入方法后，首先会做一些 session variable 的检查，比如<code>InRestrictedSQL</code> 比如<code>isolationReadContainTiFlash</code>，这些检查与一些具体 feature 有关，我们暂时可以先不用管。</p>\n<p>接着来到一个 Optimize 方法<code>OptimizeExecStmt</code>, 如果当前 node 是一个 <a href=\"https://dev.mysql.com/doc/refman/5.7/en/execute.html\"><code>EXECUTE Statement</code></a>，那我们就直接调用<code>buildLogicalPlan</code>方法构建逻辑计划，这部分就涉及到 <code>planner</code>部分的源码，我们之后再对这里进行分析。在构建完成逻辑计划后，再调用<code>GetPlanFromSessionPlanCache</code>来获取一个执行计划，若 session 的 plan cache 中存在对应的 plan，则从 cache 直接返回，否则就调用<code>generateNewPlan</code>方法来生成一个新的 plan。</p>\n<p>我们来看它是如何生成一个新的 plan 的。首先这里会尝试记录一个 cache miss 的 metric（当然这是很小的一个点，但是 metric 其实是生产环境中诊断系统健康状态的重要工具，我们看代码的过程中同样要学习如何打 metric），然后将读出的 <code>PreparedAst</code>进行优化。这样就又回到了 Optimize 方法里面。完成优化生成 plan 后，紧接着会尝试调用<code>tryCachePointPlan</code>来判断当前计划是否是一个<code>point execution plan</code>，并尝试将其 cache 下来。下面是 <code>PointGetPlan</code>的注释：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// PointGetPlan is a fast plan for simple point get.</span></span><br><span class=\"line\"><span class=\"comment\">// When we detect that the statement has a unique equal access condition, this plan is used.</span></span><br><span class=\"line\"><span class=\"comment\">// This plan is much faster to build and to execute because it avoid the optimization and coprocessor cost.</span></span><br></pre></td></tr></table></figure>\n\n<p>简单来说，<code>PointGetPlan</code>就是用于执行存在唯一的 equal 条件的查询语句的查询计划。</p>\n<p>紧接着，这里会对当前计划进行判断，确认是否可以讲计划存入 cache，这里有一系列不同类型的物理计划不允许 cache。我们后面可以单独研究一下哪些计划可以放入 cache，哪些不行。判断可以放入 cache 的 plan，这里会生成对应的 key 和 value，然后放入 cache，并将对应的 plan 返回。</p>\n<p>接下来到了比较具体的优化部分，首先从 node 中提取出 <code>tableHints</code>,并对语句中的所有 hint 进行处理。完成处理后，如果这里是一个 point plan，函数会直接尝试 <code>PointGetPlan</code>来执行当前查询。接着获取 <code>TxnManager</code>，尝试&#96;AdviseWarmup，这部分会在对 Txn 的分析里涉及到。</p>\n<p>这里接着做了一个<code>useBinding</code>的检查，我本来不知道这个是什么，后来查了一下之后发现其实就是去为特定语句绑定查询计划，比如指定索引之类的。这种操作能够人为查询过程中使用的索引，确保查询计划按照预期的方式生成。</p>\n<p>接下来最重要的<code>optimize</code>方法来了，这个方法就是执行整个优化的关键方法了。首先，语法树节点会<code>Accept</code>一个基于当前 session 的 context 生成的<code>hintProcessor</code>(这个操作我没太明白是在做什么事情，可以后面再看)，接着，我们从<code>planBuilderPool</code>里面取出一个 builder，用于生成逻辑计划，比较有意思的是这里对 builder 使用了<code>sync.Pool</code> 进行了复用和保存，<code>builder</code>在完成初始化后，会被拿来构建逻辑计划，这里用到<code>buildLogicalPlan</code>方法，这里会基于对应语句来构建执行计划。构建后逻辑计划后会执行权限检查，接着会做表锁的检查。通过上述检查后，如果当前 plan 不是逻辑计划，则会直接返回；如果是，则尝试使用瀑布计划器进行优化，找到最优的计划，并返回最佳计划。如果没有开启瀑布计划器，则会调用 <code>DoOptimize</code>方法进行优化，并返回最终计划。</p>\n<p>上面的<code>optimize</code>方法有三个方法需要进一步分析，这三个方法应该就是整个查询优化最核心部分的内容了。</p>\n<ol>\n<li><code>buildLogicalPlan</code>：基于不同的语句类型构建初始的逻辑计划，涉及的语句比较多。以最基本的<code>SELECT</code>语句举例，在构建计划之前会做一些准备工作，比如对语句的检查、是否涉及 join 操作、是否有是<code>SELECT FOR UPDATE</code>等等，在构建计划时，先会创建一个基于 <code>FROM</code>语句的带有 data source 的 plan，这里面涉及到一些view 的检查、partition 的检查，接着会基于<code>FROM</code>的不同数据源构建，如果是一个 table，那么就会去找到一些可能可以使用的索引，作为 <code>IndexHints</code>等信息放入<code>DataSource</code>中，<code>DataSource</code>中还会有一些诸如<code>Column</code>、<code>PossibleAccessPath</code>等信息，并将其作为 planer 返回，返回后会做一些特定的处理，比如<code>SORT</code>、<code>LIMIT</code>等。里面的操作相对来说比较详细，后面可能会针对某个语句执行的整个生命周期写一篇文章，这样可能更好理解整个过程。</li>\n<li>瀑布优化器的<code>FindBestPlan</code>：这个方法的注释非常完整，我们看起来也比较轻松。下面是注释的内容：</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// FindBestPlan is the optimization entrance of the cascades planner. The</span></span><br><span class=\"line\"><span class=\"comment\">// optimization is composed of 3 phases: preprocessing, exploration and implementation.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">// Phase 1: Preprocessing</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The target of this phase is to preprocess the plan tree by some heuristic</span></span><br><span class=\"line\"><span class=\"comment\">// rules which should always be beneficial, for example Column Pruning.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">// Phase 2: Exploration</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The target of this phase is to explore all the logically equivalent</span></span><br><span class=\"line\"><span class=\"comment\">// expressions by exploring all the equivalent group expressions of each group.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// At the very beginning, there is only one group expression in a Group. After</span></span><br><span class=\"line\"><span class=\"comment\">// applying some transformation rules on certain expressions of the Group, all</span></span><br><span class=\"line\"><span class=\"comment\">// the equivalent expressions are found and stored in the Group. This procedure</span></span><br><span class=\"line\"><span class=\"comment\">// can be regarded as searching for a weak connected component in a directed</span></span><br><span class=\"line\"><span class=\"comment\">// graph, where nodes are expressions and directed edges are the transformation</span></span><br><span class=\"line\"><span class=\"comment\">// rules.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">// Phase 3: Implementation</span></span><br><span class=\"line\"><span class=\"comment\">// ------------------------------------------------------------------------------</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// The target of this phase is to search the best physical plan for a Group</span></span><br><span class=\"line\"><span class=\"comment\">// which satisfies a certain required physical property.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// In this phase, we need to enumerate all the applicable implementation rules</span></span><br><span class=\"line\"><span class=\"comment\">// for each expression in each group under the required physical property. A</span></span><br><span class=\"line\"><span class=\"comment\">// memo structure is used for a group to reduce the repeated search on the same</span></span><br><span class=\"line\"><span class=\"comment\">// required physical property.</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>首先是预处理阶段。在这个阶段会对整个计划树做一个预处理，使用一些启发式规则进行优化，比如列裁剪。（我以为这里有很多优化规则，不过看方法只有一个列裁剪。。）</li>\n<li>接着是探索阶段。探索阶段会尝试对每一组表达式的所有等效表达式进行探索。在最开始的时候，一个 group 里面只有一组表达式，在执行一些转换规则之后，我们会找到所有的等效表达式并存入 Group 中。这个过程可以被当做在一个有向图里找一个弱连接组件，在这个图里，节点是表达式，边是各种转换规则。</li>\n<li>最后一个阶段是实现阶段，目标是找到一个最优的物理计划。这里会在要求的物理属性下对每一组的每一个表达式都遍历所有可用的实现规则。这里会有一个 memo 结构体，用于减少重复的搜索。</li>\n</ul>\n<ol start=\"3\">\n<li><code>DoOptimize</code>：这个方法是为了将逻辑计划优化成一个物理计划。这里会应用很多的优化规则，优化规则存储在<code>optRuleList</code>里面，我们会在下一篇文章里谈到。</li>\n</ol>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在数据库领域，逻辑计划（Logical Plan）和物理计划（Physical Plan）是查询执行的两个关键阶段。它们表示了查询在执行过程中的不同层次和优化方式。</span><br><span class=\"line\"></span><br><span class=\"line\">逻辑计划是描述查询逻辑操作的计划，它不依赖于具体的执行环境和数据存储方式。逻辑计划通常由查询优化器根据用户提交的查询语句生成，它是对查询语句的语义解析和语义优化的结果。逻辑计划描述了查询的逻辑操作流程，包括涉及的表、连接方式、过滤条件、聚合操作等，但不关注具体的执行细节和物理存储结构。</span><br><span class=\"line\"></span><br><span class=\"line\">物理计划是根据逻辑计划和执行环境的具体情况生成的计划，它依赖于具体的数据库系统、存储引擎和硬件设备。物理计划是优化器根据逻辑计划和系统统计信息等综合考虑的结果，它将逻辑计划转化为实际的执行操作。物理计划考虑了具体的执行代价、数据访问路径、索引的选择、并行度等因素，以最优的方式执行查询操作。</span><br><span class=\"line\"></span><br><span class=\"line\">总结来说，逻辑计划关注查询的逻辑操作流程和语义，独立于具体的执行环境；而物理计划则将逻辑计划转化为可执行的操作，考虑了具体的执行细节和执行代价。逻辑计划是查询优化的一个关键阶段，它对查询进行了抽象和优化；物理计划则是执行阶段的具体操作计划，它考虑了实际的执行环境和资源情况。</span><br></pre></td></tr></table></figure>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"clkp3c6is00011ts1fhspfo2b","tag_id":"clkp3c6iu00041ts15l3h1ycx","_id":"clkp3c6ix00091ts16u7r2h92"},{"post_id":"clkp3c6iu00031ts13l9d2cup","tag_id":"clkp3c6iu00041ts15l3h1ycx","_id":"clkp3c6ix000d1ts1ciiycc9l"},{"post_id":"clkp3c6ix000b1ts16sus4dsl","tag_id":"clkp3c6iu00041ts15l3h1ycx","_id":"clkp3c6iy000f1ts1etb8eqnc"},{"post_id":"clkp3c6iv00051ts19qdl93x6","tag_id":"clkp3c6iu00041ts15l3h1ycx","_id":"clkp3c6iy000h1ts17lfbc3ge"},{"post_id":"clkp3c6iv00061ts117rtfzcu","tag_id":"clkp3c6iy000g1ts19ht9d9hi","_id":"clkp3c6iy000j1ts1dp2w5cby"},{"post_id":"clkp3c6ix000a1ts12k768hix","tag_id":"clkp3c6iy000i1ts1b3rsgbd5","_id":"clkp3c6iy000l1ts1a5c7doyn"},{"post_id":"clkp3c6ix000e1ts14nucc7cv","tag_id":"clkp3c6iy000i1ts1b3rsgbd5","_id":"clkp3c6iy000m1ts15fet73pj"},{"post_id":"clkp3c6iy000n1ts1eeilf9o2","tag_id":"clkp3c6iu00041ts15l3h1ycx","_id":"clkp3c6iz000p1ts12uylapue"},{"post_id":"clkp3c6iz000o1ts10a8ycke3","tag_id":"clkp3c6iz000r1ts174tbg7zi","_id":"clkp3c6j0000w1ts1cm9j71ub"},{"post_id":"clkp3c6iz000q1ts1h5p49vlb","tag_id":"clkp3c6j0000v1ts1e2m58hwb","_id":"clkp3c6j0000z1ts12y8q5uql"},{"post_id":"clkp3c6iz000s1ts18hqeg8o1","tag_id":"clkp3c6j0000v1ts1e2m58hwb","_id":"clkp3c6j000111ts1eycv01cn"},{"post_id":"clkp3c6iz000t1ts17qy22tco","tag_id":"clkp3c6j000101ts17gb76c3e","_id":"clkp3c6j000131ts1h37gehax"},{"post_id":"clkp3c6j0000u1ts108tmfiru","tag_id":"clkp3c6j000101ts17gb76c3e","_id":"clkp3c6j100161ts17na17myq"},{"post_id":"clkp3c6j0000u1ts108tmfiru","tag_id":"clkp3c6iy000g1ts19ht9d9hi","_id":"clkp3c6j100171ts16k0f7d7r"},{"post_id":"clkp3c6j0000u1ts108tmfiru","tag_id":"clkp3c6j000141ts1hzrr98gz","_id":"clkp3c6j100191ts1fnrkakfr"},{"post_id":"clkp3c6j0000x1ts1gvff2k8r","tag_id":"clkp3c6j000101ts17gb76c3e","_id":"clkp3c6j1001a1ts13him831u"},{"post_id":"clkp3c6j0000x1ts1gvff2k8r","tag_id":"clkp3c6iy000g1ts19ht9d9hi","_id":"clkp3c6j1001b1ts1hp922wff"},{"post_id":"clkp3c6j0000x1ts1gvff2k8r","tag_id":"clkp3c6j000141ts1hzrr98gz","_id":"clkp3c6j1001c1ts1fmg78z5v"},{"post_id":"clkp3c6iv00071ts16lz5hiue","tag_id":"clkp3c6iy000g1ts19ht9d9hi","_id":"clkp3yixx0000abs1be82dhgm"},{"post_id":"clkp3c6iv00071ts16lz5hiue","tag_id":"clkp3c6iy000i1ts1b3rsgbd5","_id":"clkp3yixy0001abs19h38b4zo"}],"Tag":[{"name":"TBD","_id":"clkp3c6iu00041ts15l3h1ycx"},{"name":"数据库","_id":"clkp3c6iy000g1ts19ht9d9hi"},{"name":"Paper Reading","_id":"clkp3c6iy000i1ts1b3rsgbd5"},{"name":"技术杂谈","_id":"clkp3c6iz000r1ts174tbg7zi"},{"name":"面试","_id":"clkp3c6j0000v1ts1e2m58hwb"},{"name":"TiDB","_id":"clkp3c6j000101ts17gb76c3e"},{"name":"源码分析","_id":"clkp3c6j000141ts1hzrr98gz"}]}}